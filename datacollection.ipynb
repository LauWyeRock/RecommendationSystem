{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "import base64   \n",
    "import pandas as pd\n",
    "import librosa\n",
    "import numpy as np\n",
    "import lyricsgenius\n",
    "import langdetect\n",
    "import re\n",
    "import string\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For any api we can try using the \"+\" email trick to get more API keys\n",
    "\n",
    "spotify_client_id = \"dae4aecab9ff4dfeb227cb9ff279ebf3\"\n",
    "spotify_client_secret = \"0120d846e45e44c4843a8f983eeeb4a2\"\n",
    "\n",
    "genius_client_id = \"wZZ2RWc5mqp-5Pbz2W1rQJWE8LQ3pFBrb1Hw5_AOqgybq28mt7kjdjcG4zktCNbO\"\n",
    "genius_client_secret = \"PefqBJHor_muDgTutGlaXXaxmzsI7TQCps9FQ3FwkUTT0WJIT3s0A5YA9mnFbfp_-CBhQF7b0omgE8kaM3dJ3w\"\n",
    "genius_access_token = \"NUHHVpwnmbDYUYw8Padu0gQeHvYN4OsKYtE2MKNUpBUI6yR-xZXKY6S5NvCnFbiP\"\n",
    "\n",
    "lastfm_api_key = \"97d5a64d5ba4a8bc580b752ceff3b87f\"\n",
    "lastfm_secret = \"35175090bd61f6f16ac607bd26e5b1de\"\n",
    "\n",
    "aud_api = \"d3e2b670a1feab78763ef53399364109\" ## Valid until 4 march"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deezer API to get 30 seconds preview of songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Blueming',\n",
       " 'artist': 'IU',\n",
       " 'featured_artists': None,\n",
       " 'duration': 217,\n",
       " 'album': 'Love poem',\n",
       " 'preview_url': 'https://cdns-preview-c.dzcdn.net/stream/c-cabe5eee524ba4c4708032cdc0bbe7fe-4.mp3',\n",
       " 'link': 'https://www.deezer.com/track/811112942'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def search_deezer_track(track_name):\n",
    "    search_url = \"https://api.deezer.com/search/track\"\n",
    "    params = {\"q\": track_name}\n",
    "    response = requests.get(search_url, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        tracks = response.json().get('data', [])\n",
    "        for track in tracks:\n",
    "            print(f\"Track ID: {track['id']}, Title: {track['title']}, Artist: {track['artist']['name']}\")\n",
    "    else:\n",
    "        print(f\"Failed to search tracks. Status code: {response.status_code}\")\n",
    "\n",
    "\n",
    "def get_deezer_track_info(track_id):\n",
    "    \"\"\"\n",
    "    Fetch track information and MP3 preview file URL from Deezer API.\n",
    "\n",
    "    Parameters:\n",
    "    - track_id: The unique identifier for the track on Deezer.\n",
    "\n",
    "    Returns:\n",
    "    A dictionary with track information and the preview URL.\n",
    "    \"\"\"\n",
    "    base_url = \"https://api.deezer.com/track/\"\n",
    "    response = requests.get(f\"{base_url}{track_id}\")\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        main_artist = data.get(\"artist\", {}).get(\"name\", \"\")\n",
    "        contributors = [contributor['name'] for contributor in data.get(\"contributors\", []) if contributor['name'] != main_artist]\n",
    "        featured_artists = \", \".join(contributors) if contributors else None\n",
    "\n",
    "        track_info = {\n",
    "            \"title\": data.get(\"title\"),\n",
    "            \"artist\": main_artist,\n",
    "            \"featured_artists\": featured_artists,\n",
    "            \"duration\": data.get(\"duration\"),\n",
    "            \"album\": data.get(\"album\", {}).get(\"title\"),\n",
    "            \"preview_url\": data.get(\"preview\"),\n",
    "            \"link\": data.get(\"link\")\n",
    "        }\n",
    "        return track_info\n",
    "    else:\n",
    "        print(f\"Failed to fetch data for track ID {track_id}. Status code: {response.status_code}\")\n",
    "        return {}\n",
    "\n",
    "\n",
    "def get_song_details_from_url(audio_url, api_token):\n",
    "    \"\"\"\n",
    "    Fetch song details using AudD API from an audio URL.\n",
    "\n",
    "    Parameters:\n",
    "    - audio_url: URL to the audio file for song recognition.\n",
    "    - api_token: Your AudD API token.\n",
    "\n",
    "    Returns:\n",
    "    A dictionary with song details.\n",
    "    \"\"\"\n",
    "    api_endpoint = \"https://api.audd.io/\"\n",
    "    params = {\n",
    "        \"url\": audio_url,\n",
    "        \"return\": \"apple_music,spotify\",  # You can specify what additional data you want (e.g., metadata from Apple Music or Spotify)\n",
    "        \"api_token\": api_token,\n",
    "    }\n",
    "\n",
    "    response = requests.post(api_endpoint, data=params)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Failed to fetch song details. Status code: {response.status_code}\")\n",
    "        return {}\n",
    "\n",
    "\n",
    "\n",
    "# audio_url = \"https://cdns-preview-c.dzcdn.net/stream/c-cabe5eee524ba4c4708032cdc0bbe7fe-4.mp3\"  # Replace with the actual URL to the audio file\n",
    "# song_details = get_song_details_from_url(audio_url, aud_api)\n",
    "# print(json.dumps(song_details, indent=4))\n",
    "\n",
    "get_deezer_track_info(\"811112942\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LastFM API to get Song info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'http://ws.audioscrobbler.com/2.0/'\n",
    "\n",
    "def lastfm_get(payload):\n",
    "    headers = {'user-agent': 'DataCollectorBot'}\n",
    "    payload['api_key'] = lastfm_api_key\n",
    "    payload['format'] = 'json'\n",
    "    response = requests.get(base_url, headers=headers, params=payload)\n",
    "    return response.json()\n",
    "\n",
    "def get_song_details(artist_name, track_name):\n",
    "    payload = {\n",
    "        'method': 'track.getInfo',\n",
    "        'artist': artist_name,\n",
    "        'track': track_name,\n",
    "    }\n",
    "    json_response = lastfm_get(payload)\n",
    "    return json_response.get('track', {})\n",
    "\n",
    "def get_artist_details(artist_name):\n",
    "    payload = {\n",
    "        'method': 'artist.getInfo',\n",
    "        'artist': artist_name,\n",
    "    }\n",
    "    json_response = lastfm_get(payload)\n",
    "    return json_response.get('artist', {})\n",
    "\n",
    "def get_recommendations(artist_name, track_name, limit=20):\n",
    "    payload = {\n",
    "        'method': 'track.getSimilar',\n",
    "        'artist': artist_name,\n",
    "        'track': track_name,\n",
    "        'limit': limit,\n",
    "    }\n",
    "    json_response = lastfm_get(payload)\n",
    "    return json_response.get('similartracks', {}).get('track', [])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LastFM API to get top / trending tracks (Global and by country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_global_top_tracks(limit=50):\n",
    "    payload = {\n",
    "        'method': 'chart.getTopTracks',\n",
    "        'limit': limit,\n",
    "    }\n",
    "    json_response = lastfm_get(payload)\n",
    "    return json_response.get('tracks', {}).get('track', [])\n",
    "\n",
    "def get_top_tracks_by_country(country, limit=50):\n",
    "    payload = {\n",
    "        'method': 'geo.getTopTracks',\n",
    "        'country': country,\n",
    "        'limit': limit,\n",
    "    }\n",
    "    json_response = lastfm_get(payload)\n",
    "    return json_response.get('tracks', {}).get('track', [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spotify API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token():\n",
    "    auth_string = spotify_client_id + \":\" + spotify_client_secret\n",
    "    auth_bytes = auth_string.encode(\"utf-8\")\n",
    "    auth_base64 = str(base64.b64encode(auth_bytes), \"utf-8\")\n",
    "\n",
    "    url = \"https://accounts.spotify.com/api/token\"\n",
    "    headers = {\n",
    "        \"Authorization\" : \"Basic \" + auth_base64,\n",
    "        \"Content-Type\": \"application/x-www-form-urlencoded\"\n",
    "    }\n",
    "    data = {\"grant_type\": \"client_credentials\"}\n",
    "    result = requests.post(url,headers=headers, data=data)\n",
    "    json_result= json.loads(result.content)\n",
    "    token = json_result['access_token']\n",
    "    return token\n",
    "\n",
    "def get_auth_header(token):\n",
    "    return {\"Authorization\": \"Bearer \" + token }\n",
    "\n",
    "\n",
    "def get_song_details(song_id, auth_header):\n",
    "    \"\"\"Fetch song metadata using Spotify API.\"\"\"\n",
    "    url = f\"https://api.spotify.com/v1/tracks/{song_id}\"\n",
    "    response = requests.get(url, headers=auth_header)\n",
    "    return response.json()\n",
    "\n",
    "def get_audio_features(song_id, auth_header):\n",
    "    \"\"\"Fetch audio features for a song.\"\"\"\n",
    "    url = f\"https://api.spotify.com/v1/audio-features/{song_id}\"\n",
    "    response = requests.get(url, headers=auth_header)\n",
    "    return response.json()\n",
    "\n",
    "def get_audio_analysis(song_id, auth_header):\n",
    "    \"\"\"Fetch detailed audio analysis for a song.\"\"\"\n",
    "    url = f\"https://api.spotify.com/v1/audio-analysis/{song_id}\"\n",
    "    response = requests.get(url, headers=auth_header)\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def get_artist_details(artist_id, auth_header):\n",
    "    \"\"\"Fetch artist metadata including popularity.\"\"\"\n",
    "    url = f\"https://api.spotify.com/v1/artists/{artist_id}\"\n",
    "    response = requests.get(url, headers=auth_header)\n",
    "    return response.json()\n",
    "\n",
    "def download_song_preview(preview_url, song_id):\n",
    "    if not preview_url:\n",
    "        print(f\"No preview available for song ID {song_id}\")\n",
    "        return None\n",
    "    response = requests.get(preview_url)\n",
    "    if response.status_code == 200:\n",
    "        file_path = f\"previews/{song_id}.mp3\"\n",
    "        with open(file_path, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        return file_path\n",
    "    else:\n",
    "        print(f\"Failed to download preview for song ID {song_id}\")\n",
    "        return None\n",
    "\n",
    "## the seeds must be their ids\n",
    "def get_recommendations(token, seed_artists=None, seed_genres=None, seed_tracks=None):\n",
    "    url = \"https://api.spotify.com/v1/recommendations\"\n",
    "    headers = get_auth_header(token)\n",
    "    params = {\n",
    "        \"limit\": 20  # You can adjust this to fetch more or fewer tracks\n",
    "    }\n",
    "    if seed_artists:\n",
    "        params[\"seed_artists\"] = ','.join(seed_artists)\n",
    "    if seed_genres:\n",
    "        params[\"seed_genres\"] = ','.join(seed_genres)\n",
    "    if seed_tracks:\n",
    "        params[\"seed_tracks\"] = ','.join(seed_tracks)\n",
    "    \n",
    "    result = requests.get(url, headers=headers, params=params)\n",
    "    \n",
    "    try:\n",
    "        result.raise_for_status()\n",
    "        json_result = result.json()\n",
    "        return json_result['tracks']\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error decoding JSON response: {result.content}\")\n",
    "        return None\n",
    "    except requests.exceptions.HTTPError as err:\n",
    "        print(f\"HTTP error: {err}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'danceability': 0.819, 'energy': 0.674, 'key': 0, 'loudness': -3.145, 'mode': 1, 'speechiness': 0.0587, 'acousticness': 0.0849, 'instrumentalness': 0, 'liveness': 0.0667, 'valence': 0.682, 'tempo': 106.032, 'type': 'audio_features', 'id': '4Dr2hJ3EnVh2Aaot6fRwDO', 'uri': 'spotify:track:4Dr2hJ3EnVh2Aaot6fRwDO', 'track_href': 'https://api.spotify.com/v1/tracks/4Dr2hJ3EnVh2Aaot6fRwDO', 'analysis_url': 'https://api.spotify.com/v1/audio-analysis/4Dr2hJ3EnVh2Aaot6fRwDO', 'duration_ms': 217053, 'time_signature': 4}\n"
     ]
    }
   ],
   "source": [
    "def get_spotify_token():\n",
    "    auth_string = spotify_client_id + \":\" + spotify_client_secret\n",
    "    auth_bytes = auth_string.encode(\"utf-8\")\n",
    "    auth_base64 = str(base64.b64encode(auth_bytes), \"utf-8\")\n",
    "\n",
    "    url = \"https://accounts.spotify.com/api/token\"\n",
    "    headers = {\n",
    "        \"Authorization\" : \"Basic \" + auth_base64,\n",
    "        \"Content-Type\": \"application/x-www-form-urlencoded\"\n",
    "    }\n",
    "    data = {\"grant_type\": \"client_credentials\"}\n",
    "    result = requests.post(url, headers=headers, data=data)\n",
    "    json_result = json.loads(result.content)\n",
    "    token = json_result['access_token']\n",
    "    return token\n",
    "\n",
    "def search_song(song_name, artist_name, token):\n",
    "    query = f\"{song_name} artist:{artist_name}\"\n",
    "    url = \"https://api.spotify.com/v1/search\"\n",
    "    headers = get_auth_header(token)\n",
    "    params = {\n",
    "        \"q\": query,\n",
    "        \"type\": \"track\",\n",
    "        \"limit\": 1\n",
    "    }\n",
    "    response = requests.get(url, headers=headers, params=params).json()\n",
    "    tracks = response.get('tracks', {}).get('items', [])\n",
    "    return tracks[0]['id'] if tracks else None\n",
    "\n",
    "def get_song_audio_features(song_name, artist_name):\n",
    "    token = get_spotify_token()\n",
    "    song_id = search_song(song_name, artist_name, token)\n",
    "    if not song_id:\n",
    "        print(f\"Song '{song_name}' by '{artist_name}' not found.\")\n",
    "        return None\n",
    "    auth_header = get_auth_header(token)\n",
    "    audio_features = get_audio_features(song_id, auth_header)\n",
    "    return audio_features\n",
    "\n",
    "# Example usage\n",
    "song_name = \"Blueming\"\n",
    "artist_name = \"IU\"\n",
    "audio_features = get_song_audio_features(song_name, artist_name)\n",
    "print(audio_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spotify Trending Artists and Songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beyoncé 6vWDO969PvNqNYHIOW5v0m\n",
      "Benson Boone 22wbnEMDvgVIAGdFeek6ET\n",
      "Dua Lipa 6M2wZ9GZgrQXHCFfjv46we\n",
      "Tate McRae 45dkTj5sMRSjrmBSBeiHym\n",
      "Teddy Swims 33qOK5uJ8AR2xuQQAhHump\n",
      "Ariana Grande 66CXWjxzNUsdJxJ2JdwvnR\n",
      "Jack Harlow 2LIk90788K0zvyj2JJVwkJ\n",
      "SZA 7tYKF4w9nC0nq9CsPZTHyP\n",
      "Noah Kahan 2RQXRUsr4IW1f3mKyKsy4B\n",
      "Drake 3TVXtAsR1Inumwj472S9r4\n",
      "Sexyy Red 3DbwFQlvLxRSi2uX8mf81A\n",
      "SZA 7tYKF4w9nC0nq9CsPZTHyP\n",
      "The Weeknd 1Xyo4u8uXC1ZmMpatF05PJ\n",
      "JENNIE 250b0Wlc5Vk0CoUsaCY84M\n",
      "Lily-Rose Depp 1pBLC0qVRTB5zVMuteQ9jJ\n",
      "21 Savage 1URnnhqYAYcrqrcwql10ft\n",
      "Tyla 3SozjO3Lat463tQICI9LcE\n",
      "Doja Cat 5cj0lLjcoR7YOSnhnX0Po5\n",
      "Kali Uchis 1U1el3k54VvEUzo3ybLPlM\n",
      "Peso Pluma 12GqGscKJx3aE4t07u7eVZ\n",
      "SZA 7tYKF4w9nC0nq9CsPZTHyP\n",
      "Sabrina Carpenter 74KM79TiuVKeVCqs8QtB0B\n",
      "Taylor Swift 06HL4z0CvFAxyc27GXpf02\n",
      "Good Neighbours 52N3KGrTWDRhdQJrgBTofE\n",
      "Mitski 2uYWxilOVlUdk4oV9DvwqK\n",
      "Billie Eilish 6qqNVTkY8uBg9cP3Jd7DAH\n",
      "Selena Gomez 0C8ZW7ezQVs4URX5aX7Kqx\n",
      "Tate McRae 45dkTj5sMRSjrmBSBeiHym\n",
      "Kenya Grace 7uMDnSZyUYNBPLhPMNuaM2\n",
      "Doja Cat 5cj0lLjcoR7YOSnhnX0Po5\n",
      "Olivia Rodrigo 1McMsnEElThX1knmY4oliG\n",
      "Rema 46pWGuE3dSwY3bMMXGBvVS\n",
      "Selena Gomez 0C8ZW7ezQVs4URX5aX7Kqx\n",
      "KAROL G 790FomKkXshlbRYZFtlgla\n",
      "Tiësto 2o5jDhtHVPhrJdv3cEQ99Z\n",
      "Muni Long 7tjVFCxJdwT4NdrTmjyjQ6\n",
      "Dua Lipa 6M2wZ9GZgrQXHCFfjv46we\n",
      "Zach Bryan 40ZNYROS4zLfyyBSs2PGe2\n",
      "Kacey Musgraves 70kkdajctXSbqSMJbQO424\n",
      "Michael Marcagi 4j96cMcT8GRi11qbvo1cLQ\n",
      "Justin Timberlake 31TPClRtHm23RisEBtV3X7\n",
      "Myke Towers 7iK8PXO48WeuP03g8YR51W\n",
      "JID 6U3ybJ9UHNKEdsH7ktGBZ7\n",
      "21 Savage 1URnnhqYAYcrqrcwql10ft\n",
      "Baby Tate 3IJ21966TwNZI24MwZHMu4\n",
      "The Weeknd 1Xyo4u8uXC1ZmMpatF05PJ\n",
      "Playboi Carti 699OTQXzgjhIYAHMy9RyPD\n",
      "Madonna 6tbjWDEIzxoDsBA1FuhfPW\n",
      "Flo Milli 08PvCOlef4xdOr20jFSTPd\n",
      "Madison Beer 2kRfqPViCqYdSGhYSM9R0Q\n",
      "Kygo 23fqKkggKUBHNkbKtXEls4\n",
      "Ava Max 4npEfmQ6YuiwW1GpUmaq3F\n",
      "Jung Kook 6HaGTQPmzraVmaVxvz6EUc\n",
      "Latto 3MdXrJWsbVzdn6fe5JYkSQ\n",
      "Xavi 3Me35AWHCGqW4sZ7bWWJt1\n",
      "Miley Cyrus 5YGY8feqx7naU7z4HrwZM6\n",
      "Taylor Swift 06HL4z0CvFAxyc27GXpf02\n",
      "Dua Lipa 6M2wZ9GZgrQXHCFfjv46we\n",
      "Rich Amiri 2sF5nNXnrrsCPZlt8ZpyGd\n",
      "Travis Scott 0Y5tJX1MQlPlqiwlOH1tJY\n",
      "YG Marley 0n4Fao9kbjgM76RmVlfSwr\n",
      "Jung Kook 6HaGTQPmzraVmaVxvz6EUc\n",
      "David Kushner 33NVpKoXjItPwUJTMZIOiY\n",
      "Olivia Rodrigo 1McMsnEElThX1knmY4oliG\n"
     ]
    }
   ],
   "source": [
    "# Today's Top Hits: 37i9dQZF1DXcBWIGoYBM5M\n",
    "# Global Top 50: 37i9dQZEVXbMDoHDwVN2tF\n",
    "# United States Top 50: 37i9dQZEVXbLRQDuF5jeBp\n",
    "# Viral Hits: 37i9dQZF1DX2L0iB23Enbq\n",
    "\n",
    "def get_top_artists_from_playlist(playlist_id):\n",
    "    url = f\"https://api.spotify.com/v1/playlists/{playlist_id}/tracks\"\n",
    "    headers = get_auth_header(get_token())\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        tracks_data = response.json()\n",
    "        artists = []\n",
    "        for item in tracks_data['items']:\n",
    "            track_artists = item['track']['artists']\n",
    "            for artist in track_artists:\n",
    "                artists.append({\n",
    "                    \"name\": artist['name'],\n",
    "                    \"id\": artist['id']\n",
    "                })\n",
    "        return artists\n",
    "    else:\n",
    "        return \"Failed to fetch data from Spotify.\"\n",
    "\n",
    "def get_featured_playlists(country=None):\n",
    "    url = \"https://api.spotify.com/v1/browse/featured-playlists\"\n",
    "    headers = get_auth_header(get_token())\n",
    "    params = {\"country\": country} if country else {}\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    return response.json() \n",
    "\n",
    "def get_top_tracks_from_playlists(playlist_id):\n",
    "    url = f\"https://api.spotify.com/v1/playlists/{playlist_id}/tracks\"\n",
    "    headers = get_auth_header(get_token())\n",
    "    response = requests.get(url, headers=headers)\n",
    "    return response.json() \n",
    "\n",
    "featured_playlists_global = get_featured_playlists()\n",
    "featured_playlists_country = get_featured_playlists(country=\"US\")  \n",
    "\n",
    "playlist_id = \"37i9dQZF1DXcBWIGoYBM5M\"\n",
    "top_tracks = get_top_tracks_from_playlists(playlist_id)\n",
    "top_artists = get_top_artists_from_playlist(playlist_id)\n",
    "\n",
    "# print(json.dumps(featured_playlists_global, indent=2))\n",
    "# print(json.dumps(top_tracks, indent=2))\n",
    "for artist in top_artists:\n",
    "    print(artist['name'], artist['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Danceability: tempo, chroma_stft\n",
    "\n",
    "Energy: rms, spectral_centroid\n",
    "\n",
    "Instrumentalness: mfcc (Higher variance in MFCCs might indicate instrumental tracks)\n",
    "\n",
    "Loudness: rms\n",
    "\n",
    "Speechiness: zcr, mfcc (Patterns in MFCCs that indicate speech)\n",
    "\n",
    "Valence, Mood, Emotion: These are subjective and would require complex modeling with labeled data to infer accurately from the extracted features. Machine learning models trained on datasets where songs \n",
    "are labeled with these attributes can use these features as input to predict mood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Librosa API for low level audio analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mfcc': array([-29.733725 , 119.54214  , -39.87224  ,  39.308147 , -26.230635 ,\n",
      "        38.345    , -18.36275  ,  23.204859 , -11.205817 ,   7.416219 ,\n",
      "        -7.5335813,   6.9686804,  -7.1242647,   8.670854 ,   2.2209277,\n",
      "         3.7230785,   7.3588877,  -2.9295928,   4.087896 , -12.117584 ],\n",
      "      dtype=float32), 'chroma': array([0.5833566 , 0.41872796, 0.45743138, 0.42218533, 0.35972908,\n",
      "       0.2739078 , 0.28585538, 0.43279177, 0.332491  , 0.31129304,\n",
      "       0.3100566 , 0.42006618], dtype=float32), 'rms': 0.31068033, 'spectral_centroid': 3933.916709897445, 'zcr': 0.09486810132038927, 'tempo': 105.46875, 'beat_times': array([ 0.05804989,  0.74303855,  1.31192744,  1.88081633,  2.43809524,\n",
      "        2.99537415,  3.57587302,  4.13315193,  4.70204082,  5.24770975,\n",
      "        5.83981859,  6.40870748,  6.97759637,  7.53487528,  8.10376417,\n",
      "        8.67265306,  9.22993197,  9.79882086, 10.36770975, 10.93659864,\n",
      "       11.50548753, 12.06276644, 12.63165533, 13.20054422, 13.76943311,\n",
      "       14.32671202, 14.89560091, 15.4644898 , 16.03337868, 16.5906576 ,\n",
      "       17.15954649, 17.7168254 , 18.29732426, 18.85460317, 19.42349206,\n",
      "       19.98077098, 20.54965986, 21.11854875, 21.68743764, 22.24471655,\n",
      "       22.81360544, 23.38249433, 23.95138322, 24.52027211, 25.089161  ,\n",
      "       25.64643991, 26.2153288 , 26.78421769, 27.35310658, 27.91038549,\n",
      "       28.47927438, 29.04816327, 29.60544218])}\n"
     ]
    }
   ],
   "source": [
    "def extract_librosa_features_from_url(url):\n",
    "    # Fetch the audio file from the URL\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Failed to download audio file from {url}\")\n",
    "    \n",
    "    # Create a temporary file and manually manage it\n",
    "    temp_dir = tempfile.gettempdir()\n",
    "    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\", dir=temp_dir)\n",
    "    temp_file_path = temp_file.name\n",
    "    \n",
    "    try:\n",
    "        # Write the fetched content to the temp file and close it to release the lock\n",
    "        temp_file.write(response.content)\n",
    "        temp_file.close()\n",
    "        \n",
    "        # Now, load the audio file from the path\n",
    "        y, sr = librosa.load(temp_file_path, sr=None)  # Using sr=None to preserve the original sampling rate\n",
    "        \n",
    "        # Analyze the audio file\n",
    "        tempo, beat_frames = librosa.beat.beat_track(y=y, sr=sr)\n",
    "        rms = np.mean(librosa.feature.rms(y=y))\n",
    "        spectral_centroid = np.mean(librosa.feature.spectral_centroid(y=y, sr=sr))\n",
    "        zcr = np.mean(librosa.feature.zero_crossing_rate(y))\n",
    "        beat_times = librosa.frames_to_time(beat_frames, sr=sr)\n",
    "        \n",
    "        features = {\n",
    "            'mfcc': np.mean(librosa.feature.mfcc(y=y, sr=sr).T, axis=0),\n",
    "            'chroma': np.mean(librosa.feature.chroma_stft(y=y, sr=sr).T, axis=0),\n",
    "            'rms': rms,\n",
    "            'spectral_centroid': spectral_centroid,\n",
    "            'zcr': zcr,\n",
    "            'tempo': tempo,\n",
    "            'beat_times': beat_times\n",
    "        }\n",
    "    finally:\n",
    "        # Ensure the temporary file is removed after processing\n",
    "        os.remove(temp_file_path)\n",
    "\n",
    "    return features\n",
    "\n",
    "# Example usage\n",
    "url = 'https://cdns-preview-c.dzcdn.net/stream/c-cabe5eee524ba4c4708032cdc0bbe7fe-4.mp3'\n",
    "features = extract_librosa_features_from_url(url)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genius API to get song lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_and_clean_lyrics(artist_name, song_name):\n",
    "    # Normalize the song and artist names by removing common noise\n",
    "    song_name_clean = re.sub(r\"[\\(].*?[\\)]\", \"\", song_name).split(' - ', 1)[0]\n",
    "    artist_name_clean = re.sub(r\"[\\(].*?[\\)]\", \"\", artist_name)\n",
    "    \n",
    "    # Remove punctuation for better matching\n",
    "    song_name_clean = song_name_clean.translate(str.maketrans('', '', string.punctuation))\n",
    "    artist_name_clean = artist_name_clean.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    genius = lyricsgenius.Genius(genius_access_token, timeout=15)\n",
    "    try:\n",
    "        # Attempt to fetch the song lyrics\n",
    "        song = genius.search_song(song_name_clean, artist_name_clean)\n",
    "        if song and song.lyrics:\n",
    "            lyrics = song.lyrics\n",
    "            # Clean lyrics by removing sections like [Chorus] and any excess whitespace\n",
    "            lyrics_cleaned = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", lyrics).replace(\"\\n\", \" \").strip()\n",
    "            return lyrics_cleaned.lower()  # Convert to lowercase\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while fetching lyrics for {song_name}: {e}\")\n",
    "    \n",
    "    return \"Lyrics not found\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MusicBrainz API to get more song info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MusicBrainz API error: caused by: HTTP Error 404: Not Found\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "import musicbrainzngs\n",
    "\n",
    "musicbrainzngs.set_useragent(\"YourAppName\", \"0.1\", \"YourContactInfo\")  # Replace with your app's actual details\n",
    "\n",
    "\n",
    "def get_musicbrainz_artist_details(artist_name):\n",
    "    \"\"\"\n",
    "    Fetch artist details from MusicBrainz, including popularity (using score) and genres.\n",
    "    \"\"\"\n",
    "    result = musicbrainzngs.search_artists(artist=artist_name, limit=1)\n",
    "    if result['artist-list']:\n",
    "        artist = result['artist-list'][0]\n",
    "        # Popularity can be inferred from the 'score' field, though it's not a direct measure like Spotify's popularity index\n",
    "        popularity = artist.get('score')\n",
    "        # Genre information might be available in the 'tag-list' field\n",
    "        genres = [tag['name'] for tag in artist.get('tag-list', []) if int(tag.get('count', 0)) > 0]\n",
    "        return {'popularity': popularity, 'genres': genres}\n",
    "    return {}\n",
    "\n",
    "def get_musicbrainz_track_release_date(track_id):\n",
    "    \"\"\"\n",
    "    Fetch the release date of a track using MusicBrainz. Track ID here refers to MusicBrainz's recording ID.\n",
    "    \"\"\"\n",
    "    result = musicbrainzngs.get_recording_by_id(track_id, includes=[\"releases\"])\n",
    "    if 'recording' in result and 'release-list' in result['recording'] and result['recording']['release-list']:\n",
    "        release_date = result['recording']['release-list'][0].get('date')\n",
    "        return release_date\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_production_details(mbid):\n",
    "    \"\"\"\n",
    "    Fetch production details including producers and songwriters for a given MusicBrainz ID (MBID)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        result = musicbrainzngs.get_recording_by_id(mbid, includes=[\"artist-rels\", \"work-rels\"])\n",
    "        recording = result[\"recording\"]\n",
    "        details = {\"producers\": [], \"songwriters\": []}\n",
    "\n",
    "        if \"work-rels\" in recording:\n",
    "            for work_rel in recording[\"work-rels\"]:\n",
    "                if work_rel[\"type\"] == \"writer\":\n",
    "                    details[\"songwriters\"].append(work_rel[\"work\"][\"title\"])\n",
    "\n",
    "        if \"artist-rels\" in recording:\n",
    "            for artist_rel in recording[\"artist-rels\"]:\n",
    "                if artist_rel[\"type\"] == \"producer\":\n",
    "                    details[\"producers\"].append(artist_rel[\"artist\"][\"name\"])\n",
    "\n",
    "        return details\n",
    "    except musicbrainzngs.WebServiceError as exc:\n",
    "        print(f\"MusicBrainz API error: {exc}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to fetch production details: {e}\")\n",
    "    return {}\n",
    "\n",
    "# Example MBID\n",
    "mbid = \"1ff57329-7bf3-4ceb-9c0f-1e3acee5b832\"\n",
    "production_details = get_production_details(mbid)\n",
    "print(production_details)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main function for song info (Non spotify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for \"Lose Yourself\" by Eminem...\n",
      "Done.\n",
      "   song_id     song_title              song_album  artist featured_artists  \\\n",
      "0  1109731  Lose Yourself  Curtain Call: The Hits  Eminem             None   \n",
      "\n",
      "   duration                                       preview_path  \\\n",
      "0       326  https://cdns-preview-1.dzcdn.net/stream/c-1303...   \n",
      "\n",
      "                                              lyrics                 language  \\\n",
      "0  771 contributorstranslationsdeutschtürkçefranç...  [en:0.9999956617793786]   \n",
      "\n",
      "                                                mfcc  \\\n",
      "0  [-128.5885, 140.22298, -42.04305, 33.49153, 7....   \n",
      "\n",
      "                                              chroma       tempo  \\\n",
      "0  [0.5176217, 0.5379118, 0.6332326, 0.5261811, 0...  172.265625   \n",
      "\n",
      "                                          beat_times  \n",
      "0  [0.058049886621315196, 0.3831292517006803, 0.7...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "def combine_song_data(song_ids):\n",
    "    # Placeholder for the token retrieval and authentication methods\n",
    "    # Since the actual implementation depends on the specific API being used\n",
    "    # You would replace this with Deezer authentication if necessary\n",
    "    token = \"YOUR_DEEZER_TOKEN_HERE\"  # Placeholder token\n",
    "\n",
    "    songs_data = []\n",
    "    for song_id in song_ids:\n",
    "        # Get track details from Deezer\n",
    "        track_info = get_deezer_track_info(song_id)\n",
    "\n",
    "        # Since Deezer does not provide all the desired audio features directly,\n",
    "        # we need to use `librosa` for analyzing the audio and extracting features\n",
    "        preview_url = track_info.get(\"preview_url\")\n",
    "        if preview_url:\n",
    "            librosa_features = extract_librosa_features_from_url(preview_url)\n",
    "        else:\n",
    "            librosa_features = {}\n",
    "\n",
    "        # Lyrics and language detection\n",
    "        artist_name = track_info[\"artist\"]\n",
    "        song_name = track_info[\"title\"]\n",
    "        lyrics = fetch_and_clean_lyrics(artist_name, song_name)\n",
    "        language = langdetect.detect_langs(lyrics) if lyrics != \"Lyrics not found\" else None\n",
    "        # language detection here depends on the actual content and method used for detection\n",
    "        \n",
    "        # Combining data into a dictionary\n",
    "        song_data = {\n",
    "            \"song_id\": song_id,\n",
    "            \"song_title\": track_info.get(\"title\"),\n",
    "            \"song_album\": track_info.get(\"album\"),\n",
    "            \"artist\": track_info.get(\"artist\"),\n",
    "            \"featured_artists\": track_info.get(\"featured_artists\"),\n",
    "            \"duration\": track_info.get(\"duration\"),\n",
    "            # \"genre\": Not directly provided; might use LastFM or manual mapping\n",
    "            # \"available_markets\", \"release_date\", \"artist_popularity\": Not available from Deezer directly\n",
    "            \"preview_path\": preview_url,\n",
    "            \"lyrics\": lyrics,\n",
    "            'language': language,\n",
    "            **librosa_features  # This unpacks the mfcc, chroma, beat_times directly into the dictionary\n",
    "        }\n",
    "        \n",
    "        # Additional details like genre, popularity, etc., would need to be fetched from other APIs or manually filled\n",
    "        songs_data.append(song_data)\n",
    "    \n",
    "    # Creating a DataFrame from the combined data\n",
    "    df = pd.DataFrame(songs_data)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Example song IDs for Deezer; replace these with actual Deezer track IDs you want to analyze\n",
    "song_ids = [\"1109731\"]  # Example Deezer track IDs\n",
    "df = combine_song_data(song_ids)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main Function for Song Info (Spotify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for \"Mr Brightside\" by The Killers...\n",
      "Done.\n",
      "Searching for \"Blinding Lights\" by The Weeknd...\n",
      "Done.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'previews/7qiZfU4dY1lWllzX7mPBI3.mp3'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 56\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Example usage with dummy song IDs\u001b[39;00m\n\u001b[0;32m     53\u001b[0m song_ids \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3n3Ppam7vgaVa1iaRUc9Lp\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0VjIjW4GlUZAMYd2vXMi3b\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m7qiZfU4dY1lWllzX7mPBI3\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2XU0oxnq2qxCpomAAuJY8K\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m7qEHsqek33rTcFNT9PFqLf\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     54\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2Fxmhks0bxGSBdJ92vM42m\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m6v3KW9xbzN5yKLt9YKDYA2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3KkXRkHbMCARz0aVfEt68P\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m21jGcNKet2qwijlDFuPiPb\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     55\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2b8fOow8UzyDFAE27YhOZM\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3PfIrDoz19wz7qK7tYeu62\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Replace with actual song IDs\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mcombine_song_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43msong_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m df\n",
      "Cell \u001b[1;32mIn[12], line 11\u001b[0m, in \u001b[0;36mcombine_song_data\u001b[1;34m(song_ids)\u001b[0m\n\u001b[0;32m      9\u001b[0m audio_features \u001b[38;5;241m=\u001b[39m get_audio_features(song_id, auth_header)\n\u001b[0;32m     10\u001b[0m preview_url \u001b[38;5;241m=\u001b[39m song_details\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreview_url\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m preview_path \u001b[38;5;241m=\u001b[39m \u001b[43mdownload_song_preview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreview_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msong_id\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m preview_url \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Fetch artist details for the first artist\u001b[39;00m\n\u001b[0;32m     14\u001b[0m artist_details \u001b[38;5;241m=\u001b[39m get_artist_details(song_details[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124martists\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m], auth_header) \u001b[38;5;28;01mif\u001b[39;00m song_details[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124martists\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m {}\n",
      "Cell \u001b[1;32mIn[7], line 53\u001b[0m, in \u001b[0;36mdownload_song_preview\u001b[1;34m(preview_url, song_id)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[0;32m     52\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreviews/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msong_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.mp3\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 53\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m     54\u001b[0m         file\u001b[38;5;241m.\u001b[39mwrite(response\u001b[38;5;241m.\u001b[39mcontent)\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m file_path\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    277\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m     )\n\u001b[1;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'previews/7qiZfU4dY1lWllzX7mPBI3.mp3'"
     ]
    }
   ],
   "source": [
    "\n",
    "def combine_song_data(song_ids):\n",
    "    \n",
    "    token = get_token()\n",
    "    auth_header = get_auth_header(token)\n",
    "    \n",
    "    songs_data = []\n",
    "    for song_id in song_ids:\n",
    "        song_details = get_song_details(song_id, auth_header)\n",
    "        audio_features = get_audio_features(song_id, auth_header)\n",
    "        preview_url = song_details.get(\"preview_url\")\n",
    "        preview_path = download_song_preview(preview_url, song_id) if preview_url else None\n",
    "\n",
    "        # Fetch artist details for the first artist\n",
    "        artist_details = get_artist_details(song_details[\"artists\"][0][\"id\"], auth_header) if song_details[\"artists\"] else {}\n",
    "\n",
    "        artist_name = song_details[\"artists\"][0][\"name\"] if song_details[\"artists\"] else \"\"\n",
    "        song_name = song_details.get(\"name\", \"\")\n",
    "        featured_artists = \", \".join([artist['name'] for artist in song_details['artists'][1:]]) if len(song_details['artists']) > 1 else None\n",
    "        lyrics = fetch_and_clean_lyrics(artist_name, song_name)\n",
    "        language = langdetect.detect_langs(lyrics) if lyrics != \"Lyrics not found\" else None\n",
    "        librosa_features = extract_librosa_features(preview_path) if preview_path else {}\n",
    "\n",
    "        combined_data = {\n",
    "            \"song_id\": song_id,\n",
    "            \"name\": song_details.get(\"name\"),\n",
    "            \"album\": song_details[\"album\"][\"name\"] if song_details.get(\"album\") else None,\n",
    "            \"artist\": song_details[\"artists\"][0][\"name\"] if song_details[\"artists\"] else None,\n",
    "            \"featured_artists\": featured_artists,\n",
    "            \"genre\": artist_details.get(\"genres\")[0] if artist_details.get(\"genres\") else None,\n",
    "            \"available_markets\": len(song_details[\"available_markets\"]) if song_details.get(\"available_markets\") else 0,\n",
    "            \"release_date\": song_details[\"album\"][\"release_date\"] if song_details.get(\"album\") else None,\n",
    "            \"artist_popularity\": artist_details.get(\"popularity\"),\n",
    "            \"duration_ms\": song_details.get(\"duration_ms\"),\n",
    "            \"danceability\": audio_features.get(\"danceability\"),\n",
    "            \"energy\": audio_features.get(\"energy\"),\n",
    "            \"instrumentalness\": audio_features.get(\"instrumentalness\"),\n",
    "            \"loudness\": audio_features.get(\"loudness\"),\n",
    "            \"speechiness\": audio_features.get(\"speechiness\"),\n",
    "            \"tempo\": audio_features.get(\"tempo\"),\n",
    "            \"time_signature\": audio_features.get(\"time_signature\"),\n",
    "            \"valence\": audio_features.get(\"valence\"),\n",
    "            \"preview_path\": preview_path,\n",
    "            \"lyrics\": lyrics,\n",
    "            \"language\": language,\n",
    "            **librosa_features\n",
    "        }\n",
    "        songs_data.append(combined_data)\n",
    "    \n",
    "    df = pd.DataFrame(songs_data)\n",
    "    return df\n",
    "\n",
    "# Example usage with dummy song IDs\n",
    "song_ids = [\"3n3Ppam7vgaVa1iaRUc9Lp\", \"0VjIjW4GlUZAMYd2vXMi3b\", '7qiZfU4dY1lWllzX7mPBI3', '2XU0oxnq2qxCpomAAuJY8K', '7qEHsqek33rTcFNT9PFqLf',\n",
    "            '2Fxmhks0bxGSBdJ92vM42m', '6v3KW9xbzN5yKLt9YKDYA2', '3KkXRkHbMCARz0aVfEt68P', '21jGcNKet2qwijlDFuPiPb', \n",
    "            '2b8fOow8UzyDFAE27YhOZM', '3PfIrDoz19wz7qK7tYeu62']  # Replace with actual song IDs\n",
    "df = combine_song_data(song_ids)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] []\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def fetch_songwriter_producer_musicbrainz(artist_name, song_name):\n",
    "    base_url = \"http://musicbrainz.org/ws/2/recording/\"\n",
    "    params = {\n",
    "        \"query\": f'recording:\"{song_name}\" AND artist:\"{artist_name}\"',\n",
    "        \"fmt\": \"json\",\n",
    "        \"inc\": \"artist-rels work-rels\"\n",
    "    }\n",
    "    response = requests.get(base_url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return data\n",
    "    else:\n",
    "        print(\"Failed to fetch data from MusicBrainz\")\n",
    "        return {}\n",
    "    \n",
    "def parse_songwriter_producer(data):\n",
    "    songwriters = []\n",
    "    producers = []\n",
    "    works = []\n",
    "\n",
    "    if 'recordings' in data:\n",
    "        for recording in data['recordings']:\n",
    "            if 'relations' in recording:\n",
    "                # Fetching work relations\n",
    "                for relation in recording['relations']:\n",
    "                    if relation['type'] == 'work':\n",
    "                        works.append(relation['work']['id'])\n",
    "    \n",
    "    # Now we have work IDs, we can fetch details for each work\n",
    "    for work_id in works:\n",
    "        work_data = fetch_work_details(work_id)\n",
    "        if 'relations' in work_data:\n",
    "            for relation in work_data['relations']:\n",
    "                if relation['type'] == 'lyricist' or relation['type'] == 'composer':\n",
    "                    songwriters.append(relation['artist']['name'])\n",
    "                if relation['type'] == 'producer':\n",
    "                    producers.append(relation['artist']['name'])\n",
    "    \n",
    "    return songwriters, producers\n",
    "\n",
    "def fetch_work_details(work_id):\n",
    "    base_url = f\"http://musicbrainz.org/ws/2/work/{work_id}\"\n",
    "    params = {\n",
    "        \"fmt\": \"json\",\n",
    "        \"inc\": \"artist-rels\"\n",
    "    }\n",
    "    response = requests.get(base_url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Failed to fetch work details for work ID {work_id}\")\n",
    "        return {}\n",
    "    \n",
    "artist_name = \"Ed Sheeran\"\n",
    "song_name = \"Shape of you\"\n",
    "\n",
    "data = fetch_songwriter_producer_musicbrainz(artist_name, song_name)\n",
    "songwriters, producers = parse_songwriter_producer(data)\n",
    "print(songwriters, producers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://genius.com/Ed-sheeran-shape-of-you-lyrics\n",
      "{'Produced by': 'Not found', 'Written by': 'Not found'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def get_song_url_genius(access_token, artist_name, song_name):\n",
    "    base_url = \"https://api.genius.com/search\"\n",
    "    headers = {\"Authorization\": f\"Bearer {access_token}\"}\n",
    "    params = {\"q\": f\"{artist_name} {song_name}\"}\n",
    "    response = requests.get(base_url, headers=headers, params=params)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        hits = data['response']['hits']\n",
    "        for hit in hits:\n",
    "            if artist_name.lower() in hit['result']['primary_artist']['name'].lower():\n",
    "                return hit['result']['url']\n",
    "        return \"URL not found.\"\n",
    "    else:\n",
    "        return \"Failed to fetch data from Genius.\"\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scrape_song_info_genius(song_url):\n",
    "    response = requests.get(song_url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Assuming 'song_body-lyrics' was a placeholder and the correct class names need to be found\n",
    "        # Update the class names according to the current page structure\n",
    "        song_info = soup.find('div', class_='correct-class-for-song-info')\n",
    "        \n",
    "        # Assuming the layout for 'Produced by' and 'Written by' sections can be found with updated selectors\n",
    "        produced_by = 'Not found'\n",
    "        written_by = 'Not found'\n",
    "        \n",
    "        if song_info:\n",
    "            produced_by_section = song_info.find('div', text='Produced by')\n",
    "            if produced_by_section:\n",
    "                produced_by = produced_by_section.find_next_sibling('a').text\n",
    "                \n",
    "            written_by_section = song_info.find('div', text='Written by')\n",
    "            if written_by_section:\n",
    "                written_by = written_by_section.find_next_sibling('a').text\n",
    "                \n",
    "        return {\n",
    "            'Produced by': produced_by,\n",
    "            'Written by': written_by\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            'Produced by': 'Failed to fetch data',\n",
    "            'Written by': 'Failed to fetch data'\n",
    "        }\n",
    "\n",
    "\n",
    "url = get_song_url_genius(genius_access_token, \"Ed Sheeran\", \"Shape of you\")\n",
    "print(url)\n",
    "print(scrape_song_info_genius(url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last.FM API for user data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'http://ws.audioscrobbler.com/2.0/'\n",
    "\n",
    "def lastfm_get(payload):\n",
    "    headers = {'user-agent': 'DataCollectorBot'}\n",
    "    payload['api_key'] = lastfm_api_key\n",
    "    payload['format'] = 'json'\n",
    "    response = requests.get(base_url, headers=headers, params=payload)\n",
    "    return response.json()\n",
    "\n",
    "# Function for each endpoint\n",
    "def get_user_info(user):\n",
    "    payload = {'method': 'user.getinfo', 'user': user}\n",
    "    return lastfm_get(payload)\n",
    "\n",
    "def get_loved_tracks(user):\n",
    "    payload = {'method': 'user.getlovedtracks', 'user': user}\n",
    "    return lastfm_get(payload)\n",
    "\n",
    "def get_recent_tracks(user):\n",
    "    payload = {'method': 'user.getrecenttracks', 'user': user}\n",
    "    return lastfm_get(payload)\n",
    "\n",
    "def get_top_albums(user):\n",
    "    payload = {'method': 'user.gettopalbums', 'user': user}\n",
    "    return lastfm_get(payload)\n",
    "\n",
    "def get_top_artists(user):\n",
    "    payload = {'method': 'user.gettopartists', 'user': user}\n",
    "    return lastfm_get(payload)\n",
    "\n",
    "def get_top_tags(user):\n",
    "    payload = {'method': 'user.gettoptags', 'user': user}\n",
    "    return lastfm_get(payload)\n",
    "\n",
    "def get_top_tracks(user):\n",
    "    payload = {'method': 'user.gettoptracks', 'user': user}\n",
    "    return lastfm_get(payload)\n",
    "\n",
    "def get_weekly_album_chart(user):\n",
    "    payload = {'method': 'user.getweeklyalbumchart', 'user': user}\n",
    "    return lastfm_get(payload)\n",
    "\n",
    "def get_weekly_artist_chart(user):\n",
    "    payload = {'method': 'user.getweeklyartistchart', 'user': user}\n",
    "    return lastfm_get(payload)\n",
    "\n",
    "def get_weekly_chart_list(user):\n",
    "    payload = {'method': 'user.getweeklychartlist', 'user': user}\n",
    "    return lastfm_get(payload)\n",
    "\n",
    "def get_weekly_track_chart(user):\n",
    "    payload = {'method': 'user.getweeklytrackchart', 'user': user}\n",
    "    return lastfm_get(payload)\n",
    "\n",
    "\n",
    "user_data = {\n",
    "    'info': get_user_info('Bans77'),\n",
    "    'loved_tracks': get_loved_tracks('Bans77'),\n",
    "    'recent_tracks': get_recent_tracks('Bans77'),\n",
    "    'top_albums': get_top_albums('Bans77'),\n",
    "    'top_artists': get_top_artists('Bans77'),\n",
    "    'top_tags': get_top_tags('Bans77'),\n",
    "    'top_tracks': get_top_tracks('Bans77'),\n",
    "    'weekly_album_chart': get_weekly_album_chart('Bans77'),\n",
    "    'weekly_artist_chart': get_weekly_artist_chart('Bans77'),\n",
    "    'weekly_chart_list': get_weekly_chart_list('Bans77'),\n",
    "    'weekly_track_chart': get_weekly_track_chart('Bans77')\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user': {'name': 'Bans77',\n",
       "  'age': '0',\n",
       "  'subscriber': '1',\n",
       "  'realname': 'Dan',\n",
       "  'bootstrap': '0',\n",
       "  'playcount': '85007',\n",
       "  'artist_count': '4597',\n",
       "  'playlists': '0',\n",
       "  'track_count': '12514',\n",
       "  'album_count': '7806',\n",
       "  'image': [{'size': 'small',\n",
       "    '#text': 'https://lastfm.freetls.fastly.net/i/u/34s/5a6d8929cab975388c0ae86e4af52404.png'},\n",
       "   {'size': 'medium',\n",
       "    '#text': 'https://lastfm.freetls.fastly.net/i/u/64s/5a6d8929cab975388c0ae86e4af52404.png'},\n",
       "   {'size': 'large',\n",
       "    '#text': 'https://lastfm.freetls.fastly.net/i/u/174s/5a6d8929cab975388c0ae86e4af52404.png'},\n",
       "   {'size': 'extralarge',\n",
       "    '#text': 'https://lastfm.freetls.fastly.net/i/u/300x300/5a6d8929cab975388c0ae86e4af52404.png'}],\n",
       "  'registered': {'unixtime': '1642497274', '#text': 1642497274},\n",
       "  'country': 'South Africa',\n",
       "  'gender': 'n',\n",
       "  'url': 'https://www.last.fm/user/Bans77',\n",
       "  'type': 'subscriber'}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data['info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cubbie - Endlos is currently playing or missing timestamp data.\n",
      "Clairo - Bags listened to at 19 Feb 2024, 05:21 (timestamp: 1708320087)\n",
      "Isabel LaRosa - Older listened to at 19 Feb 2024, 05:04 (timestamp: 1708319068)\n",
      "Olivia Rodrigo - Can’t Catch Me Now - from The Hunger Games: The Ballad of Songbirds & Snakes listened to at 19 Feb 2024, 05:01 (timestamp: 1708318864)\n",
      "Dilated Peoples - Who's Who listened to at 19 Feb 2024, 04:56 (timestamp: 1708318594)\n",
      "Aero Chord - Surface listened to at 19 Feb 2024, 04:52 (timestamp: 1708318341)\n",
      "Aero Chord - Break Them listened to at 19 Feb 2024, 04:48 (timestamp: 1708318083)\n",
      "Bullet for My Valentine - Hand of Blood listened to at 19 Feb 2024, 04:44 (timestamp: 1708317876)\n",
      "The Crystal Method - Born Too Slow listened to at 19 Feb 2024, 04:42 (timestamp: 1708317752)\n",
      "The Prodigy - You'll Be Under My Wheels listened to at 19 Feb 2024, 04:38 (timestamp: 1708317515)\n",
      "T.I. - 24's listened to at 19 Feb 2024, 04:34 (timestamp: 1708317255)\n",
      "P$C - Do Ya Thing (feat. Young Dro) listened to at 19 Feb 2024, 04:29 (timestamp: 1708316991)\n",
      "Sofi Tukker - Swing listened to at 19 Feb 2024, 04:26 (timestamp: 1708316798)\n",
      "Muse - Butterflies & Hurricanes listened to at 19 Feb 2024, 04:21 (timestamp: 1708316498)\n",
      "Rebūke - Digital Dream listened to at 19 Feb 2024, 04:18 (timestamp: 1708316298)\n",
      "Billy Talent - Fallen Leaves listened to at 19 Feb 2024, 04:14 (timestamp: 1708316043)\n",
      "52Blue - Blick Über Die Stadt listened to at 19 Feb 2024, 04:11 (timestamp: 1708315876)\n",
      "Kidd Azzurra - Sie liebt mich nicht listened to at 19 Feb 2024, 04:09 (timestamp: 1708315770)\n",
      "забей, лерочка - Lie listened to at 19 Feb 2024, 03:59 (timestamp: 1708315194)\n",
      "Chernikovskaya Hata - Последняя осень listened to at 19 Feb 2024, 03:55 (timestamp: 1708314954)\n",
      "Три дня дождя, SHENA? - Отражения listened to at 19 Feb 2024, 03:51 (timestamp: 1708314712)\n",
      "Три Дня Дождя - Отражения listened to at 19 Feb 2024, 03:51 (timestamp: 1708314710)\n",
      "Три Дня Дождя - За край listened to at 19 Feb 2024, 03:49 (timestamp: 1708314579)\n",
      "Три Дня Дождя - За край listened to at 19 Feb 2024, 03:49 (timestamp: 1708314577)\n",
      "vioria - Я просто хочу додому listened to at 19 Feb 2024, 03:47 (timestamp: 1708314440)\n",
      "vioria - Я просто хочу додому listened to at 19 Feb 2024, 03:47 (timestamp: 1708314436)\n",
      "vioria - хвора на любов listened to at 19 Feb 2024, 03:45 (timestamp: 1708314307)\n",
      "vioria - хвора на любов listened to at 19 Feb 2024, 03:45 (timestamp: 1708314301)\n",
      "vioria - хвора на любов listened to at 19 Feb 2024, 03:42 (timestamp: 1708314170)\n",
      "vioria - хвора на любов listened to at 19 Feb 2024, 03:42 (timestamp: 1708314168)\n",
      "vioria - хвора на любов listened to at 19 Feb 2024, 03:40 (timestamp: 1708314024)\n",
      "vioria - хвора на любов listened to at 19 Feb 2024, 03:40 (timestamp: 1708314021)\n",
      "Lil Eyes - ohne dich listened to at 18 Feb 2024, 18:55 (timestamp: 1708282521)\n",
      "Matze - herzen listened to at 18 Feb 2024, 18:52 (timestamp: 1708282344)\n",
      "Capital Bra - Berlin lebt listened to at 18 Feb 2024, 18:18 (timestamp: 1708280289)\n",
      "Capital Bra - Olé Olé listened to at 18 Feb 2024, 18:06 (timestamp: 1708279611)\n",
      "Capital Bra, RAF Camora, Joshi Mizu - Olé Olé listened to at 18 Feb 2024, 18:04 (timestamp: 1708279459)\n",
      "BEVN - Sex listened to at 18 Feb 2024, 18:01 (timestamp: 1708279266)\n",
      "Nugat - Killshot listened to at 18 Feb 2024, 18:01 (timestamp: 1708279266)\n",
      "BEVN - Sex listened to at 18 Feb 2024, 17:58 (timestamp: 1708279122)\n",
      "Kidd Azzurra - Sie liebt mich nicht listened to at 18 Feb 2024, 17:55 (timestamp: 1708278958)\n",
      "Katlix - 115 Tage listened to at 18 Feb 2024, 15:25 (timestamp: 1708269944)\n",
      "Maaks - Farblose Welt listened to at 18 Feb 2024, 15:24 (timestamp: 1708269844)\n",
      "Nugat - Killshot listened to at 18 Feb 2024, 15:22 (timestamp: 1708269731)\n",
      "Nugat - Killshot listened to at 18 Feb 2024, 15:20 (timestamp: 1708269609)\n",
      "BEVN - Sex listened to at 18 Feb 2024, 15:20 (timestamp: 1708269604)\n",
      "BEVN - Sex listened to at 18 Feb 2024, 15:17 (timestamp: 1708269473)\n",
      "Dondon - Problemboy listened to at 18 Feb 2024, 15:17 (timestamp: 1708269459)\n",
      "Dondon, YUNGMON - Problemboy listened to at 18 Feb 2024, 15:15 (timestamp: 1708269342)\n",
      "Kidd Azzurra - Sie liebt mich nicht listened to at 18 Feb 2024, 15:14 (timestamp: 1708269249)\n",
      "Kidd Azzurra - Sie liebt mich nicht listened to at 18 Feb 2024, 15:13 (timestamp: 1708269209)\n"
     ]
    }
   ],
   "source": [
    "recent_tracks = user_data['recent_tracks']\n",
    "\n",
    "# Print each track with its listen timestamp\n",
    "for track in recent_tracks['recenttracks']['track']:\n",
    "    track_name = track['name']\n",
    "    artist_name = track['artist']['#text']\n",
    "    # Check if the 'date' key exists\n",
    "    if 'date' in track:\n",
    "        listen_time = track['date']['#text']  # Human-readable timestamp\n",
    "        listen_timestamp = track['date']['uts']  # Unix timestamp\n",
    "        print(f\"{artist_name} - {track_name} listened to at {listen_time} (timestamp: {listen_timestamp})\")\n",
    "    else:\n",
    "        # If 'date' key does not exist, it might be currently playing\n",
    "        print(f\"{artist_name} - {track_name} is currently playing or missing timestamp data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 21 friends so far...\n",
      "Collected 69 friends so far...\n",
      "Collected 117 friends so far...\n",
      "Collected 133 friends so far...\n",
      "Collected 181 friends so far...\n",
      "Collected 190 friends so far...\n",
      "Collected 239 friends so far...\n",
      "Collected 259 friends so far...\n",
      "Collected 309 friends so far...\n",
      "Collected 359 friends so far...\n",
      "Collected 359 friends so far...\n",
      "Collected 382 friends so far...\n",
      "Collected 394 friends so far...\n",
      "Collected 395 friends so far...\n",
      "Collected 396 friends so far...\n",
      "Collected 446 friends so far...\n",
      "Collected 446 friends so far...\n",
      "Collected 494 friends so far...\n",
      "Collected 544 friends so far...\n",
      "Collected 547 friends so far...\n",
      "Collected 577 friends so far...\n",
      "Collected 609 friends so far...\n",
      "Collected 632 friends so far...\n",
      "Collected 640 friends so far...\n",
      "Collected 689 friends so far...\n",
      "Collected 738 friends so far...\n",
      "Collected 783 friends so far...\n",
      "Collected 828 friends so far...\n",
      "Collected 876 friends so far...\n",
      "Collected 880 friends so far...\n",
      "Collected 925 friends so far...\n",
      "Collected 968 friends so far...\n",
      "Error fetching data for user NickGrassType: no such page\n",
      "Collected 1005 friends so far...\n",
      "Collected 1016 friends so far...\n",
      "Collected 1022 friends so far...\n",
      "Collected 1072 friends so far...\n",
      "Error fetching data for user K0ntzl3r: no such page\n",
      "Collected 1105 friends so far...\n",
      "Error fetching data for user madame-disaster: no such page\n",
      "Collected 1153 friends so far...\n",
      "Collected 1198 friends so far...\n",
      "Collected 1213 friends so far...\n",
      "Collected 1221 friends so far...\n",
      "Collected 1223 friends so far...\n",
      "Collected 1226 friends so far...\n",
      "Collected 1252 friends so far...\n",
      "Collected 1302 friends so far...\n",
      "Collected 1351 friends so far...\n",
      "Collected 1383 friends so far...\n",
      "Collected 1431 friends so far...\n",
      "Collected 1474 friends so far...\n",
      "Collected 1522 friends so far...\n",
      "Collected 1550 friends so far...\n",
      "Collected 1587 friends so far...\n",
      "Collected 1598 friends so far...\n",
      "Collected 1642 friends so far...\n",
      "Collected 1646 friends so far...\n",
      "Collected 1670 friends so far...\n",
      "Collected 1715 friends so far...\n",
      "Collected 1761 friends so far...\n",
      "Collected 1786 friends so far...\n",
      "Collected 1804 friends so far...\n",
      "Error fetching data for user ScrobbleAddict: no such page\n",
      "Error fetching data for user designertaytay: no such page\n",
      "Collected 1847 friends so far...\n",
      "Error fetching data for user AgaAagGaa: no such page\n",
      "Collected 1890 friends so far...\n",
      "Collected 1914 friends so far...\n",
      "Collected 1962 friends so far...\n",
      "Collected 2007 friends so far...\n",
      "Collected 2029 friends so far...\n",
      "Collected 2077 friends so far...\n",
      "Collected 2119 friends so far...\n",
      "Collected 2140 friends so far...\n",
      "Collected 2183 friends so far...\n",
      "Collected 2201 friends so far...\n",
      "Collected 2205 friends so far...\n",
      "Error fetching data for user fletcherrenn: no such page\n",
      "Collected 2217 friends so far...\n",
      "Collected 2261 friends so far...\n",
      "Collected 2311 friends so far...\n",
      "Collected 2356 friends so far...\n",
      "Collected 2374 friends so far...\n",
      "Collected 2420 friends so far...\n",
      "Error fetching data for user flaxhorizon: no such page\n",
      "Collected 2444 friends so far...\n",
      "Collected 2490 friends so far...\n",
      "Collected 2525 friends so far...\n",
      "Error fetching data for user AutisticRaptor: no such page\n",
      "Collected 2565 friends so far...\n",
      "Error fetching data for user GarionOrbX: no such page\n",
      "Collected 2583 friends so far...\n",
      "Collected 2585 friends so far...\n",
      "Collected 2593 friends so far...\n",
      "Error fetching data for user basstzarrun_: no such page\n",
      "Error fetching data for user AadPiraat: no such page\n",
      "Error fetching data for user syrupsndwitches: no such page\n",
      "Collected 2615 friends so far...\n",
      "Collected 2633 friends so far...\n",
      "Collected 2677 friends so far...\n",
      "Collected 2725 friends so far...\n",
      "Collected 2730 friends so far...\n",
      "Collected 2756 friends so far...\n",
      "Collected 2793 friends so far...\n",
      "Collected 2836 friends so far...\n",
      "Collected 2846 friends so far...\n",
      "Collected 2895 friends so far...\n",
      "Collected 2912 friends so far...\n",
      "Collected 2954 friends so far...\n",
      "Collected 3002 friends so far...\n",
      "Collected 3042 friends so far...\n",
      "Collected 3086 friends so far...\n",
      "Collected 3112 friends so far...\n",
      "Collected 3119 friends so far...\n",
      "Collected 3140 friends so far...\n",
      "Collected 3183 friends so far...\n",
      "Collected 3185 friends so far...\n",
      "Collected 3233 friends so far...\n",
      "Collected 3275 friends so far...\n",
      "Error fetching data for user Ace_potat: no such page\n",
      "Collected 3301 friends so far...\n",
      "Collected 3302 friends so far...\n",
      "Error fetching data for user Lyesolution666: no such page\n",
      "Collected 3311 friends so far...\n",
      "Collected 3312 friends so far...\n",
      "Collected 3320 friends so far...\n",
      "Collected 3320 friends so far...\n",
      "Collected 3334 friends so far...\n",
      "Error fetching data for user Vaenderby: no such page\n",
      "Error fetching data for user DuckCut: no such page\n",
      "Collected 3359 friends so far...\n",
      "Collected 3359 friends so far...\n",
      "Collected 3402 friends so far...\n",
      "Collected 3445 friends so far...\n",
      "Collected 3478 friends so far...\n",
      "Collected 3528 friends so far...\n",
      "Collected 3575 friends so far...\n",
      "Collected 3623 friends so far...\n",
      "Error fetching data for user frommyknees: no such page\n",
      "Collected 3673 friends so far...\n",
      "Collected 3674 friends so far...\n",
      "Collected 3710 friends so far...\n",
      "Collected 3741 friends so far...\n",
      "Collected 3786 friends so far...\n",
      "Collected 3832 friends so far...\n",
      "Collected 3875 friends so far...\n",
      "Collected 3922 friends so far...\n",
      "Collected 3923 friends so far...\n",
      "Collected 3966 friends so far...\n",
      "Collected 4003 friends so far...\n",
      "Collected 4004 friends so far...\n",
      "Collected 4022 friends so far...\n",
      "Error fetching data for user carolineanny: no such page\n",
      "Collected 4070 friends so far...\n",
      "Collected 4111 friends so far...\n",
      "Collected 4157 friends so far...\n",
      "Collected 4201 friends so far...\n",
      "Collected 4209 friends so far...\n",
      "Error fetching data for user barnesbish: no such page\n",
      "Collected 4225 friends so far...\n",
      "Collected 4269 friends so far...\n",
      "Collected 4296 friends so far...\n",
      "Collected 4343 friends so far...\n",
      "Collected 4368 friends so far...\n",
      "Collected 4417 friends so far...\n",
      "Error fetching data for user gonesko: no such page\n",
      "Collected 4418 friends so far...\n",
      "Collected 4455 friends so far...\n",
      "Collected 4497 friends so far...\n",
      "Collected 4528 friends so far...\n",
      "Error fetching data for user evanx8: no such page\n",
      "Collected 4574 friends so far...\n",
      "Error fetching data for user richertiser: no such page\n",
      "Collected 4575 friends so far...\n",
      "Collected 4621 friends so far...\n",
      "Collected 4649 friends so far...\n",
      "Collected 4650 friends so far...\n",
      "Error fetching data for user LeytonB: no such page\n",
      "Collected 4684 friends so far...\n",
      "Collected 4734 friends so far...\n",
      "Error fetching data for user cmkarizma: no such page\n",
      "Collected 4780 friends so far...\n",
      "Collected 4782 friends so far...\n",
      "Collected 4826 friends so far...\n",
      "Collected 4829 friends so far...\n",
      "Collected 4876 friends so far...\n",
      "Collected 4911 friends so far...\n",
      "Error fetching data for user itargetmoon: no such page\n",
      "Collected 4950 friends so far...\n",
      "Collected 4986 friends so far...\n",
      "Collected 5000 friends so far...\n",
      "Collected 5000 unique friends.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Serletti243',\n",
       " 'Moldyreeds',\n",
       " 'irrelevantstfu1',\n",
       " 'Kemikal89',\n",
       " 'stargazer96',\n",
       " 'Ev0308',\n",
       " 'kaychill',\n",
       " 'gabcoelhomusic',\n",
       " 'Sotttacqua',\n",
       " 'Genoverse',\n",
       " 'AltheaEcho',\n",
       " 'fm-bot',\n",
       " 'chuubot',\n",
       " 'gowon_',\n",
       " 'majkel2137',\n",
       " 'Oomstompie55',\n",
       " 'e6n',\n",
       " 'dmartinsid',\n",
       " 'grimgxre',\n",
       " 'rkhelaa_',\n",
       " 'xleepyy',\n",
       " 'QuidProBro_',\n",
       " 'DEViANCE_Rus_3d',\n",
       " 'cutiepatootie0',\n",
       " 'thedadbrains',\n",
       " 'carbon1k',\n",
       " 'skye410',\n",
       " 'sapplerx',\n",
       " 'thicc_grandma',\n",
       " 'blo0dycigarette',\n",
       " 'foreverhere',\n",
       " 'NickGrassType',\n",
       " 'StupidGenius',\n",
       " 'Jonnas94',\n",
       " 'Gimlocke',\n",
       " 'domi_mcrmy',\n",
       " 'K0ntzl3r',\n",
       " 'Zenpyrean',\n",
       " 'madame-disaster',\n",
       " 'StrangePooP',\n",
       " 'mclarge',\n",
       " 'frozendilemma',\n",
       " 'nesscurse',\n",
       " 'straightheart',\n",
       " 'Starsitsuki',\n",
       " 'SonofSnow',\n",
       " 'VatoJack',\n",
       " 'EtherealBangerz',\n",
       " 'rockpotatoe',\n",
       " 'Butterednuts',\n",
       " 'Bobbyatlast',\n",
       " 'YeezusSuburbia',\n",
       " 'theranton',\n",
       " 'Puffyjacket-',\n",
       " 'Metatable',\n",
       " '-_misery_-',\n",
       " 'Wakemeupinside1',\n",
       " 'mrwhite5',\n",
       " 'InterdependentM',\n",
       " 'Willgregg10',\n",
       " 'necrojunk',\n",
       " 'Resplash',\n",
       " 'ScrobbleAddict',\n",
       " 'designertaytay',\n",
       " 'AreYouTyler',\n",
       " 'AgaAagGaa',\n",
       " 'WarriorJones',\n",
       " 'CLIKIVE',\n",
       " 'allegrotree',\n",
       " 'bleueyedevil67',\n",
       " 'Swo0pie',\n",
       " 'omart56melomano',\n",
       " 'lyraaaaaa',\n",
       " 'kauanbtw',\n",
       " 'eldorado_1974',\n",
       " 'spacemell',\n",
       " 'stellarnt',\n",
       " 'fletcherrenn',\n",
       " 'Earthmovering',\n",
       " 'eggygregg',\n",
       " 'Karma_Idiot',\n",
       " 'thesaltysalute',\n",
       " 'Didatic',\n",
       " 'Weltschmerzq',\n",
       " 'flaxhorizon',\n",
       " 'generallyinsan3',\n",
       " 'Georg_Bonk',\n",
       " 'chl01k',\n",
       " 'AutisticRaptor',\n",
       " 'Flower1st',\n",
       " 'GarionOrbX',\n",
       " 'sksdeux',\n",
       " 'Mermaidtwinkle',\n",
       " 'the-dead-cow',\n",
       " 'basstzarrun_',\n",
       " 'AadPiraat',\n",
       " 'syrupsndwitches',\n",
       " 'ruszaj',\n",
       " 'drinkybirdswag',\n",
       " 'saultratts',\n",
       " 'j_migue',\n",
       " 'd4g_',\n",
       " 'Konofart',\n",
       " 'maliksgalaxy',\n",
       " 'psycholucy',\n",
       " 'AviRB',\n",
       " 'Aeligator',\n",
       " 'alienography',\n",
       " 'spideram',\n",
       " 'garfieldcouch',\n",
       " 'nataliexp',\n",
       " 'foreignlawns',\n",
       " 'schiz0rr',\n",
       " 'NootNoot123',\n",
       " 'locrilydian',\n",
       " '5Lighters',\n",
       " 'fazepablito',\n",
       " 'CabroOones',\n",
       " 'lurskk',\n",
       " 'Ace_potat',\n",
       " 'laura__zm',\n",
       " 'life1400999life',\n",
       " 'Lyesolution666',\n",
       " 'nanaisbreathing',\n",
       " 'ankkah_',\n",
       " 'vanscoy87',\n",
       " 'Uektol',\n",
       " 'Dylliance',\n",
       " 'Vaenderby',\n",
       " 'DuckCut',\n",
       " 'kristengab',\n",
       " 'Clava8129',\n",
       " 'Jelipse',\n",
       " 'bellahx',\n",
       " 'snufkinspipe',\n",
       " 'pyroxenic',\n",
       " 'motomxmi',\n",
       " 'isaquiruza',\n",
       " 'frommyknees',\n",
       " 'vogelfeuers',\n",
       " 'benkobio32',\n",
       " 'laissez-moi',\n",
       " 'maxwellk10',\n",
       " 'higorrz',\n",
       " 'klen25',\n",
       " 'Dimiddg85',\n",
       " 'Basil_Rebelwind',\n",
       " 'Pedro_A_arvore',\n",
       " 'MateusAlbani',\n",
       " 'samspearl',\n",
       " 'Gustavinhx',\n",
       " 'SanBitch2002',\n",
       " 'carolineanny',\n",
       " 'rainonmethough',\n",
       " 'KillsXO',\n",
       " 'b12563',\n",
       " 'RaulOrihara',\n",
       " 'luanbohrer',\n",
       " 'barnesbish',\n",
       " 'gigiod',\n",
       " 'joaohmattoss',\n",
       " 'iagourquizas',\n",
       " 'imsecsie',\n",
       " 'DiegoFontinelly',\n",
       " 'Debzebub',\n",
       " 'gonesko',\n",
       " 'frasley',\n",
       " 'jpjoao28',\n",
       " 'vhq',\n",
       " 'seokuzinho',\n",
       " 'evanx8',\n",
       " 'jugofuturizam',\n",
       " 'richertiser',\n",
       " 'Adalaineb',\n",
       " 'gui_x',\n",
       " 'duhparra',\n",
       " 'Jason_mendoza',\n",
       " 'LeytonB',\n",
       " 'astrocesar',\n",
       " 'AndreCopolla',\n",
       " 'cmkarizma',\n",
       " 'discotequedude',\n",
       " 'flawedinc',\n",
       " 'chetchet',\n",
       " 'mercuryeater',\n",
       " 'KrSoulrak',\n",
       " 'limitedlove',\n",
       " 'itargetmoon',\n",
       " 'RammingMode',\n",
       " 'silver1021',\n",
       " 'Duduomartins',\n",
       " 'will3kid0',\n",
       " 'ChaosDevin',\n",
       " 'Punkocalypse',\n",
       " 'cloudskater',\n",
       " 'Enigma_Machine_',\n",
       " 'markhopiss',\n",
       " 'stupot_666',\n",
       " 'LemonHyena',\n",
       " 'tisteatime',\n",
       " 'Stef-C',\n",
       " 'apathys',\n",
       " 'Admiral_Cap',\n",
       " 'frequentcrier',\n",
       " 'PopPunkKidZ',\n",
       " 'TomiT14',\n",
       " 'lylo127',\n",
       " 'stonecoldwhat16',\n",
       " 'electricshirt',\n",
       " 'MrKrusader',\n",
       " 'tagmen',\n",
       " 'Keksinautin',\n",
       " 'troelsenator',\n",
       " 'Jack_Pitts',\n",
       " 'JanuaryEmbers19',\n",
       " 'jimmynewtprawn',\n",
       " 'dddouseddd',\n",
       " 'hesheteewumbo',\n",
       " 'arcanumdown',\n",
       " 'squeaktoad',\n",
       " 'defektseit94',\n",
       " 'i_am_erk_',\n",
       " 'Kanixtant',\n",
       " 'mattchew_',\n",
       " 'NeedlePusher89',\n",
       " 'ZanderVog',\n",
       " 'vistencluse',\n",
       " 'dcss_uk',\n",
       " 'CyKnight118',\n",
       " 'tornadosheep',\n",
       " 'goat-division',\n",
       " 'NK-Metal',\n",
       " 'Parkerkiing',\n",
       " 'chixie6',\n",
       " 'fishyoffishial',\n",
       " 'Aaryamxn-',\n",
       " 'scarethehoes',\n",
       " 'TomSloaneSucks',\n",
       " 'carteriscringe',\n",
       " 'kerwin_',\n",
       " 'myrrs',\n",
       " 'sant1ago_',\n",
       " 'Senpai20',\n",
       " 'haydenwdt',\n",
       " 'amygrey188',\n",
       " 'strxwb4rry',\n",
       " 'tyisba3',\n",
       " 'shudleylild',\n",
       " 'linc_saul',\n",
       " 'fabian_saul',\n",
       " 'Flavie_Kitty',\n",
       " 'zzz_shaun',\n",
       " 'mags_chill',\n",
       " 'soysharna',\n",
       " 'chesy_',\n",
       " 'Joumase_____',\n",
       " 'xoleni',\n",
       " 'elrinafaiyaz',\n",
       " 'hiimbrielol',\n",
       " 'cpunctn',\n",
       " 'mayjaiIer',\n",
       " 'sunigovai_yiigo',\n",
       " 'cyopd',\n",
       " 'arianaglorious',\n",
       " 'hausofannie',\n",
       " 'Marcuzian0',\n",
       " 'katsuraqi',\n",
       " 'c-tr-c',\n",
       " 'kovkoz',\n",
       " 'lagosnigeria',\n",
       " 'diog1st',\n",
       " 'rrhrtntt',\n",
       " 'norita_',\n",
       " 'riamisu',\n",
       " 'whoisgaby',\n",
       " 'Houndsofhate10',\n",
       " 'ferrari690',\n",
       " 'alainchristian',\n",
       " 'planetpola',\n",
       " 'eliselilflower',\n",
       " 'condensepancake',\n",
       " 'oliesz',\n",
       " 'risemi',\n",
       " 'DumbDebbie',\n",
       " 'babskun',\n",
       " 'solvettcoagula',\n",
       " 'goncalvesrafael',\n",
       " 'pinkpantheress2',\n",
       " 'Cora-_-Coral',\n",
       " 'Ayron_',\n",
       " 'maadtheus',\n",
       " 'Risingin',\n",
       " 'Mircea14',\n",
       " 'cadeonline',\n",
       " 'Yazly12',\n",
       " 'Clazyy_',\n",
       " 'Alexandy1',\n",
       " 'Igueuigu',\n",
       " 'eIIis',\n",
       " 'reggieharris',\n",
       " 'Rantsavage',\n",
       " 'RedJMSx',\n",
       " 'alexswif',\n",
       " 'mattiasleiva',\n",
       " 'JulianaAlves-',\n",
       " 'DeusRocha',\n",
       " 'Vixelsa',\n",
       " 'Ayelexx2x',\n",
       " 'eeleallex',\n",
       " 'ProsaicOpinion',\n",
       " 'geekthegrrrl',\n",
       " 'snegnaha',\n",
       " 'SoulKilling',\n",
       " 'fra_six',\n",
       " 'carnicupidity',\n",
       " 'rosanetica',\n",
       " 'LavyLavender',\n",
       " 'Arcuseaquara',\n",
       " 'ManyAwfulThings',\n",
       " 'pillboxhats',\n",
       " 'Cosmug',\n",
       " 'eddy10166',\n",
       " 'homowarrior',\n",
       " 'sineadauer',\n",
       " 'mxmeme',\n",
       " 'GabrielPuma3',\n",
       " 'marillchu789',\n",
       " 'nickkoman',\n",
       " 'throwup111',\n",
       " 'Zaphyra89',\n",
       " 'mattaaack',\n",
       " 'tearsborne',\n",
       " 'onlygirlalive',\n",
       " 'ArcticWhiteOwl',\n",
       " 'koravala',\n",
       " 'Fallingparts',\n",
       " 'Sahjra',\n",
       " 'seraphicjamz',\n",
       " 'josh_morgan16',\n",
       " 'Metalbeast7',\n",
       " 'cruelreligion',\n",
       " 'WeInTheUSA',\n",
       " 'minuix',\n",
       " 'Lewishalo',\n",
       " 'aussieoscarr',\n",
       " 'sjfwaite',\n",
       " 'earth2morgue',\n",
       " 'm1ss1ngt33th',\n",
       " 'flying_buccia',\n",
       " 'mwacmax',\n",
       " 'akion_sesle',\n",
       " 'leberumen',\n",
       " 'nemochains',\n",
       " 'gale888',\n",
       " 'Tekasaur',\n",
       " 'vlavdia',\n",
       " 'gmikwsa',\n",
       " 'rrespicefinem',\n",
       " 'FraccoVDA',\n",
       " 'controlcalos',\n",
       " 'Portabella56',\n",
       " 'tess6z',\n",
       " 'fingwon',\n",
       " 'Silva_Cobra',\n",
       " 'toastaa',\n",
       " 'L2D2E2',\n",
       " 'i666666i',\n",
       " 'buhroke33',\n",
       " 'cyberlily',\n",
       " 'Maixxzs',\n",
       " 'wabungy',\n",
       " 'ALI123j',\n",
       " 'Tayloveskpop',\n",
       " 'SarahTomb',\n",
       " 'skywithdiamondz',\n",
       " 'nyancrimew',\n",
       " 'Cie1',\n",
       " 'hyewoncult',\n",
       " 'starlitgardens',\n",
       " 'ryder-r',\n",
       " 'oddfrontt',\n",
       " 'rusnek',\n",
       " 'Winterbay',\n",
       " 'aethelic',\n",
       " 'arap5',\n",
       " 'Zeroxysm',\n",
       " 'Paralectic',\n",
       " 'Kefkef123',\n",
       " 'Sarah297',\n",
       " 'easterntrees',\n",
       " 'LAST.HQ',\n",
       " 'BitlDev',\n",
       " 'flushed_emoji',\n",
       " 'frikandel_',\n",
       " 'Hwang-Yeji',\n",
       " 'Gillibear89',\n",
       " 'Piotr1981',\n",
       " 'Lolah_Collins',\n",
       " 'IsaiahBolly',\n",
       " 'glorified--g',\n",
       " 'ethli',\n",
       " 'happy_kudlaty',\n",
       " 'raptownerealia',\n",
       " 'Vanilia666',\n",
       " 'nataliie9',\n",
       " 'triiiine',\n",
       " 'dzimipejcz',\n",
       " 'natha_lie_31',\n",
       " 'DIllinger44',\n",
       " 'obelga',\n",
       " 'st4rfem',\n",
       " 'kimberlyxcx',\n",
       " 'Xantris',\n",
       " 'Fukking_Death',\n",
       " 'Hasturrr',\n",
       " 'Speeedzio',\n",
       " 'miloszbalazs',\n",
       " 'Re4ctioN',\n",
       " 'llonerism',\n",
       " 'soul-sleep',\n",
       " 'SebastianM91',\n",
       " 'xmoargh',\n",
       " 'weed1988',\n",
       " 'aaaRunaway',\n",
       " 'Cerede',\n",
       " 'morfeusz',\n",
       " 'rhayader-',\n",
       " 'Narcoser',\n",
       " 'kamilek_666',\n",
       " 'Fretka8',\n",
       " 'klemposs',\n",
       " 'minerfffa',\n",
       " 'MCMXIX-',\n",
       " 'fiszkaaa',\n",
       " 'Palladyn',\n",
       " 'kartagina',\n",
       " 'celun',\n",
       " 'wujek_drut',\n",
       " 'Turbomieciu',\n",
       " 'samel89',\n",
       " 'ZindriMyr',\n",
       " 'Jebdupcyl',\n",
       " 'nusior',\n",
       " 'wwmwmw',\n",
       " 'faser',\n",
       " 'mateusZet',\n",
       " 'aridante_21',\n",
       " 'ignoramos',\n",
       " 'futrr',\n",
       " 'deoda7o',\n",
       " 'rhnstnc0wb0y',\n",
       " 'Mcjuicyj',\n",
       " 'NotJakeee',\n",
       " 'davsko01',\n",
       " 'Punlio',\n",
       " 'FromThe419_',\n",
       " 'emsmsm',\n",
       " 'ClioCJS',\n",
       " 'whitehandlesyuh',\n",
       " 'ssyndafloden',\n",
       " 'miIfs',\n",
       " 'grecie',\n",
       " 'GOLF_HALEY',\n",
       " 'Ididealism',\n",
       " 'jeromebuckets',\n",
       " 'Sykstus-',\n",
       " 'SauceDaddy',\n",
       " 'MoistZerg',\n",
       " 'Taiyokei',\n",
       " 'jt_2246',\n",
       " 'LilMC09',\n",
       " 'VIPxl',\n",
       " 'Allon_z',\n",
       " 'Sheeeeeeeeeeee',\n",
       " 'BigDerp97',\n",
       " 'lilareola',\n",
       " 'Bladeeslover111',\n",
       " 'Yeezylistening',\n",
       " 'ryejpg',\n",
       " 'soulcalibur2',\n",
       " 'Unathihlubi',\n",
       " 'bonbon19',\n",
       " 'baotheprophet',\n",
       " 'Joseph-fm',\n",
       " 'lucydh',\n",
       " 'brooke_bousleyy',\n",
       " 'gersonnn_',\n",
       " 'cursedlean',\n",
       " 'J0531',\n",
       " 'Thaofficialshed',\n",
       " 'marcdubya',\n",
       " 'bbarleyy',\n",
       " 'Tom_Sawyerr',\n",
       " 'ChiefGrumps',\n",
       " 'NickVolps',\n",
       " 'atrislab',\n",
       " 'cinnymoncinder',\n",
       " 'Elih123',\n",
       " 'mariaa2002',\n",
       " 'watermuffin3000',\n",
       " 'MyDixieNormus',\n",
       " 'acabate',\n",
       " 'YellowSnowPKMN',\n",
       " 'raquelsmurph',\n",
       " 'gercog8nya',\n",
       " 'DarlinBambi',\n",
       " 'whoknowslad',\n",
       " 'Freys_Music',\n",
       " 'reuballs',\n",
       " 'gaysinistro',\n",
       " 'Zazazulu',\n",
       " 'XAADE',\n",
       " 'Kunal803193',\n",
       " 'rookie_guy',\n",
       " 'TweepTwee',\n",
       " 'DoubleKOoOo1',\n",
       " 'Aztec_1',\n",
       " 'Re-Kramer',\n",
       " 'ST_Tanji',\n",
       " 'vinushka00',\n",
       " 'Kanopos',\n",
       " 'Kirion-',\n",
       " 'suratvant',\n",
       " 'Ahn_chi',\n",
       " 'EnTeKw',\n",
       " 'martinkimla',\n",
       " 'J1m1nsWife',\n",
       " 'Fuzzphorescent',\n",
       " 'vici_mb',\n",
       " 'Vyphy',\n",
       " 'Anysch',\n",
       " 'OkYeahSure',\n",
       " 'Twiggless_',\n",
       " 'Mileva',\n",
       " 'bootylicker23',\n",
       " 'frachella',\n",
       " 'filterskzzz',\n",
       " 'jupiter0419',\n",
       " 'pixelatedzephyr',\n",
       " 'FlowerySpon',\n",
       " 'NuhBluh',\n",
       " 'Badmusictastew',\n",
       " 'jmprojectone',\n",
       " 'wiredshin',\n",
       " 'BorysReal',\n",
       " 'Aidaniel',\n",
       " 'CryForHelp001',\n",
       " 'abigoop',\n",
       " 'Zaid_90210',\n",
       " 'zachandtwo',\n",
       " 'natgav1',\n",
       " 'itscaduu',\n",
       " 'a4rya',\n",
       " 'Destroyed17',\n",
       " 'jjevy',\n",
       " 'fxlcxn',\n",
       " 'christianorbit',\n",
       " 'DM997',\n",
       " 'Wyattwashington',\n",
       " 'rajdeepkhosa',\n",
       " 'jtbfive',\n",
       " 'Sitkol_76',\n",
       " 'mahamtariq',\n",
       " 'mimisyro',\n",
       " 'scoobydoodaphne',\n",
       " 'Brody_J',\n",
       " 'babydwake',\n",
       " 'Piccyy',\n",
       " 'sleepyeden_',\n",
       " 'spoonwomb',\n",
       " 'BobSacamann0',\n",
       " 'snortsugar',\n",
       " 'phenofm',\n",
       " 'Goombaa',\n",
       " 'drainsophia',\n",
       " 'defStevenYSL',\n",
       " 'nand_i',\n",
       " 'That_Generic',\n",
       " 'raedagh',\n",
       " 'bonesss___',\n",
       " 'noodle_real',\n",
       " 'soulglitches',\n",
       " 'LZR007',\n",
       " 'ur_hue_',\n",
       " 'Pineoid',\n",
       " 'cesxs',\n",
       " 'warf0rged',\n",
       " 'whatermelons',\n",
       " 'marinakoehler',\n",
       " 'Tazonia',\n",
       " 'IAmMichaelGira',\n",
       " 'aeonanarchy',\n",
       " 'oscare_gs',\n",
       " 'plusxtwookbud',\n",
       " 'thedeepfryer',\n",
       " 'compulsivity',\n",
       " 'marc_bev',\n",
       " 'Roman-en-laine',\n",
       " 'windowilcker',\n",
       " 'auspoke',\n",
       " 'Nachtxjager',\n",
       " 'pixiedust_3m1',\n",
       " 'parilly',\n",
       " 'WalmartAlmond19',\n",
       " 'markkuu',\n",
       " 'LouVanBoo',\n",
       " 'lastbloom96',\n",
       " 'not-noided',\n",
       " 'flowuris',\n",
       " 'DaveDuchovny',\n",
       " 'SLNUS',\n",
       " 'jankuca',\n",
       " 'StevenBonnellII',\n",
       " 'HurricaneOfLies',\n",
       " 'tomfromyspace',\n",
       " 'Dag0th_Ur',\n",
       " 'tordstor',\n",
       " 'guywithaqmark',\n",
       " 'xdsocky',\n",
       " 'melgoncalves',\n",
       " 'CunkSkylark',\n",
       " 'DjDarkrai10',\n",
       " 'haterdoo9',\n",
       " 'maxidectillion',\n",
       " 'tuckern21',\n",
       " 'Mars_06',\n",
       " 'homieusername',\n",
       " 'dedenne',\n",
       " 'Typo19',\n",
       " 'hresvelgian',\n",
       " 'Cinebad',\n",
       " 'kdotcdot0',\n",
       " 'Lusssh',\n",
       " 'ULTRA_radio',\n",
       " 'BigSlon',\n",
       " 'frostslvr',\n",
       " 'Amaretto007',\n",
       " 'BlodOgMinne',\n",
       " 'WhisperOfMind',\n",
       " 'slipoi',\n",
       " 'CXMSLXT',\n",
       " 'K0rnl0ver69',\n",
       " 'ange1444l',\n",
       " 'anagrant1',\n",
       " 'CallMeNate',\n",
       " 'souvulaki',\n",
       " 'ieromusttdie',\n",
       " 'w027',\n",
       " 'i6l66k',\n",
       " 'quanrui',\n",
       " 'rvbygloom',\n",
       " 'demjoyntz',\n",
       " 'liricismo',\n",
       " 'kireii-i',\n",
       " 'R41N_',\n",
       " 'storyofaquarius',\n",
       " 'OfMightAndMagic',\n",
       " 'Haruu02',\n",
       " 'notnonzero',\n",
       " 'irenestar',\n",
       " 'ashthee',\n",
       " 'senassky',\n",
       " 'olli33_',\n",
       " 'rollingrl',\n",
       " 'avlisteph',\n",
       " 'emptymaggotry',\n",
       " 'khvv',\n",
       " 'indiechick',\n",
       " 'apieu',\n",
       " 'bbgwony',\n",
       " 'phxlpxo',\n",
       " 'cs_havana',\n",
       " 'd4kotah',\n",
       " 'meurene',\n",
       " 'jiIuka',\n",
       " 'y2kpop',\n",
       " 'odd_carrot',\n",
       " 'angellalala',\n",
       " 'MurotanGekkiLuv',\n",
       " 'Aristocrat4',\n",
       " 'jurupingas',\n",
       " 'heIIovenus',\n",
       " 'Hybrid_Warrior-',\n",
       " 'iwannareset',\n",
       " 'mibalazmiz',\n",
       " 'faqqot',\n",
       " 'avedemiel',\n",
       " 'y4ves',\n",
       " 'momo_momomo',\n",
       " 'strangedays1998',\n",
       " 'leprachaun97',\n",
       " 'SouptheHoop',\n",
       " 'Slothuny',\n",
       " 'Aserikoth',\n",
       " 'theaago',\n",
       " 'sloppyface',\n",
       " 'constantLo',\n",
       " 'benjamin__jh',\n",
       " 'demilland',\n",
       " 'Puhtutz',\n",
       " 'karlistack',\n",
       " 'Nix_Puritanin',\n",
       " 'eyeIids',\n",
       " 'bobo9390',\n",
       " 'oyebeomsito',\n",
       " 'Diggleman007',\n",
       " 'Beast-Robot',\n",
       " 'Hacker420MLG',\n",
       " 'jackxIope',\n",
       " 'lain2002',\n",
       " 'MachineAnimal',\n",
       " 'SerenadeinLead',\n",
       " 'Sattero',\n",
       " 'garlicsucksx',\n",
       " 'moononthebath',\n",
       " 'alexlakisov',\n",
       " 'AussieStarlight',\n",
       " 'HSBallina',\n",
       " 'DynamiteJavvy',\n",
       " 'lalamoraesz',\n",
       " 'ivyshandle',\n",
       " 'WestoFloppa',\n",
       " 'MrAddams',\n",
       " 'OverKektor',\n",
       " 'medxvo',\n",
       " 'grscl',\n",
       " 'HerrPinsam',\n",
       " 'helikopteri13',\n",
       " 'lukosuduko',\n",
       " 'Kizuriley',\n",
       " 'izzyybiz',\n",
       " 'fancyclown1729',\n",
       " 'Song4soul',\n",
       " 'Sakinho',\n",
       " 'digitalgoober',\n",
       " 'BetaAvalanche',\n",
       " 'mattbrundage',\n",
       " 'inuekai',\n",
       " 'naomivirgem',\n",
       " 'ryuejis',\n",
       " 'lanakitty',\n",
       " 'nbhshbr',\n",
       " 'mxup',\n",
       " 'c4zt96',\n",
       " 'RowboatK',\n",
       " 'bearduckmonkey',\n",
       " 'Exoplace',\n",
       " 'Karma-code',\n",
       " 'fitzfrantic',\n",
       " 'stargrl6',\n",
       " 'ZackSu1cide',\n",
       " 'hatefin',\n",
       " 'bloodshedrain',\n",
       " 'cceliaa02',\n",
       " 'nxtready',\n",
       " 'sheikchilli',\n",
       " 'sk8erboi03',\n",
       " 'lace2',\n",
       " 'shanicenaomi',\n",
       " 'vomitboyy-x',\n",
       " 'lovebuzzd',\n",
       " 'nordicvampire',\n",
       " 'XMissCadaverous',\n",
       " 'mojk111',\n",
       " 'blitzen111',\n",
       " 'LeytonKnight',\n",
       " 'asharpdescent',\n",
       " 'gabrielxcx',\n",
       " 'guusgvd',\n",
       " 'jessboucher',\n",
       " 'AngieGerber',\n",
       " 'Jur4iks87',\n",
       " 'camjr01',\n",
       " 'MorkeChaosV',\n",
       " 'die_to_xx',\n",
       " 'lithiumhearts',\n",
       " 'Miguel3424',\n",
       " 'Oksymoron11',\n",
       " 'J3T_ST4R',\n",
       " 'ok',\n",
       " 'motelpr1ncess',\n",
       " 'YoungAntichrist',\n",
       " 'ILoveYouWasabi',\n",
       " 'magicalocelot',\n",
       " 'notoriousmoura',\n",
       " 'hnkd_',\n",
       " 'colorsandfuel',\n",
       " 'Rozalinda00',\n",
       " 'TheKupesters',\n",
       " 'Karrion_',\n",
       " 'moonshineswift',\n",
       " 'Briel_Briel',\n",
       " 'souvenr',\n",
       " 'fairylynaa',\n",
       " 'trivenefica6',\n",
       " 'RiversCuomoStan',\n",
       " 'Stlleji',\n",
       " 'niftytoast',\n",
       " 'Runeric',\n",
       " 'emogirl-_-',\n",
       " 'Izzylkkj',\n",
       " 'magic_pixiee',\n",
       " 'SundownDevil',\n",
       " 'meqtrefer',\n",
       " 'Bodinshoegazer',\n",
       " 'Boobachan',\n",
       " 'celinabaran',\n",
       " 'dacafrin',\n",
       " 'crustycholula',\n",
       " 'Rafanerdfudido',\n",
       " 'ghostbush',\n",
       " 'jaraczhery68686',\n",
       " 'retardedkitten',\n",
       " 'frosty_85',\n",
       " 'jupiluxe',\n",
       " 'theawesomestore',\n",
       " 'Oaehurt',\n",
       " 'dangmustang2',\n",
       " 'Johanna2999',\n",
       " 'sillycelery1974',\n",
       " 'wick29',\n",
       " 'SooLil',\n",
       " 'Spicy_slushy',\n",
       " 'jonhdee23',\n",
       " 'nami0noodles',\n",
       " 'bunnygut',\n",
       " 'Sainted_eek',\n",
       " 'streetyyy',\n",
       " 'rileygeraghty',\n",
       " 'sorry',\n",
       " 'Getawayswift',\n",
       " 'BionicBum',\n",
       " 'greencherries',\n",
       " 'sporcleqlh27',\n",
       " 'lovedytea',\n",
       " 'signofthevibes',\n",
       " 'candyfIoss',\n",
       " 'kingpaca',\n",
       " 'pastelmilk222',\n",
       " 'CainRipley',\n",
       " 'webfag',\n",
       " 'Citrine_01',\n",
       " 'Musiclover10416',\n",
       " 'Pariyawam',\n",
       " 'buffchoila',\n",
       " 'DragonFire2559',\n",
       " 'fbzio',\n",
       " 'huzwastaken',\n",
       " 'anisha_',\n",
       " 'Euclid02',\n",
       " 'Joshy0217',\n",
       " 'tozaro',\n",
       " 'fredits',\n",
       " 'MrOverratedAF',\n",
       " 'baraprast',\n",
       " 'Midzyitzy',\n",
       " 'RiseTheFoo',\n",
       " 'MintyCorpse',\n",
       " 'lemongrassss',\n",
       " 'hikamu',\n",
       " 'HimitsuUK',\n",
       " 'Mjuzik_zg',\n",
       " 'MITZYITZY',\n",
       " 'yoscarly',\n",
       " 'ssophcb',\n",
       " 'barfbagtpot',\n",
       " 'jimijoop',\n",
       " 'TooMuchSlop',\n",
       " 'lunargrande',\n",
       " 'ceosp',\n",
       " 'Zacied',\n",
       " 'huntyweaves',\n",
       " 'ButeraMoonlight',\n",
       " 'Euglena50',\n",
       " 'BringThatLevity',\n",
       " 'royalhunty',\n",
       " 'bluFevr',\n",
       " 'ethanliu930',\n",
       " 'Griffinsheep',\n",
       " 'Seal434',\n",
       " 'jombies',\n",
       " 'myjugularvein',\n",
       " 'Eggectomy',\n",
       " 'despise2beloved',\n",
       " 'femcelkitty',\n",
       " 'Azag0th',\n",
       " 'SpikeSpiegel',\n",
       " 'damesoumbi',\n",
       " 'Tall4LifeX',\n",
       " 'DaannK3',\n",
       " 'HumanRepellent',\n",
       " 'forgiveness999',\n",
       " 'porkfloyd',\n",
       " 'FiestaWarlord',\n",
       " 'proxinite',\n",
       " 'kyra-knightley',\n",
       " 'emo',\n",
       " 'misaeld7',\n",
       " 'torielicious',\n",
       " 'Ethan_Paul',\n",
       " 'g1dget',\n",
       " 'MOOSIC_LOVAH',\n",
       " 'remorsa',\n",
       " 'lordfart',\n",
       " 'L4N73RN',\n",
       " 'dunkelhe1tt',\n",
       " 'Valenehow',\n",
       " 'Sionista',\n",
       " 'marjuaLSS',\n",
       " 'ellieeeee742',\n",
       " 'dbodas1',\n",
       " 'BoiledInfection',\n",
       " 'Elliwowo',\n",
       " 'M4st3r0fW1ck375',\n",
       " 'ocurao',\n",
       " 'scoopitywoopity',\n",
       " 'ARKOBIA',\n",
       " 'awldpawld',\n",
       " 'a-mess',\n",
       " 'Guzzoven',\n",
       " 'Damocles_',\n",
       " 'nickgoodjohn',\n",
       " 'Daniel_Green',\n",
       " 'ann18h',\n",
       " 'Xotic_',\n",
       " 'wrqth',\n",
       " 'kujoisretarded',\n",
       " 'ilusiumrus',\n",
       " 'DanSchliebe',\n",
       " 'dozmaden',\n",
       " 'mairhna',\n",
       " 'G41400',\n",
       " 'MooTwoo',\n",
       " 'figure09s',\n",
       " 'Punkemon27',\n",
       " 'mcrbrainrotz',\n",
       " 'Pronouncemyname',\n",
       " 'pixieg1rl',\n",
       " 'shann0nb3ll',\n",
       " 'Fuck_Your_Rules',\n",
       " 'To4stcat',\n",
       " 'degaussser',\n",
       " 'MaximumThree37',\n",
       " 'KONHaze',\n",
       " 'sw4n_air',\n",
       " 'Shadow_Mortuary',\n",
       " 'JJSOFRS3',\n",
       " 'DrainGavinDrain',\n",
       " 'djballslover32',\n",
       " 'katrrin_d',\n",
       " 'ottrer',\n",
       " 'subparcore',\n",
       " 'backstreet_boy_',\n",
       " 'largeslavicman',\n",
       " 'theworkingbones',\n",
       " 'echocore_',\n",
       " 'bakughol',\n",
       " 'wheezycoffin',\n",
       " 'formlessness',\n",
       " 'endochronic_',\n",
       " 'UponDoom',\n",
       " 'hecksmaniac',\n",
       " 'JoannaET',\n",
       " 'xiiihearts',\n",
       " 'emarosa4l',\n",
       " 'ptv_priscilla',\n",
       " 'taniaa1111',\n",
       " 'TheDarkCosmos',\n",
       " 'will2etterhi',\n",
       " 'oO_Saraswati_Oo',\n",
       " 'JaggerSavage',\n",
       " 'BeatsAndBlades',\n",
       " 'Philthehippy',\n",
       " 'frrrantic',\n",
       " 'clambicus',\n",
       " 'certain_harbors',\n",
       " 'Aswin008',\n",
       " 'florigen9',\n",
       " 'turtleislands',\n",
       " 'getgreens',\n",
       " 'glassbottle',\n",
       " 'PraiseCamwise',\n",
       " 'mikem123',\n",
       " 'Sportsnut',\n",
       " 'Lucas_Sartori',\n",
       " 'Vemrion',\n",
       " 'DaveKlynch615',\n",
       " 'SpydurUndead',\n",
       " 'Vash619',\n",
       " 'HighSynergy',\n",
       " 'Melindael',\n",
       " 'Nachielle',\n",
       " 'Xpirious',\n",
       " 'Zeritas',\n",
       " 'rdsathene',\n",
       " 'Space_Trucker',\n",
       " 'midnightfire24',\n",
       " 'Tom-Knowles',\n",
       " 'grendan17',\n",
       " 'yogalyla',\n",
       " ...]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from collections import deque\n",
    "\n",
    "def get_lastfm_friends_bfs(start_username, api_key, min_users=5000):\n",
    "    discovered = set([start_username])  # Users that have been discovered\n",
    "    queue = deque([start_username])     # Users to be explored\n",
    "    collected_friends = []              # Collected friends\n",
    "\n",
    "    while queue and len(collected_friends) < min_users:\n",
    "        current_user = queue.popleft()\n",
    "        url = f\"http://ws.audioscrobbler.com/2.0/?method=user.getfriends&user={current_user}&api_key={api_key}&format=json\"\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            data = response.json()\n",
    "            \n",
    "            if 'error' in data:\n",
    "                print(f\"Error fetching data for user {current_user}: {data['message']}\")\n",
    "                continue\n",
    "            \n",
    "            users = data.get('friends', {}).get('user', [])\n",
    "            for user in users:\n",
    "                friend_name = user['name']\n",
    "                if friend_name not in discovered:\n",
    "                    discovered.add(friend_name)\n",
    "                    queue.append(friend_name)\n",
    "                    collected_friends.append(friend_name)\n",
    "                    if len(collected_friends) >= min_users:\n",
    "                        break  # Stop if we have collected enough friends\n",
    "\n",
    "            print(f\"Collected {len(collected_friends)} friends so far...\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while processing user {current_user}: {e}\")\n",
    "    \n",
    "    return collected_friends[:min_users]\n",
    "\n",
    "# Example usage\n",
    "api_key = lastfm_api_key\n",
    "start_username = 'Bans77'\n",
    "friends = get_lastfm_friends_bfs(start_username, api_key)\n",
    "print(f\"Collected {len(friends)} unique friends.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for user wyerock: no such page\n",
      "Collected loved tracks for 0 users.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_lastfm_friends_loved_tracks(start_username, api_key, min_users=100, tracks_per_user=50):\n",
    "    discovered = set([start_username])\n",
    "    queue = deque([start_username])\n",
    "    users_loved_tracks = {}  # Dictionary to hold users and their loved tracks\n",
    "\n",
    "    while queue and len(users_loved_tracks) < min_users:\n",
    "        current_user = queue.popleft()\n",
    "        # Fetch friends\n",
    "        friends_url = f\"http://ws.audioscrobbler.com/2.0/?method=user.getfriends&user={current_user}&api_key={api_key}&format=json\"\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(friends_url)\n",
    "            data = response.json()\n",
    "            \n",
    "            if 'error' in data:\n",
    "                print(f\"Error fetching data for user {current_user}: {data['message']}\")\n",
    "                continue\n",
    "            \n",
    "            users = data.get('friends', {}).get('user', [])\n",
    "            for user in users:\n",
    "                friend_name = user['name']\n",
    "                if friend_name not in discovered:\n",
    "                    discovered.add(friend_name)\n",
    "                    queue.append(friend_name)\n",
    "                    # Fetch loved tracks for this friend\n",
    "                    tracks_url = f\"http://ws.audioscrobbler.com/2.0/?method=user.getlovedtracks&user={friend_name}&api_key={api_key}&format=json&limit={tracks_per_user}\"\n",
    "                    tracks_response = requests.get(tracks_url)\n",
    "                    tracks_data = tracks_response.json()\n",
    "                    \n",
    "                    if 'error' not in tracks_data:\n",
    "                        loved_tracks = tracks_data.get('lovedtracks', {}).get('track', [])\n",
    "                        users_loved_tracks[friend_name] = [track['name'] for track in loved_tracks]\n",
    "\n",
    "            print(f\"Collected {len(users_loved_tracks)} users' loved tracks so far...\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while processing user {current_user}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return users_loved_tracks\n",
    "\n",
    "\n",
    "api_key = lastfm_api_key\n",
    "start_username = 'wyerock'\n",
    "users_loved_tracks = get_lastfm_friends_loved_tracks(start_username, api_key)\n",
    "print(f\"Collected loved tracks for {len(users_loved_tracks)} users.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
