{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path as Data_Path\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General libraries\n",
    "import json\n",
    "from pathlib import Path as Data_Path\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Import relevant ML libraries\n",
    "from typing import Optional, Union\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "from torch.nn import Embedding, ModuleList, Linear\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric\n",
    "import torch_geometric.nn as pyg_nn\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "from torch.nn.modules.loss import _Loss\n",
    "\n",
    "from torch_geometric.nn.conv import LGConv, GATConv, SAGEConv\n",
    "from torch_geometric.typing import Adj, OptTensor, SparseTensor\n",
    "\n",
    "print(f\"Torch version: {torch.__version__}; Torch-cuda version: {torch.version.cuda}; Torch Geometric version: {torch_geometric.__version__}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_song_data = pd.read_csv('../Data/user_songs_filtered.csv')\n",
    "song_song_data = pd.read_csv('../Data/songs_with_similarities.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the seed for reproducibility\n",
    "seed = 224\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_song_data = pd.read_csv('../Data/user_songs_filtered.csv')\n",
    "user_song_data = user_song_data.sort_values(by = 'Username')\n",
    "user_song_data = user_song_data.reset_index(drop=True)\n",
    "user_song_data_subset = user_song_data.loc[user_song_data.Username <= 'SierraWuff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Track:\n",
    "  def __init__(self, track_name, artist_name, similar_tracks):\n",
    "    self.name = track_name\n",
    "    self.artist_name = artist_name\n",
    "    self.similar_tracks = similar_tracks\n",
    "\n",
    "\n",
    "  def __str__(self):\n",
    "    return f\"Track called {self.name} from artist {self.artist_name}.\"\n",
    "\n",
    "  def __repr__(self):\n",
    "    return f\"Track {self.name}\"\n",
    "\n",
    "user_song_data_subset[['track_name', 'artist_name']].drop_duplicates().to_numpy()\n",
    "\n",
    "tracks = []\n",
    "unique_tracks = user_song_data_subset[['track_name', 'artist_name']].drop_duplicates().to_numpy()\n",
    "\n",
    "for track, artist_name in unique_tracks:\n",
    "    # track = track[0]  # Extract the scalar value\n",
    "    # row_data = data_subset.loc[(data_subset['track_name'] == track) & (data_subset['artist_name'] == artist)].iloc[0]\n",
    "    row_similar_songs = song_song_data[(song_song_data['track_name'] == track) & (song_song_data['artist_name'] == artist_name)].iloc[0]\n",
    "    similar_tracks = [\n",
    "        (row_similar_songs['Track_Name_1'], row_similar_songs['Similarity_1']),\n",
    "        (row_similar_songs['Track_Name_2'], row_similar_songs['Similarity_2']),\n",
    "        (row_similar_songs['Track_Name_3'], row_similar_songs['Similarity_3']),\n",
    "        (row_similar_songs['Track_Name_4'], row_similar_songs['Similarity_4']),\n",
    "        (row_similar_songs['Track_Name_5'], row_similar_songs['Similarity_5'])\n",
    "    ]\n",
    "\n",
    "\n",
    "    tracks += [Track(track, artist_name, similar_tracks)]\n",
    "\n",
    "\n",
    "class User:\n",
    "  def __init__(self, user_data, top_songs):\n",
    "\n",
    "    self.name = user_data['Username']\n",
    "    self.country = user_data['country']\n",
    "    self.track_count = int(user_data['track_count'])\n",
    "    self.total_playcount = 0\n",
    "    self.top_songs = {}\n",
    "    self.artists = []\n",
    "    for index, row in top_songs.iterrows():\n",
    "      rank = row['rank']\n",
    "      track_name = row['track_name']\n",
    "      artist_name = row['artist_name']\n",
    "      track = [obj for obj in tracks if (obj.name == track_name)&(obj.artist_name == artist_name)][0]\n",
    "      playcount = row['playcount']\n",
    "      self.top_songs[rank] = (track, playcount)\n",
    "      self.total_playcount += playcount\n",
    "      # or should i use a dict for artists\n",
    "      self.artists +=[artist_name]\n",
    "\n",
    "    self.top_songs =  {k: self.top_songs[k] for k in sorted(self.top_songs)}\n",
    "  def __str__(self):\n",
    "    return f\"User {self.name} with {len(self.top_songs)} top tracks loaded, total listen count is {self.total_playcount}.\"\n",
    "\n",
    "  def __repr__(self):\n",
    "    return f\"User {self.name}\"\n",
    "  def __lt__(self, other):\n",
    "    return (self.name < other.name) and (self.total_playcount < other.total_playcount)\n",
    "\n",
    "  def __gt__(self, other):\n",
    "    return (self.name > other.name) and (self.total_playcount > other.total_playcount)\n",
    "\n",
    "unique_users = user_song_data_subset.Username.unique()\n",
    "users = []\n",
    "for user in unique_users:\n",
    "    user_data = user_song_data_subset.loc[user_song_data_subset['Username'] == user].iloc[0]\n",
    "    user_data = user_data[['Username', 'country', 'track_count']].to_dict()\n",
    "    top_songs = user_song_data_subset.loc[user_song_data_subset['Username'] == user]\n",
    "    top_songs = top_songs[['rank', 'track_name', 'artist_name', 'playcount']]\n",
    "    users +=[User(user_data, top_songs)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding nodes\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from([\n",
    "    (p, {'name':p, \"node_type\" : \"user\"}) for p in users\n",
    "])\n",
    "G.add_nodes_from([\n",
    "    (t, {'name':t, \"node_type\" : \"track\"}) for t in tracks\n",
    "])\n",
    "\n",
    "# adding edges\n",
    "edge_list = []\n",
    "for user in users:\n",
    "  top_songs = user.top_songs\n",
    "  user_total_listening = user.total_playcount\n",
    "  for song, count in top_songs.values():\n",
    "    G.add_edge(user, song, weight=1 / (count/user_total_listening))\n",
    "G.add_weighted_edges_from(edge_list)\n",
    "\n",
    "for track in tracks:\n",
    "   track_name = track.name\n",
    "   similar_tracks = track.similar_tracks\n",
    "\n",
    "   for similar_track in similar_tracks:\n",
    "        similar_track_name = similar_track[0]\n",
    "        similar_track_score = similar_track[1]\n",
    "        if not G.has_node(similar_track_name):\n",
    "            G.add_node(similar_track_name, node_type = \"track\")\n",
    "        G.add_edge(track, similar_track_name, weight = 1 / similar_track_score)\n",
    "    \n",
    "\n",
    "\n",
    "# Make a large subgraph\n",
    "random.seed(100)\n",
    "rand_nodes_lg = random.sample(list(G.nodes()), 3000)\n",
    "sub_G_lg = G.subgraph(rand_nodes_lg)\n",
    "largest_cc_lg = max(nx.connected_components(sub_G_lg.to_undirected()), key=len)\n",
    "sub_G_lg = nx.Graph(sub_G_lg.subgraph(largest_cc_lg))\n",
    "print('Large subgraph Num nodes:', sub_G_lg.number_of_nodes(),\n",
    "      '. Num edges:', sub_G_lg.number_of_edges())\n",
    "\n",
    "\n",
    "n_nodes, n_edges = G.number_of_nodes(), G.number_of_edges()\n",
    "\n",
    "# by sorting them we get an ordering playlist1, ..., playlistN, track1, ..., trackN\n",
    "sorted_nodes = list(G.nodes())\n",
    "\n",
    "# create dictionaries to index to 0 to n_nodes, will be necessary for when we are using tensors\n",
    "node2id = dict(zip(sorted_nodes, np.arange(n_nodes)))\n",
    "id2node = dict(zip(np.arange(n_nodes), sorted_nodes))\n",
    "\n",
    "G = nx.relabel_nodes(G, node2id)\n",
    "\n",
    "# also keep track of how many users, tracks we have\n",
    "users_idx = [i for i, v in enumerate(node2id.keys()) if isinstance(v, User)] \n",
    "tracks_idx = [i for i, v in enumerate(node2id.keys()) if isinstance(v, Track)]\n",
    "n_users = np.max(users_idx) + 1\n",
    "n_tracks = n_nodes - n_users\n",
    "\n",
    "n_users, n_tracks\n",
    "\n",
    "# turn the graph into a torch_geometric Data object\n",
    "num_nodes = G.number_of_nodes()\n",
    "edge_idx = torch.Tensor(np.array(G.edges()).T)\n",
    "# Get the edge weights from the NetworkX graph\n",
    "edge_weights = []\n",
    "for u, v in G.edges():\n",
    "    edge_weights.append(G[u][v]['weight'])\n",
    "edge_weights = torch.tensor(edge_weights, dtype=torch.float)\n",
    "graph_data = Data(edge_index = edge_idx, edge_weight = edge_weights, num_nodes = num_nodes)\n",
    "\n",
    "# convert to train/val/test splits\n",
    "transform = RandomLinkSplit(\n",
    "    is_undirected=True,\n",
    "    add_negative_train_samples=False,\n",
    "    neg_sampling_ratio=0,\n",
    "    num_val=0.15, num_test=0.15\n",
    ")\n",
    "train_split, val_split, test_split = transform(graph_data)\n",
    "for split_data in [train_split, val_split, test_split]:\n",
    "    edge_weights_split = []\n",
    "    for u, v in split_data.edge_index.T:\n",
    "        edge_weights_split.append(G[node2id[id2node[u.item()]]][node2id[id2node[v.item()]]]['weight'])\n",
    "    split_data.edge_weight = torch.tensor(edge_weights_split, dtype=torch.float)\n",
    "\n",
    "\n",
    "\n",
    "# note these are stored as float32, we need them to be int64 for future training\n",
    "\n",
    "# Edge index: message passing edges\n",
    "train_split.edge_index = train_split.edge_index.type(torch.int64)\n",
    "val_split.edge_index = val_split.edge_index.type(torch.int64)\n",
    "test_split.edge_index = test_split.edge_index.type(torch.int64)\n",
    "# Edge label index: supervision edges\n",
    "train_split.edge_label_index = train_split.edge_label_index.type(torch.int64)\n",
    "val_split.edge_label_index = val_split.edge_label_index.type(torch.int64)\n",
    "test_split.edge_label_index = test_split.edge_label_index.type(torch.int64)\n",
    "\n",
    "print(f\"Train set has {train_split.edge_label_index.shape[1]} positives supervision edges\")\n",
    "print(f\"Validation set has {val_split.edge_label_index.shape[1]} positive supervision edges\")\n",
    "print(f\"Test set has {test_split.edge_label_index.shape[1]} positive supervision edges\")\n",
    "\n",
    "print(f\"Train set has {train_split.edge_index.shape[1]} message passing edges\")\n",
    "print(f\"Validation set has {val_split.edge_index.shape[1]} message passing edges\")\n",
    "print(f\"Test set has {test_split.edge_index.shape[1]} message passing edges\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import networkx as nx\n",
    "from torch_geometric.utils import from_networkx\n",
    "\n",
    "data = from_networkx(G)\n",
    "\n",
    "edge_weights = torch.tensor([G[u][v]['weight'] for u, v in G.edges()], dtype=torch.float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import inspect\n",
    "from typing import Any, Callable, Dict, Final, List, Optional, Tuple, Union\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear, ModuleList\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import CachedLoader, NeighborLoader\n",
    "from torch_geometric.nn.conv import (\n",
    "    EdgeConv,\n",
    "    GATConv,\n",
    "    GATv2Conv,\n",
    "    GCNConv,\n",
    "    GINConv,\n",
    "    MessagePassing,\n",
    "    PNAConv,\n",
    "    SAGEConv,\n",
    ")\n",
    "from torch_geometric.nn.models import MLP\n",
    "from torch_geometric.nn.models.jumping_knowledge import JumpingKnowledge\n",
    "from torch_geometric.nn.resolver import (\n",
    "    activation_resolver,\n",
    "    normalization_resolver,\n",
    ")\n",
    "from torch_geometric.typing import Adj, OptTensor\n",
    "from torch_geometric.utils._trim_to_layer import TrimToLayer\n",
    "\n",
    "\n",
    "class BasicGNN(torch.nn.Module):\n",
    "    supports_edge_weight: Final[bool]\n",
    "    supports_edge_attr: Final[bool]\n",
    "    supports_norm_batch: Final[bool]\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        hidden_channels: int,\n",
    "        num_layers: int,\n",
    "        out_channels: Optional[int] = None,\n",
    "        dropout: float = 0.0,\n",
    "        act: Union[str, Callable, None] = \"relu\",\n",
    "        act_first: bool = False,\n",
    "        act_kwargs: Optional[Dict[str, Any]] = None,\n",
    "        norm: Union[str, Callable, None] = None,\n",
    "        norm_kwargs: Optional[Dict[str, Any]] = None,\n",
    "        jk: Optional[str] = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "        self.act = activation_resolver(act, **(act_kwargs or {}))\n",
    "        self.jk_mode = jk\n",
    "        self.act_first = act_first\n",
    "        self.norm = norm if isinstance(norm, str) else None\n",
    "        self.norm_kwargs = norm_kwargs\n",
    "\n",
    "        if out_channels is not None:\n",
    "            self.out_channels = out_channels\n",
    "        else:\n",
    "            self.out_channels = hidden_channels\n",
    "\n",
    "        self.convs = ModuleList()\n",
    "        if num_layers > 1:\n",
    "            self.convs.append(\n",
    "                self.init_conv(in_channels, hidden_channels, **kwargs))\n",
    "            if isinstance(in_channels, (tuple, list)):\n",
    "                in_channels = (hidden_channels, hidden_channels)\n",
    "            else:\n",
    "                in_channels = hidden_channels\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(\n",
    "                self.init_conv(in_channels, hidden_channels, **kwargs))\n",
    "            if isinstance(in_channels, (tuple, list)):\n",
    "                in_channels = (hidden_channels, hidden_channels)\n",
    "            else:\n",
    "                in_channels = hidden_channels\n",
    "        if out_channels is not None and jk is None:\n",
    "            self._is_conv_to_out = True\n",
    "            self.convs.append(\n",
    "                self.init_conv(in_channels, out_channels, **kwargs))\n",
    "        else:\n",
    "            self.convs.append(\n",
    "                self.init_conv(in_channels, hidden_channels, **kwargs))\n",
    "\n",
    "        self.norms = ModuleList()\n",
    "        norm_layer = normalization_resolver(\n",
    "            norm,\n",
    "            hidden_channels,\n",
    "            **(norm_kwargs or {}),\n",
    "        )\n",
    "        if norm_layer is None:\n",
    "            norm_layer = torch.nn.Identity()\n",
    "\n",
    "        self.supports_norm_batch = False\n",
    "        if hasattr(norm_layer, 'forward'):\n",
    "            norm_params = inspect.signature(norm_layer.forward).parameters\n",
    "            self.supports_norm_batch = 'batch' in norm_params\n",
    "\n",
    "        for _ in range(num_layers - 1):\n",
    "            self.norms.append(copy.deepcopy(norm_layer))\n",
    "\n",
    "        if jk is not None:\n",
    "            self.norms.append(copy.deepcopy(norm_layer))\n",
    "        else:\n",
    "            self.norms.append(torch.nn.Identity())\n",
    "\n",
    "        if jk is not None and jk != 'last':\n",
    "            self.jk = JumpingKnowledge(jk, hidden_channels, num_layers)\n",
    "\n",
    "        if jk is not None:\n",
    "            if jk == 'cat':\n",
    "                in_channels = num_layers * hidden_channels\n",
    "            else:\n",
    "                in_channels = hidden_channels\n",
    "            self.lin = Linear(in_channels, self.out_channels)\n",
    "\n",
    "        # We define `trim_to_layer` functionality as a module such that we can\n",
    "        # still use `to_hetero` on-top.\n",
    "        self._trim = TrimToLayer()\n",
    "\n",
    "    def init_conv(self, in_channels: Union[int, Tuple[int, int]],\n",
    "                  out_channels: int, **kwargs) -> MessagePassing:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "        for norm in self.norms:\n",
    "            if hasattr(norm, 'reset_parameters'):\n",
    "                norm.reset_parameters()\n",
    "        if hasattr(self, 'jk'):\n",
    "            self.jk.reset_parameters()\n",
    "        if hasattr(self, 'lin'):\n",
    "            self.lin.reset_parameters()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: Tensor,\n",
    "        edge_index: Adj,\n",
    "        edge_weight: OptTensor = None,\n",
    "        edge_attr: OptTensor = None,\n",
    "        batch: OptTensor = None,\n",
    "        batch_size: Optional[int] = None,\n",
    "        num_sampled_nodes_per_hop: Optional[List[int]] = None,\n",
    "        num_sampled_edges_per_hop: Optional[List[int]] = None,\n",
    "    ) -> Tensor:\n",
    "        if (num_sampled_nodes_per_hop is not None\n",
    "                and isinstance(edge_weight, Tensor)\n",
    "                and isinstance(edge_attr, Tensor)):\n",
    "            raise NotImplementedError(\"'trim_to_layer' functionality does not \"\n",
    "                                      \"yet support trimming of both \"\n",
    "                                      \"'edge_weight' and 'edge_attr'\")\n",
    "\n",
    "        xs: List[Tensor] = []\n",
    "        assert len(self.convs) == len(self.norms)\n",
    "        for i, (conv, norm) in enumerate(zip(self.convs, self.norms)):\n",
    "            if (not torch.jit.is_scripting()\n",
    "                    and num_sampled_nodes_per_hop is not None):\n",
    "                x, edge_index, value = self._trim(\n",
    "                    i,\n",
    "                    num_sampled_nodes_per_hop,\n",
    "                    num_sampled_edges_per_hop,\n",
    "                    x,\n",
    "                    edge_index,\n",
    "                    edge_weight if edge_weight is not None else edge_attr,\n",
    "                )\n",
    "                if edge_weight is not None:\n",
    "                    edge_weight = value\n",
    "                else:\n",
    "                    edge_attr = value\n",
    "\n",
    "            # Tracing the module is not allowed with *args and **kwargs :(\n",
    "            # As such, we rely on a static solution to pass optional edge\n",
    "            # weights and edge attributes to the module.\n",
    "            if self.supports_edge_weight and self.supports_edge_attr:\n",
    "                x = conv(x, edge_index, edge_weight=edge_weight,\n",
    "                         edge_attr=edge_attr)\n",
    "            elif self.supports_edge_weight:\n",
    "                x = conv(x, edge_index, edge_weight=edge_weight)\n",
    "            elif self.supports_edge_attr:\n",
    "                x = conv(x, edge_index, edge_attr=edge_attr)\n",
    "            else:\n",
    "                x = conv(x, edge_index)\n",
    "\n",
    "            if i < self.num_layers - 1 or self.jk_mode is not None:\n",
    "                if self.act is not None and self.act_first:\n",
    "                    x = self.act(x)\n",
    "                if self.supports_norm_batch:\n",
    "                    x = norm(x, batch, batch_size)\n",
    "                else:\n",
    "                    x = norm(x)\n",
    "                if self.act is not None and not self.act_first:\n",
    "                    x = self.act(x)\n",
    "                x = self.dropout(x)\n",
    "                if hasattr(self, 'jk'):\n",
    "                    xs.append(x)\n",
    "\n",
    "        x = self.jk(xs) if hasattr(self, 'jk') else x\n",
    "        x = self.lin(x) if hasattr(self, 'lin') else x\n",
    "\n",
    "        return x\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def inference_per_layer(\n",
    "        self,\n",
    "        layer: int,\n",
    "        x: Tensor,\n",
    "        edge_index: Adj,\n",
    "        batch_size: int,\n",
    "    ) -> Tensor:\n",
    "\n",
    "        x = self.convs[layer](x, edge_index)[:batch_size]\n",
    "\n",
    "        if layer == self.num_layers - 1 and self.jk_mode is None:\n",
    "            return x\n",
    "\n",
    "        if self.act is not None and self.act_first:\n",
    "            x = self.act(x)\n",
    "        if self.norms is not None:\n",
    "            x = self.norms[layer](x)\n",
    "        if self.act is not None and not self.act_first:\n",
    "            x = self.act(x)\n",
    "        if layer == self.num_layers - 1 and hasattr(self, 'lin'):\n",
    "            x = self.lin(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def inference(\n",
    "        self,\n",
    "        loader: NeighborLoader,\n",
    "        device: Optional[Union[str, torch.device]] = None,\n",
    "        embedding_device: Union[str, torch.device] = 'cpu',\n",
    "        progress_bar: bool = False,\n",
    "        cache: bool = False,\n",
    "    ) -> Tensor:\n",
    "        assert self.jk_mode is None or self.jk_mode == 'last'\n",
    "        assert isinstance(loader, NeighborLoader)\n",
    "        assert len(loader.dataset) == loader.data.num_nodes\n",
    "        assert len(loader.node_sampler.num_neighbors) == 1\n",
    "        assert not self.training\n",
    "        # assert not loader.shuffle  # TODO (matthias) does not work :(\n",
    "        if progress_bar:\n",
    "            pbar = tqdm(total=len(self.convs) * len(loader))\n",
    "            pbar.set_description('Inference')\n",
    "\n",
    "        x_all = loader.data.x.to(embedding_device)\n",
    "\n",
    "        if cache:\n",
    "\n",
    "            # Only cache necessary attributes:\n",
    "            def transform(data: Data) -> Data:\n",
    "                kwargs = dict(n_id=data.n_id, batch_size=data.batch_size)\n",
    "                if hasattr(data, 'adj_t'):\n",
    "                    kwargs['adj_t'] = data.adj_t\n",
    "                else:\n",
    "                    kwargs['edge_index'] = data.edge_index\n",
    "\n",
    "                return Data.from_dict(kwargs)\n",
    "\n",
    "            loader = CachedLoader(loader, device=device, transform=transform)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            xs: List[Tensor] = []\n",
    "            for batch in loader:\n",
    "                x = x_all[batch.n_id].to(device)\n",
    "                batch_size = batch.batch_size\n",
    "                if hasattr(batch, 'adj_t'):\n",
    "                    edge_index = batch.adj_t.to(device)\n",
    "                else:\n",
    "                    edge_index = batch.edge_index.to(device)\n",
    "\n",
    "                x = self.inference_per_layer(i, x, edge_index, batch_size)\n",
    "                xs.append(x.to(embedding_device))\n",
    "\n",
    "                if progress_bar:\n",
    "                    pbar.update(1)\n",
    "\n",
    "            x_all = torch.cat(xs, dim=0)\n",
    "\n",
    "        if progress_bar:\n",
    "            pbar.close()\n",
    "\n",
    "        return x_all\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f'{self.__class__.__name__}({self.in_channels}, '\n",
    "                f'{self.out_channels}, num_layers={self.num_layers})')\n",
    "\n",
    "\n",
    "class GCN(BasicGNN):\n",
    "    supports_edge_weight: Final[bool] = True\n",
    "    supports_edge_attr: Final[bool] = False\n",
    "    supports_norm_batch: Final[bool]\n",
    "\n",
    "    def init_conv(self, in_channels: int, out_channels: int,\n",
    "                  **kwargs) -> MessagePassing:\n",
    "        return GCNConv(in_channels, out_channels, **kwargs)\n",
    "\n",
    "\n",
    "class GraphSAGE(BasicGNN):\n",
    "    supports_edge_weight: Final[bool] = False\n",
    "    supports_edge_attr: Final[bool] = False\n",
    "    supports_norm_batch: Final[bool]\n",
    "\n",
    "    def init_conv(self, in_channels: Union[int, Tuple[int, int]],\n",
    "                  out_channels: int, **kwargs) -> MessagePassing:\n",
    "        return SAGEConv(in_channels, out_channels, **kwargs)\n",
    "\n",
    "\n",
    "class GIN(BasicGNN):\n",
    "    supports_edge_weight: Final[bool] = False\n",
    "    supports_edge_attr: Final[bool] = False\n",
    "    supports_norm_batch: Final[bool]\n",
    "\n",
    "    def init_conv(self, in_channels: int, out_channels: int,\n",
    "                  **kwargs) -> MessagePassing:\n",
    "        mlp = MLP(\n",
    "            [in_channels, out_channels, out_channels],\n",
    "            act=self.act,\n",
    "            act_first=self.act_first,\n",
    "            norm=self.norm,\n",
    "            norm_kwargs=self.norm_kwargs,\n",
    "        )\n",
    "        return GINConv(mlp, **kwargs)\n",
    "\n",
    "\n",
    "class GAT(BasicGNN):\n",
    "    supports_edge_weight: Final[bool] = False\n",
    "    supports_edge_attr: Final[bool] = True\n",
    "    supports_norm_batch: Final[bool]\n",
    "\n",
    "    def init_conv(self, in_channels: Union[int, Tuple[int, int]],\n",
    "                  out_channels: int, **kwargs) -> MessagePassing:\n",
    "\n",
    "        v2 = kwargs.pop('v2', False)\n",
    "        heads = kwargs.pop('heads', 1)\n",
    "        concat = kwargs.pop('concat', True)\n",
    "\n",
    "        # Do not use concatenation in case the layer `GATConv` layer maps to\n",
    "        # the desired output channels (out_channels != None and jk != None):\n",
    "        if getattr(self, '_is_conv_to_out', False):\n",
    "            concat = False\n",
    "\n",
    "        if concat and out_channels % heads != 0:\n",
    "            raise ValueError(f\"Ensure that the number of output channels of \"\n",
    "                             f\"'GATConv' (got '{out_channels}') is divisible \"\n",
    "                             f\"by the number of heads (got '{heads}')\")\n",
    "\n",
    "        if concat:\n",
    "            out_channels = out_channels // heads\n",
    "\n",
    "        Conv = GATConv if not v2 else GATv2Conv\n",
    "        return Conv(in_channels, out_channels, heads=heads, concat=concat,\n",
    "                    dropout=self.dropout.p, **kwargs)\n",
    "\n",
    "\n",
    "class PNA(BasicGNN):\n",
    "    supports_edge_weight: Final[bool] = False\n",
    "    supports_edge_attr: Final[bool] = True\n",
    "    supports_norm_batch: Final[bool]\n",
    "\n",
    "    def init_conv(self, in_channels: int, out_channels: int,\n",
    "                  **kwargs) -> MessagePassing:\n",
    "        return PNAConv(in_channels, out_channels, **kwargs)\n",
    "\n",
    "\n",
    "class EdgeCNN(BasicGNN):\n",
    "    supports_edge_weight: Final[bool] = False\n",
    "    supports_edge_attr: Final[bool] = False\n",
    "    supports_norm_batch: Final[bool]\n",
    "\n",
    "    def init_conv(self, in_channels: int, out_channels: int,\n",
    "                  **kwargs) -> MessagePassing:\n",
    "        mlp = MLP(\n",
    "            [2 * in_channels, out_channels, out_channels],\n",
    "            act=self.act,\n",
    "            act_first=self.act_first,\n",
    "            norm=self.norm,\n",
    "            norm_kwargs=self.norm_kwargs,\n",
    "        )\n",
    "        return EdgeConv(mlp, **kwargs)\n",
    "\n",
    "\n",
    "__all__ = [\n",
    "    'GCN',\n",
    "    'GraphSAGE',\n",
    "    'GIN',\n",
    "    'GAT',\n",
    "    'PNA',\n",
    "    'EdgeCNN',\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
