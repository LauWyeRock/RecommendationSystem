{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install lightfm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooTR7i5S6-M2",
        "outputId": "0213dbe5-6dc2-4550-a7b2-e3c527ee1fcb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightfm in /usr/local/lib/python3.10/dist-packages (1.17)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lightfm) (1.25.2)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from lightfm) (1.11.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from lightfm) (2.31.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from lightfm) (1.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->lightfm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->lightfm) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->lightfm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->lightfm) (2024.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lightfm) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lightfm) (3.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LightFM\n"
      ],
      "metadata": {
        "id": "LzNJVkWGBdqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from lightfm import LightFM\n",
        "from lightfm.data import Dataset\n",
        "from lightfm.evaluation import precision_at_k, auc_score\n",
        "from lightfm.cross_validation import random_train_test_split\n",
        "import ast\n",
        "from collections import deque\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "df = pd.read_csv('/content/drive/MyDrive/Googlecolab/user_songs_filtered.csv')\n",
        "df['toptags'] = df['toptags'].apply(ast.literal_eval)\n",
        "\n",
        "# Assuming `df` is your DataFrame with the structure provided.\n",
        "df_copy = df"
      ],
      "metadata": {
        "id": "UY4gq3WHQibx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fb4547d-e4ea-45c3-99d6-7ad3a25c798d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['emotion1'].unique()\n",
        "emotion_mapping = {\n",
        "    'joy': 1,\n",
        "    'positive': 2,\n",
        "    'trust': 3,\n",
        "    'surprise': 4,\n",
        "    'negative': 5,\n",
        "    'sadness': 6,\n",
        "    'fear': 7,\n",
        "    'disgust': 8,\n",
        "    'anger':9\n",
        "}\n",
        "df['emotion1_encoded'] = df['emotion1'].map(emotion_mapping)\n",
        "df['emotion2_encoded'] = df['emotion2'].map(emotion_mapping)\n",
        "last_2_interactions = df.groupby('Username').tail(2)\n",
        "train_df = df.drop(last_2_interactions.index)"
      ],
      "metadata": {
        "id": "WESL_x-n-kEg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Dataset()\n",
        "df['track_id'] = df['track_name'] + ' - ' + df['artist_name']\n",
        "unique_toptags = set(tag for sublist in df['toptags'].dropna() for tag in sublist)\n",
        "unique_countries = set(df['country'].unique())\n",
        "item_features_list = ['listeners', 'total_playcount', \"profanity_density\",\n",
        "                      \"polarity\", \"subjectivity\", \"emotion1_encoded\", \"emotion1_score\",\n",
        "                      \"emotion2_encoded\", \"emotion2_score\", \"mfcc\", \"chroma\", \"rms\",\n",
        "                      \"spectral_centroid\", \"zcr\", \"tempo\"] + list(unique_toptags)\n",
        "\n",
        "# Preparing the complete list of user features including 'country'\n",
        "user_features_list = ['registered_year', \"track_count\", \"artist_count\"] + list(unique_countries)\n",
        "\n",
        "dataset = Dataset()\n",
        "dataset.fit(\n",
        "    users=df['Username'].unique(),\n",
        "    items=df['track_id'].unique(),\n",
        "    user_features=user_features_list,\n",
        "    item_features=item_features_list\n",
        ")\n"
      ],
      "metadata": {
        "id": "jDqf7jbx7yQd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "item_features_data = []\n",
        "for index, row in df.iterrows():\n",
        "    chroma_list = np.fromstring(row.chroma.strip('[]'), sep=' ')\n",
        "    chroma_avg = np.mean(chroma_list)\n",
        "    mfcc_list = np.fromstring(row.mfcc.strip('[]'), sep=' ')\n",
        "    mfcc_avg = np.mean(mfcc_list)\n",
        "    # Preparing a dictionary for the current row/item with feature weights\n",
        "    features_dict = {\n",
        "\n",
        "        'listeners': int(row.listeners),\n",
        "        'total_playcount': int(row.total_playcount),\n",
        "        'profanity_density': float(row.profanity_density),\n",
        "        'polarity': float(row.polarity),\n",
        "        'subjectivity': float(row.subjectivity),\n",
        "        'emotion1_encoded': int(row.emotion1_encoded),  # Convert to integer if it's encoded as a numeric string\n",
        "        'emotion1_score': float(row.emotion1_score),\n",
        "        'emotion2_encoded': int(row.emotion2_encoded),  # Convert to integer if it's encoded as a numeric string\n",
        "        'emotion2_score': float(row.emotion2_score),\n",
        "        'mfcc': float(mfcc_avg),\n",
        "        'chroma': float(chroma_avg),\n",
        "        'rms': float(row.rms),\n",
        "        'spectral_centroid': float(row.spectral_centroid),\n",
        "        'zcr': float(row.zcr),\n",
        "        'tempo': float(row.tempo)\n",
        "    }\n",
        "    toptags_features = {tag: 1.0 for tag in row.toptags}\n",
        "    features_dict.update(toptags_features)\n",
        "    # Add the item id and its features to the list\n",
        "    item_features_data.append((row.track_id, features_dict))\n",
        "\n",
        "# Now, build the item features matrix with this data\n",
        "item_features = dataset.build_item_features(item_features_data, normalize=True)\n"
      ],
      "metadata": {
        "id": "s44B6TN39p8W"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_features_data = []\n",
        "for index, row in df.iterrows():\n",
        "    # Preparing a dictionary for the current row/item with feature weights\n",
        "    features_dict = {\n",
        "        row.country: 1.0,\n",
        "        'registered_year': int(row.registered_year),\n",
        "        'track_count': int(row.track_count),\n",
        "        'artist_count': int(row.artist_count)}\n",
        "\n",
        "    # Add the item id and its features to the list\n",
        "    item_features_data.append((row.Username, features_dict))\n",
        "\n",
        "# Now, build the item features matrix with this data\n",
        "user_features = dataset.build_user_features(user_features_data, normalize=True)\n",
        "\n",
        "(interactions, weights) = dataset.build_interactions(((row.Username, row.track_id, row.playcount) for index, row in df.iterrows()))\n",
        "\n",
        "train_interactions, test_interactions = random_train_test_split(interactions, test_percentage=0.2, random_state=None)"
      ],
      "metadata": {
        "id": "6BkdAcc542u1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LightFM(loss='warp')\n",
        "\n",
        "# Train the model\n",
        "model.fit(interactions, user_features=user_features, item_features=item_features, epochs=50, num_threads=4)\n",
        "\n",
        "from lightfm.evaluation import precision_at_k, recall_at_k, auc_score, reciprocal_rank\n",
        "\n",
        "model_filename = '/content/drive/MyDrive/Googlecolab/model_lightfm.pkl'  # Update the path to your desired Google Drive folder\n",
        "\n",
        "import pickle\n",
        "with open(model_filename, 'wb') as model_file:\n",
        "    pickle.dump(model, model_file)"
      ],
      "metadata": {
        "id": "JNF_RCQXGeRC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute and print the precision at k\n",
        "precision_at_k = precision_at_k(model, test_interactions, k=30, user_features=user_features, item_features=item_features).mean()\n",
        "print(f\"Precision at k: {precision_at_k}\")\n",
        "recall_at_k = recall_at_k(model, test_interactions, k=30, user_features=user_features, item_features=item_features).mean()\n",
        "print(f\"recall at k: {recall_at_k}\")\n",
        "auc_score = auc_score(model, test_interactions, user_features=user_features, item_features=item_features).mean()\n",
        "print(f\"auc score: {auc_score}\")\n",
        "reciprocal_rank = reciprocal_rank(model, test_interactions,  user_features=user_features, item_features=item_features).mean()\n",
        "print(f\"reciprocal_rank: {reciprocal_rank}\")"
      ],
      "metadata": {
        "id": "5-V_-eTK95F1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model from the file\n",
        "import pickle\n",
        "with open('/content/drive/MyDrive/Googlecolab/model_lightfm.pkl', 'rb') as f:\n",
        "    model = pickle.load(f)\n",
        "def recommend(user_id, model, data, interactions, n_items=10):\n",
        "    user_index = data.mapping()[0][user_id]\n",
        "\n",
        "    scores = model.predict(user_index, np.arange(interactions.shape[1]))\n",
        "\n",
        "    item_indices = np.argsort(-scores)[:n_items]\n",
        "\n",
        "    # Convert item indices back to item IDs\n",
        "    item_ids = [list(data.mapping()[2].keys())[i] for i in item_indices]\n",
        "\n",
        "    return item_ids\n",
        "\n",
        "user_id = 'emosoup'\n",
        "recommended_tracks = recommend(user_id, model, dataset, test_interactions, n_items=10)\n",
        "print(f\"Recommended tracks for user {user_id}: {recommended_tracks}\")"
      ],
      "metadata": {
        "id": "0AEiljFbsgCy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "908fb137-952f-4f84-c31a-c9b137beb17a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommended tracks for user emosoup: [\"Ain't it Pretty - will.i.am\", 'You Dont Know My Name - Alicia Keys', 'Home - Will Hanson', 'No Feelings - Remastered 2012 - Sex Pistols', 'The Chemistry Between Us - Suede', 'No Distance Left to Run - Blur', 'Return Trip - Electric Wizard', 'Pet Sematary - Ramones', 'Pilot - 50 Cent', 'Under Pressure (Ice Ice Baby) - Jedward']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_artist_diversity(recommended_lists):\n",
        "    diversity_scores = []\n",
        "\n",
        "    for recommended_list in recommended_lists:\n",
        "        artists = [get_artist_for_song(song_id) for song_id in recommended_list]\n",
        "        unique_artists = set(artists)\n",
        "        diversity_score = len(unique_artists) / len(recommended_list) if recommended_list else 0\n",
        "        diversity_scores.append(diversity_score)\n",
        "\n",
        "    # Calculate the average diversity score across all recommendation lists\n",
        "    average_diversity = sum(diversity_scores) / len(diversity_scores) if diversity_scores else 0\n",
        "    return average_diversity\n",
        "\n",
        "def get_artist_for_song(song_id):\n",
        "    # Implement this function based on your dataset\n",
        "    # It should return the artist for the given song ID\n",
        "    pass\n",
        "\n",
        "# Assume `recommendations` is a list of lists, where each inner list contains recommended song IDs for a user\n",
        "average_diversity_score = calculate_artist_diversity(recommended_tracks)\n",
        "print(f\"Average Artist Diversity Score: {average_diversity_score}\")\n"
      ],
      "metadata": {
        "id": "hxJ-8nftymlP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8ae2a6d-ea45-436b-9afd-9995f1dc2dcb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Artist Diversity Score: 0.038124816483377025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The AUC score is relatively high, suggesting the model is quite good at distinguishing between songs that a user will like and songs they wonâ€™t, when considering the entire dataset.\n",
        "\n",
        "In the context of a recommendation system using the LightFM model and a user-song interaction matrix, a \"relevant song\" typically refers to a song that has some form of positive interaction recorded in the interaction matrix for a given user.\n",
        "\n",
        "epoch: 30 k=5\n",
        "Precision at k: 0.0002954209630843252\n",
        "recall at k: 0.00018907612281741844\n",
        "auc score: 0.7672815918922424\n",
        "\n",
        "epopch 50, k=100\n",
        "Precision at k: 0.00016875856090337038\n",
        "recall at k: 0.0022899736471617073\n",
        "auc score: 0.7718917727470398\n",
        "\n",
        "learning rate 0.05, no.components 30\n",
        "Precision at k: 0.00020050653256475925\n",
        "recall at k: 0.002668390848592225\n",
        "auc score: 0.7745291590690613"
      ],
      "metadata": {
        "id": "7u9cGKqqZ09D"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}