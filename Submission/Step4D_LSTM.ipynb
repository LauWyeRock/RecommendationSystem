{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "import base64   \n",
    "import pandas as pd\n",
    "import librosa\n",
    "import numpy as np\n",
    "import lyricsgenius\n",
    "import langdetect\n",
    "import re\n",
    "import string\n",
    "import tempfile\n",
    "from tqdm import tqdm  # Import tqdm for progress bar\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For any api we can try using the \"+\" email trick to get more API keys\n",
    "\n",
    "genius_client_id = \"wZZ2RWc5mqp-5Pbz2W1rQJWE8LQ3pFBrb1Hw5_AOqgybq28mt7kjdjcG4zktCNbO\"\n",
    "genius_client_secret = \"PefqBJHor_muDgTutGlaXXaxmzsI7TQCps9FQ3FwkUTT0WJIT3s0A5YA9mnFbfp_-CBhQF7b0omgE8kaM3dJ3w\"\n",
    "genius_access_token = \"NUHHVpwnmbDYUYw8Padu0gQeHvYN4OsKYtE2MKNUpBUI6yR-xZXKY6S5NvCnFbiP\"\n",
    "\n",
    "lastfm_api_key = \"97d5a64d5ba4a8bc580b752ceff3b87f\"\n",
    "lastfm_secret = \"35175090bd61f6f16ac607bd26e5b1de\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next 2 codeblocks are for extracting data from lastfm. These pertain to User data, where we want to get their recent tracks from up to one month ago. We limit it to 100 tracks per user. This is run on unique users from the user-song dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'http://ws.audioscrobbler.com/2.0/'\n",
    "\n",
    "def lastfm_get(payload):\n",
    "    headers = {'user-agent': 'DataCollectorBot'}\n",
    "    payload['api_key'] = lastfm_api_key\n",
    "    payload['format'] = 'json'\n",
    "    response = requests.get(base_url, headers=headers, params=payload)\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def get_recent_tracks(user):\n",
    "    payload = {'method': 'user.getrecenttracks', 'user': user}\n",
    "    return lastfm_get(payload)\n",
    "\n",
    "def get_weekly_artist_chart(user):\n",
    "    payload = {'method': 'user.getweeklyartistchart', 'user': user}\n",
    "    return lastfm_get(payload)\n",
    "\n",
    "def get_weekly_track_chart(user):\n",
    "    payload = {'method': 'user.getweeklytrackchart', 'user': user}\n",
    "    return lastfm_get(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Users: 100%|██████████| 9483/9483 [2:08:50<00:00,  1.23user/s]  \n"
     ]
    }
   ],
   "source": [
    "def get_one_month_ago_timestamp():\n",
    "    one_month_ago = datetime.now() - timedelta(days=30)\n",
    "    return int(one_month_ago.timestamp())\n",
    "\n",
    "def recent_tracks_for_user_to_df(user, min_tracks=50, max_tracks=100):\n",
    "    from_timestamp = get_one_month_ago_timestamp()\n",
    "    \n",
    "    payload = {\n",
    "        'method': 'user.getrecenttracks',\n",
    "        'user': user,\n",
    "        'from': from_timestamp,\n",
    "        'limit': max_tracks \n",
    "    }\n",
    "    \n",
    "    recent_tracks = lastfm_get(payload)\n",
    "    tracks_list = []\n",
    "    \n",
    "    if 'track' in recent_tracks.get('recenttracks', {}):\n",
    "        for track in recent_tracks['recenttracks']['track']:\n",
    "            if 'date' in track: \n",
    "                track_info = {\n",
    "                    'User': user, \n",
    "                    'Artist': track['artist']['#text'],\n",
    "                    'Track Name': track['name'],\n",
    "                    'Timestamp': track['date']['uts']\n",
    "                }\n",
    "                tracks_list.append(track_info)\n",
    "\n",
    "    df = pd.DataFrame(tracks_list)\n",
    "    return df\n",
    "\n",
    "def recent_tracks_all_users_to_df(users):\n",
    "    all_tracks_dfs = [] \n",
    "    total_users = len(users)\n",
    "    \n",
    "    with tqdm(total=total_users, desc=\"Processing Users\", unit=\"user\") as pbar:\n",
    "        for user in users:\n",
    "            df = recent_tracks_for_user_to_df(user)\n",
    "            all_tracks_dfs.append(df)\n",
    "            pbar.update(1) \n",
    "    \n",
    "    combined_df = pd.concat(all_tracks_dfs, ignore_index=True)\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "\n",
    "df = pd.read_csv('../../Downloads/user_songs_filtered.csv')\n",
    "users = df[\"Username\"].unique()\n",
    "combined_tracks_df = recent_tracks_all_users_to_df(users)\n",
    "combined_tracks_df.to_excel(\"../../Downloads/Users_Songs_Timestamps.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_df(data_list, columns):\n",
    "    if data_list:\n",
    "        df = pd.DataFrame(data_list, columns=columns)\n",
    "        return df\n",
    "    else:\n",
    "        return pd.DataFrame(columns=columns)\n",
    "\n",
    "def get_weekly_artist_chart_df(user):\n",
    "    result = get_weekly_artist_chart(user)\n",
    "    artists = []\n",
    "    if 'weeklyartistchart' in result and 'artist' in result['weeklyartistchart']:\n",
    "        for item in result['weeklyartistchart']['artist']:\n",
    "            artists.append({\n",
    "                'Artist': item['name'],\n",
    "                'Play Count': item['playcount']\n",
    "            })\n",
    "    return list_to_df(artists, ['Artist', 'Play Count'])\n",
    "\n",
    "def get_weekly_track_chart_df(user):\n",
    "    result = get_weekly_track_chart(user)\n",
    "    tracks = []\n",
    "    if 'weeklytrackchart' in result and 'track' in result['weeklytrackchart']:\n",
    "        for item in result['weeklytrackchart']['track']:\n",
    "            tracks.append({\n",
    "                'Track Name': item['name'],\n",
    "                'Artist': item['artist']['#text'],\n",
    "                'Play Count': item['playcount']\n",
    "            })\n",
    "    return list_to_df(tracks, ['Track Name', 'Artist', 'Play Count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timestamp Conversion: The 'Timestamp' column, is converted into a datetime format. This allows for extracting more granular time information such as hours.\n",
    "\n",
    "Time of Day: 'Time_of_Day' feature by extracting the hour from the timestamp. This is done to capture patterns in listening behavior based on the time of day.\n",
    "\n",
    "Combining Artist and Track: The 'Artist' and 'Track Name' columns are combined into a single 'Artist_Track' column. This creates a unique identifier for each artist-track combination \n",
    "\n",
    "One-Hot Encoding Time of Day\n",
    "\n",
    "Label Encoding Artist-Track: The 'Artist_Track' combinations are label-encoded, assigning a unique integer to each unique artist-track string. This is necessary for the model to process textual/categorical data.\n",
    "\n",
    "Concatenate the original dataframe with the one-hot encoded 'Time_of_Day' features, expanding the feature set to include this time information explicitly.\n",
    "\n",
    "A sequence length of 3 is specified, which means using sequences of two previous songs listened to by a user to predict the next song.\n",
    "\n",
    "Sequence and Label Creation: For each user, sort their listening events by timestamp and create sequences of artist-track encodings along with their corresponding time-of-day features. Each sequence (excluding the last element) serves as input, and the next song (the last element in the sequence) is the label/target.\n",
    "Input Sequence: Comprises the label-encoded artist-track IDs for two consecutive songs, concatenated with the one-hot encoded time features for those songs, flattened into a single vector.\n",
    "Label: The label-encoded artist-track ID for the song following the sequence.\n",
    "\n",
    "Split the structured sequences into training and test sets, ensuring that the sequences are not shuffled (shuffle=False). This is important for time series data to maintain the temporal order.\n",
    "\n",
    "The input sequences are split into two parts: one containing the artist-track features (first two elements of each sequence) and another containing the time-of-day features (the rest of the sequence).\n",
    "This separation facilitates different handling or processing paths in the neural network model, allowing for specialized layers (e.g., an embedding layer for artist-track features and a dense layer for time features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = combined_tracks_df[:100000]\n",
    "df = pd.read_excel(\"../../Downloads/Users_Songs_Timestamps.xlsx\")\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'], unit='s')\n",
    "df['Time_of_Day'] = df['Timestamp'].dt.hour\n",
    "df['Artist_Track'] = df['Artist'].astype(str) + ' - ' + df['Track Name'].astype(str)\n",
    "\n",
    "time_of_day_encoded = pd.get_dummies(df['Time_of_Day'], prefix='hour')\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "df['Artist_Track_Encoded'] = label_encoder.fit_transform(df['Artist_Track'])\n",
    "\n",
    "df = pd.concat([df, time_of_day_encoded], axis=1)\n",
    "\n",
    "sequence_length = 3\n",
    "vocab_size = len(label_encoder.classes_)\n",
    "\n",
    "\n",
    "X_seq_list, y_seq_list = [], []\n",
    "\n",
    "for _, group in df.groupby('User'):\n",
    "    group = group.sort_values('Timestamp')\n",
    "    \n",
    "    for i in range(len(group) - sequence_length + 1):\n",
    "        artist_track_sequence = group['Artist_Track_Encoded'].iloc[i:i + sequence_length - 1].values\n",
    "        \n",
    "        time_features_sequence = group[time_of_day_encoded.columns].iloc[i:i + sequence_length - 1].values.reshape((sequence_length - 1) * len(time_of_day_encoded.columns))\n",
    "        \n",
    "        sequence = np.hstack([artist_track_sequence, time_features_sequence])\n",
    "        \n",
    "        label = group['Artist_Track_Encoded'].iloc[i + sequence_length - 1]\n",
    "        \n",
    "        X_seq_list.append(sequence)\n",
    "        y_seq_list.append(label)\n",
    "\n",
    "X_seq = np.array(X_seq_list)\n",
    "# y_seq = to_categorical(y_seq_list, num_classes=vocab_size)\n",
    "y_seq = np.array(y_seq_list) # Integer instead of one hot encoding\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, shuffle=False)\n",
    "\n",
    "num_artist_track_features = sequence_length - 1  \n",
    "num_time_features = 24 * (sequence_length - 1)  \n",
    "\n",
    "X_train_artist_track = X_train[:, :num_artist_track_features]  \n",
    "X_train_time_features = X_train[:, num_artist_track_features:] \n",
    "\n",
    "X_test_artist_track = X_test[:, :num_artist_track_features] \n",
    "X_test_time_features = X_test[:, num_artist_track_features:]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated number of time features: 48\n"
     ]
    }
   ],
   "source": [
    "num_time_features_actual = X_train_time_features.shape[1]\n",
    "\n",
    "num_time_features = num_time_features_actual\n",
    "print(\"Updated number of time features:\", num_time_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "set_global_policy('mixed_float16'): This configures TensorFlow to use mixed precision training, which combines float32 and float16 data types to improve performance and reduce memory usage without compromising the model's accuracy. This significantly accelerates training on compatible hardware (GPUs with tensor cores).\n",
    "\n",
    "EarlyStopping: A callback to stop training when a monitored metric has stopped improving, preventing overfitting. Here, we monitor validation loss ('val_loss'), with a patience of 10 epochs (i.e., training will stop if there is no improvement in validation loss for 10 consecutive epochs). \n",
    "\n",
    "Embedding Layer: Maps the integer-encoded artist-track IDs to dense vectors. This layer helps the model to understand the relationships between different IDs by projecting them into a continuous vector space.\n",
    "\n",
    "LSTM Layer: Processes the sequences of embeddings with 40 units, using dropout and recurrent dropout to prevent overfitting.\n",
    "\n",
    "Dense Time Features Layer: A dense layer that processes the one-hot encoded time features.\n",
    "\n",
    "Output Layer: The final dense layer uses softmax activation to output a probability distribution over all possible artist-track IDs, corresponding to the model's prediction of the next song.\n",
    "\n",
    "The model is compiled with the sparse_categorical_crossentropy loss function. The Adam optimizer is used with a learning rate of 0.001."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " artist_track_input (InputLayer  [(None, 2)]         0           []                               \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 2, 50)        15286150    ['artist_track_input[0][0]']     \n",
      "                                                                                                  \n",
      " time_features_input (InputLaye  [(None, 48)]        0           []                               \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, 40)           14560       ['embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 40)           1960        ['time_features_input[0][0]']    \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 80)           0           ['lstm_1[0][0]',                 \n",
      "                                                                  'dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 80)           0           ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 80)          320         ['dropout_2[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 100)          8100        ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 100)          0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 305722)       30877922    ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 46,189,012\n",
      "Trainable params: 46,188,852\n",
      "Non-trainable params: 160\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dropout, Dense, Bidirectional, BatchNormalization, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.mixed_precision import set_global_policy\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "set_global_policy('mixed_float16')\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  \n",
    "    patience=10,  \n",
    "    restore_best_weights=True \n",
    ")\n",
    "\n",
    "artist_track_input = Input(shape=(sequence_length-1,), dtype='int32', name='artist_track_input')\n",
    "time_features_input = Input(shape=(num_time_features,), name='time_features_input')  \n",
    "\n",
    "embedding_layer = Embedding(input_dim=vocab_size + 1, output_dim=50, input_length=sequence_length-1)(artist_track_input)\n",
    "lstm_layer = LSTM(40, dropout=0.2, recurrent_dropout=0.2)(embedding_layer)\n",
    "\n",
    "time_dense_layer = Dense(40, activation='relu')(time_features_input)\n",
    "\n",
    "combined = concatenate([lstm_layer, time_dense_layer])\n",
    "\n",
    "x = Dropout(0.5)(combined)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(100, activation='relu', kernel_regularizer=l1_l2(l1=0.01, l2=0.01))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(vocab_size, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=[artist_track_input, time_features_input], outputs=output)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The function enters an infinite loop, which allows the generator to yield batches indefinitely. \n",
    "Inside the loop, the function iterates over the dataset in increments of batch_size. For each iteration, it slices the X_artist_track, X_time_features, and y arrays to create a new batch of data.\n",
    "\n",
    "Instead of passing the entire dataset to the fit method, we pass the generator to the fit_generator method. The generator will produce batches of data on-the-fly, which is memory efficient and allows for the training process to start immediately without waiting for the entire dataset to be preprocessed or loaded into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(X_artist_track, X_time_features, y, batch_size):\n",
    "\n",
    "    num_samples = X_artist_track.shape[0]\n",
    "    while True: \n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_X_artist_track = X_artist_track[offset:offset+batch_size]\n",
    "            batch_X_time_features = X_time_features[offset:offset+batch_size]\n",
    "            batch_y = y[offset:offset+batch_size]\n",
    "            \n",
    "            \n",
    "            yield [batch_X_artist_track, batch_X_time_features], batch_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "   1/4490 [..............................] - ETA: 56:03:18 - loss: 20.8018 - accuracy: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "steps_per_epoch = np.ceil(X_train_artist_track.shape[0] / batch_size)\n",
    "\n",
    "train_generator = data_generator(X_train_artist_track, X_train_time_features, y_train, batch_size)\n",
    "validation_generator = data_generator(X_test_artist_track, X_test_time_features, y_test, batch_size)\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=np.ceil(X_test_artist_track.shape[0] / batch_size), \n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: lstm_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: lstm_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('lstm_model')\n",
    "\n",
    "# model = load_model('lstm_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_pred_prob = model.predict([X_test_artist_track, X_test_time_features]): uses the trained model to predict the probabilities of each possible next song for the entries in the test set. y_pred_prob is an array where each row corresponds to a test example, and each column represents the model's assigned probability that the example belongs to that class (song).\n",
    "\n",
    "Determining Top-k Classes: The model's predictions are probabilities for each class. To evaluate its performance in a top-k context, we are interested in the classes with the highest probabilities. np.argsort(y_pred_prob, axis=1)[:, -k:][:, ::-1] sorts the classes by their predicted probabilities and selects the top 30 for each example. The [:, ::-1] part reverses the columns because np.argsort returns them in ascending order, and you want the highest probabilities first.\n",
    "\n",
    "Transforming Indices to Class Names: label_encoder.inverse_transform(top_k_indices.flatten()).reshape(top_k_indices.shape) takes these top-k indices and converts them back into the original class labels (song names or IDs) using the inverse of the label encoding applied earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "613/613 [==============================] - 348s 567ms/step\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.43 GiB for an array with shape (19594, 19594) and data type int32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m y_pred_top_k \u001b[38;5;241m=\u001b[39m label_encoder\u001b[38;5;241m.\u001b[39minverse_transform(top_k_indices\u001b[38;5;241m.\u001b[39mflatten())\u001b[38;5;241m.\u001b[39mreshape(top_k_indices\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      7\u001b[0m y_true_names \u001b[38;5;241m=\u001b[39m label_encoder\u001b[38;5;241m.\u001b[39minverse_transform(y_true)\n\u001b[1;32m----> 9\u001b[0m binary_relevance \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpred\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43my_true_names\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpred\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43my_pred_top_k\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m predicted_scores \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand(k)  \n\u001b[0;32m     12\u001b[0m all_positives \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(y_true)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.43 GiB for an array with shape (19594, 19594) and data type int32"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred_prob = model.predict([X_test_artist_track, X_test_time_features])\n",
    "y_true = y_test\n",
    "k = 30\n",
    "top_k_indices = np.argsort(y_pred_prob, axis=1)[:, -k:][:, ::-1]  \n",
    "\n",
    "y_pred_top_k = label_encoder.inverse_transform(top_k_indices.flatten()).reshape(top_k_indices.shape)\n",
    "y_true_names = label_encoder.inverse_transform(y_true)\n",
    "\n",
    "# binary_relevance = np.array([[1 if label in pred[:k] else 0 for label in y_true_names] for pred in y_pred_top_k])\n",
    "# predicted_scores = np.random.rand(k)  \n",
    "\n",
    "all_positives = len(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hit Rate at k\n",
    "Purpose: Measures whether the true item appears in the top-k recommendations.\n",
    "\n",
    "Precision@30 and Recall@30\n",
    "Purpose: Precision@30 measures the proportion of relevant items among the top 30 recommendations, whereas Recall@30 measures the proportion of relevant items that were recommended in the top 30.\n",
    "\n",
    "Mean Average Precision (MAP)\n",
    "Purpose: MAP@k averages the precision scores calculated at each rank position up to k, for all users, considering only the order of the relevant items.\n",
    "\n",
    "NDCG@30\n",
    "Purpose: NDCG@30 evaluates the ranking quality by comparing the order of recommended items to the order of true relevance, penalizing incorrect rankings based on their positions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit Rate at 30: 0.0469\n",
      "Precision@30: 0.0469\n",
      "Recall@30: 0.0469\n",
      "MAP: 0.0070\n"
     ]
    }
   ],
   "source": [
    "def compute_hit_rate_at_k(y_true, y_pred_top_k, k):\n",
    "    hits = 0\n",
    "    for true, pred in zip(y_true, y_pred_top_k):\n",
    "        if true in pred[:k]:\n",
    "            hits += 1\n",
    "    return hits / len(y_true)\n",
    "\n",
    "def precision_at_30(y_true, y_pred_top_k):\n",
    "    correct_predictions = sum(1 for true, pred in zip(y_true, y_pred_top_k) if true in pred[:30])\n",
    "    return correct_predictions / len(y_pred_top_k)\n",
    "\n",
    "def recall_at_30(y_true, y_pred_top_k):\n",
    "    hits = sum(1 for true, pred in zip(y_true, y_pred_top_k) if true in pred[:30])\n",
    "    total_relevant = len(y_true)\n",
    "    return hits / total_relevant\n",
    "\n",
    "\n",
    "def average_precision_at_k(y_true, y_score, k=30):\n",
    "    y_true = np.asarray(y_true)[:k]\n",
    "    y_score = np.asarray(y_score)[:k]\n",
    "\n",
    "    if not y_true.any():\n",
    "        return 0\n",
    "\n",
    "    score = 0\n",
    "    num_hits = 0\n",
    "    for i, (p, rel) in enumerate(zip(y_score, y_true), 1):\n",
    "        if rel:\n",
    "            num_hits += 1\n",
    "            score += num_hits / i\n",
    "    return score / np.sum(y_true)\n",
    "\n",
    "def apk(actual, predicted, k=30):\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k=30):\n",
    "    return np.mean([apk(a, p, k) for a, p in zip(actual, predicted)])\n",
    "\n",
    "\n",
    "\n",
    "hit_rate = compute_hit_rate_at_k(y_true_names, y_pred_top_k, k)\n",
    "print(f\"Hit Rate at {k}: {hit_rate:.4f}\")\n",
    "precision_30 = precision_at_30(y_true_names, y_pred_top_k)\n",
    "print(f\"Precision@30: {precision_30:.4f}\")\n",
    "recall_30 = recall_at_30(y_true_names, y_pred_top_k)\n",
    "print(f\"Recall@30: {recall_30:.4f}\")\n",
    "map_score = mapk([[y] for y in y_true_names], y_pred_top_k, k=30)\n",
    "print(f\"MAP: {map_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean NDCG@30: 0.0128\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def precompute_logarithms(k):\n",
    "    return np.log2(np.arange(2, k + 2))\n",
    "\n",
    "def calculate_batch_ndcg(y_true_batch, y_pred_prob_batch, k, precomputed_logs):\n",
    "    top_k_indices = np.argpartition(y_pred_prob_batch, -k)[:, -k:]\n",
    "    ndcg_scores = []\n",
    "\n",
    "    for true_label, indices in zip(y_true_batch, top_k_indices):\n",
    "        sorted_indices = np.argsort(-y_pred_prob_batch[np.arange(len(indices)), indices])\n",
    "        is_relevant = (true_label == indices[sorted_indices]).astype(int)\n",
    "        dcg = np.sum((2**is_relevant - 1) / precomputed_logs[sorted_indices])\n",
    "        idcg = np.sum((2**1 - 1) / precomputed_logs[:np.sum(is_relevant)])\n",
    "        ndcg_score = dcg / idcg if idcg > 0 else 0\n",
    "        ndcg_scores.append(ndcg_score)\n",
    "\n",
    "    return np.mean(ndcg_scores)\n",
    "\n",
    "def calculate_ndcg_in_batches(y_true, y_pred_prob, k=30, batch_size=1000):\n",
    "    num_samples = y_true.shape[0]\n",
    "    precomputed_logs = precompute_logarithms(k)\n",
    "    ndcg_scores = []\n",
    "\n",
    "    for start_idx in range(0, num_samples, batch_size):\n",
    "        end_idx = start_idx + batch_size\n",
    "        batch_ndcg_score = calculate_batch_ndcg(\n",
    "            y_true[start_idx:end_idx],\n",
    "            y_pred_prob[start_idx:end_idx],\n",
    "            k,\n",
    "            precomputed_logs\n",
    "        )\n",
    "        ndcg_scores.append(batch_ndcg_score)\n",
    "\n",
    "    mean_ndcg = np.mean(ndcg_scores)\n",
    "    return mean_ndcg\n",
    "\n",
    "mean_ndcg_score = calculate_ndcg_in_batches(y_true, y_pred_prob, k=30, batch_size=1000)\n",
    "print(f\"Mean NDCG@30: {mean_ndcg_score:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
