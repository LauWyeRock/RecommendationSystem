{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8123e4ca",
   "metadata": {},
   "source": [
    "# Neural Collaborative Filtering\n",
    "\n",
    "Neural Collaborative Filtering (NCF) is an algorithm based on deep neural networks to tackle collaborative filtering on the basis of implicit feedback. Since we are using neural networks to find relation between users and items, we can easily scale the solution to large datasets. Thus making this method better than item based collaborative filtering.\n",
    "\n",
    "NCF works by first representing users and items as vectors in a latent space. These vectors are then used to calculate a score for each user-item pair. The score is then used to predict whether the user will interact with the item. NCF is useful because it can learn non-linear relationships between users and items. This makes it a more powerful model than traditional matrix factorization methods.\n",
    "\n",
    "Reference: [https://github.com/recommenders-team/recommenders/blob/main/examples/02_model_collaborative_filtering/ncf_deep_dive.ipynb]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbebba14",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a53ab250",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T05:27:38.330093Z",
     "iopub.status.busy": "2024-04-14T05:27:38.329314Z",
     "iopub.status.idle": "2024-04-14T05:27:50.657185Z",
     "shell.execute_reply": "2024-04-14T05:27:50.656111Z"
    },
    "papermill": {
     "duration": 12.565208,
     "end_time": "2024-04-14T05:27:50.659265",
     "exception": false,
     "start_time": "2024-04-14T05:27:38.094057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "WARNING:tensorflow:From C:\\Users\\e0559632\\AppData\\Roaming\\Python\\Python39\\site-packages\\recommenders\\models\\ncf\\ncf_singlenode.py:12: The name tf.disable_eager_execution is deprecated. Please use tf.compat.v1.disable_eager_execution instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]\n",
      "Pandas version: 1.4.2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from recommenders.utils.timer import Timer\n",
    "from recommenders.datasets.python_splitters import python_chrono_split, python_stratified_split\n",
    "\n",
    "from recommenders.models.ncf.dataset import Dataset as NCFDataset\n",
    "\n",
    "# Importing the NCF model class from the recommenders library\n",
    "from recommenders.models.ncf.ncf_singlenode import NCF\n",
    "\n",
    "# importing the evaluation metrics\n",
    "from recommenders.evaluation.python_evaluation import (rmse, mae, rsquared, exp_var, map_at_k, ndcg_at_k, precision_at_k,\n",
    "                                                     recall_at_k, get_top_k_items,\n",
    "                                                     catalog_coverage, distributional_coverage, novelty, diversity, serendipity)\n",
    "from recommenders.utils.constants import SEED as DEFAULT_SEED\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Pandas version: {}\".format(pd.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62df1bbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T05:27:51.122823Z",
     "iopub.status.busy": "2024-04-14T05:27:51.121802Z",
     "iopub.status.idle": "2024-04-14T05:27:53.407743Z",
     "shell.execute_reply": "2024-04-14T05:27:53.406682Z"
    },
    "papermill": {
     "duration": 2.522266,
     "end_time": "2024-04-14T05:27:53.410088",
     "exception": false,
     "start_time": "2024-04-14T05:27:50.887822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 51548 entries, 0 to 393030\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   userID  51548 non-null  int64\n",
      " 1   itemID  51548 non-null  int64\n",
      " 2   rating  51548 non-null  int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 1.6 MB\n"
     ]
    }
   ],
   "source": [
    "df_full = pd.read_csv('users_feature_eng.csv')[['Username', 'track_name', 'artist_name',\n",
    "                                                    'rank',\n",
    "                                                    # 'playcount'\n",
    "                                                    ]]\n",
    "df_full['track'] = df_full['track_name'] + ' ' + df_full['artist_name']\n",
    "df_full['itemID'] = df_full.groupby('track').ngroup() + 1\n",
    "df_full['userID'] = df_full.groupby('Username').ngroup() + 1\n",
    "\n",
    "# df = df_full.copy()\n",
    "df_full.rename(columns={'rank': 'rating'}, inplace=True)\n",
    "# df.rename(columns={'playcount': 'rating'}, inplace=True)\n",
    "df_full = df_full.drop(['track', 'track_name', 'artist_name', 'Username'], axis = 1)\n",
    "\n",
    "# # using a subset of data to reduce runtime to manageable duration, select users who have more than 48 top songs\n",
    "threshold = 48\n",
    "df_full = df_full[df_full.groupby('userID')['userID'].transform('size') > threshold]\n",
    "df_full = df_full[['userID', 'itemID', 'rating']]\n",
    "df_full.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84773a6e",
   "metadata": {},
   "source": [
    "Stratified Split: this is similar to random sampling, but the splits are stratified, for example if the datasets are split by user, the splitting approach will attempt to maintain the same ratio of items used in both training and test splits. The converse is true if splitting by item.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "beac0684",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T05:27:53.885610Z",
     "iopub.status.busy": "2024-04-14T05:27:53.885279Z",
     "iopub.status.idle": "2024-04-14T05:27:57.870119Z",
     "shell.execute_reply": "2024-04-14T05:27:57.869104Z"
    },
    "papermill": {
     "duration": 4.221572,
     "end_time": "2024-04-14T05:27:57.872118",
     "exception": false,
     "start_time": "2024-04-14T05:27:53.650546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119014</th>\n",
       "      <td>6</td>\n",
       "      <td>92294</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185573</th>\n",
       "      <td>6</td>\n",
       "      <td>18824</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153328</th>\n",
       "      <td>10</td>\n",
       "      <td>121378</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219164</th>\n",
       "      <td>10</td>\n",
       "      <td>83514</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270950</th>\n",
       "      <td>10</td>\n",
       "      <td>129097</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        userID  itemID  rating\n",
       "119014       6   92294      33\n",
       "185573       6   18824       3\n",
       "153328      10  121378      17\n",
       "219164      10   83514      10\n",
       "270950      10  129097      32"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split the dataset into 75% train and 25% test\n",
    "\n",
    "# header = {\n",
    "#     \"col_user\": \"userID\",\n",
    "#     \"col_item\": \"itemID\",\n",
    "#     \"col_rank\": \"rank\",\n",
    "#     # \"col_rank\": 'playcount',\n",
    "#     \"col_prediction\": \"Prediction\",\n",
    "# }\n",
    "\n",
    "\n",
    "train, test = python_stratified_split(\n",
    "    df_full, ratio=0.8,\n",
    "    #   col_user=\"userID\", col_item=\"itemID\", seed=42\n",
    ")\n",
    "\n",
    "# Filtering out users and items in the test set that do not appear in the training set.\n",
    "# This is done so that we can see if our model has learnt user's previous item interactions and can recommend relevant items.\n",
    "test = test[test[\"userID\"].isin(train[\"userID\"].unique())]\n",
    "test = test[test[\"itemID\"].isin(train[\"itemID\"].unique())]\n",
    "\n",
    "# Creating a test set which only contains the last interaction for each user. Remaining data of the user is used in the train set\n",
    "leave_one_out_test = test.groupby(\"userID\").last().reset_index()\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f9adae7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T05:27:58.412490Z",
     "iopub.status.busy": "2024-04-14T05:27:58.412114Z",
     "iopub.status.idle": "2024-04-14T05:27:58.417542Z",
     "shell.execute_reply": "2024-04-14T05:27:58.416696Z"
    },
    "papermill": {
     "duration": 0.27043,
     "end_time": "2024-04-14T05:27:58.419465",
     "exception": false,
     "start_time": "2024-04-14T05:27:58.149035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# top k items to recommend\n",
    "TOP_K = 30\n",
    "\n",
    "# Model parameters\n",
    "# Number of iterations during the training process\n",
    "EPOCHS = 100\n",
    "# Batch size means how many user-item pairs you want to predict at once\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "# Setting seed to remove any stochasticity and reproduce results\n",
    "SEED = DEFAULT_SEED  # Set None for non-deterministic results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f73d4f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T05:27:58.888873Z",
     "iopub.status.busy": "2024-04-14T05:27:58.887941Z",
     "iopub.status.idle": "2024-04-14T05:27:58.893173Z",
     "shell.execute_reply": "2024-04-14T05:27:58.892196Z"
    },
    "papermill": {
     "duration": 0.241436,
     "end_time": "2024-04-14T05:27:58.895205",
     "exception": false,
     "start_time": "2024-04-14T05:27:58.653769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Writing the data into csv files\n",
    "train_file = \"train.csv\"\n",
    "test_file = \"test.csv\"\n",
    "leave_one_out_test_file = \"leave_one_out_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "160e6e62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T05:27:59.394013Z",
     "iopub.status.busy": "2024-04-14T05:27:59.393621Z",
     "iopub.status.idle": "2024-04-14T05:27:59.562964Z",
     "shell.execute_reply": "2024-04-14T05:27:59.562045Z"
    },
    "papermill": {
     "duration": 0.436211,
     "end_time": "2024-04-14T05:27:59.565279",
     "exception": false,
     "start_time": "2024-04-14T05:27:59.129068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.to_csv(train_file, index=False)\n",
    "test.to_csv(test_file, index=False)\n",
    "leave_one_out_test.to_csv(leave_one_out_test_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d2a6aa2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T05:28:00.072711Z",
     "iopub.status.busy": "2024-04-14T05:28:00.071969Z",
     "iopub.status.idle": "2024-04-14T05:28:21.835870Z",
     "shell.execute_reply": "2024-04-14T05:28:21.835007Z"
    },
    "papermill": {
     "duration": 21.999448,
     "end_time": "2024-04-14T05:28:21.838284",
     "exception": false,
     "start_time": "2024-04-14T05:27:59.838836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:recommenders.models.ncf.dataset:Indexing train.csv ...\n",
      "INFO:recommenders.models.ncf.dataset:Indexing leave_one_out_test.csv ...\n",
      "INFO:recommenders.models.ncf.dataset:Creating full leave-one-out test file leave_one_out_test_full.csv ...\n",
      "100%|██████████| 997/997 [00:13<00:00, 73.23it/s]\n",
      "INFO:recommenders.models.ncf.dataset:Indexing leave_one_out_test_full.csv ...\n"
     ]
    }
   ],
   "source": [
    "data = NCFDataset(train_file=train_file, test_file=leave_one_out_test_file, seed=SEED, overwrite_test_file_full=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415f0298",
   "metadata": {},
   "source": [
    "## Training the NCF Model\n",
    "\n",
    "NCF parameters:\n",
    "\n",
    "`n_users`, number of users. We are one hot encoding our user data. Therefore the input size of the model will be number of users.\n",
    "\n",
    "`n_items`, number of items. Same logic as `n_users`.\n",
    "\n",
    "`batch_size`, number of examples you want the model to process at a time. Higher value will consume more memory.\n",
    "\n",
    "`learning_rate`, this can be thought of as how much you want the model to change after one iteration. Large value will lead to unstability and very small values will take more time to converge.\n",
    "\n",
    "`n_factors`, which controls the dimension of the latent space. Usually, the quality of the training set predictions grows with as n_factors gets higher.\n",
    "\n",
    "`layer_sizes`, sizes of input layer (and hidden layers) of MLP, input type is list. We have set it to [32,16,8,4], [64,32,16,8,4], [64, 32, 16, 8] as from training and testing, higher values gave better results. We have explored running the model with different layer sizes, finally deciding on [64, 32, 16, 8] due to performance and time cost.\n",
    "\n",
    "`n_epochs`, which defines the number of iteration of the SGD procedure. Note that both parameter also affect the training time.\n",
    "\n",
    "`model_type`, we can train single \"MLP\", \"GMF\" or combined model \"NCF\" by changing the type of model.\n",
    "\n",
    "[Reference: https://github.com/recommenders-team/recommenders/blob/main/examples/02_model_collaborative_filtering/ncf_deep_dive.ipynb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f44616a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T05:28:22.368849Z",
     "iopub.status.busy": "2024-04-14T05:28:22.368428Z",
     "iopub.status.idle": "2024-04-14T05:28:23.494600Z",
     "shell.execute_reply": "2024-04-14T05:28:23.493515Z"
    },
    "papermill": {
     "duration": 1.410561,
     "end_time": "2024-04-14T05:28:23.496973",
     "exception": false,
     "start_time": "2024-04-14T05:28:22.086412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\e0559632\\AppData\\Roaming\\Python\\Python39\\site-packages\\recommenders\\models\\ncf\\ncf_singlenode.py:264: The name tf.losses.log_loss is deprecated. Please use tf.compat.v1.losses.log_loss instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\e0559632\\AppData\\Roaming\\Python\\Python39\\site-packages\\recommenders\\models\\ncf\\ncf_singlenode.py:269: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = NCF (\n",
    "    n_users=data.n_users,\n",
    "    n_items=data.n_items,\n",
    "    model_type=\"NeuMF\",\n",
    "    n_factors=4,\n",
    "    layer_sizes=[64,32,16,8],\n",
    "    n_epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    learning_rate=1e-3,\n",
    "    verbose=10,\n",
    "    seed=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "867a299c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T05:28:23.993623Z",
     "iopub.status.busy": "2024-04-14T05:28:23.993257Z",
     "iopub.status.idle": "2024-04-14T06:11:02.452897Z",
     "shell.execute_reply": "2024-04-14T06:11:02.451956Z"
    },
    "papermill": {
     "duration": 2558.998572,
     "end_time": "2024-04-14T06:11:02.744945",
     "exception": false,
     "start_time": "2024-04-14T05:28:23.746373",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 10 [8.85s]: train_loss = 0.087081 \n",
      "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 20 [8.54s]: train_loss = 0.035409 \n",
      "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 30 [8.73s]: train_loss = 0.020464 \n",
      "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 40 [8.64s]: train_loss = 0.015794 \n",
      "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 50 [8.79s]: train_loss = 0.012869 \n",
      "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 60 [8.78s]: train_loss = 0.010372 \n",
      "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 70 [8.59s]: train_loss = 0.009050 \n",
      "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 80 [8.67s]: train_loss = 0.008748 \n",
      "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 90 [8.64s]: train_loss = 0.007571 \n",
      "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 100 [8.69s]: train_loss = 0.006530 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 868.1762786999999 seconds for training.\n"
     ]
    }
   ],
   "source": [
    "with Timer() as train_time:\n",
    "    model.fit(data)\n",
    "\n",
    "print(\"Took {} seconds for training.\".format(train_time.interval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64ebbc96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T06:11:03.231353Z",
     "iopub.status.busy": "2024-04-14T06:11:03.231003Z",
     "iopub.status.idle": "2024-04-14T06:11:03.406811Z",
     "shell.execute_reply": "2024-04-14T06:11:03.405981Z"
    },
    "papermill": {
     "duration": 0.422355,
     "end_time": "2024-04-14T06:11:03.408997",
     "exception": false,
     "start_time": "2024-04-14T06:11:02.986642",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save the model\n",
    "# https://github.com/recommenders-team/recommenders/issues/1735\n",
    "dir_path = 'NCF_model_trained'\n",
    "model.save(dir_path)\n",
    "# # and then while loading depending on the type of your model in this case neumf pass it that dir parameter\n",
    "# model.load(neumf_dir='dir_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "133136c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T06:11:03.897372Z",
     "iopub.status.busy": "2024-04-14T06:11:03.897022Z",
     "iopub.status.idle": "2024-04-14T06:11:04.890086Z",
     "shell.execute_reply": "2024-04-14T06:11:04.889001Z"
    },
    "papermill": {
     "duration": 1.238432,
     "end_time": "2024-04-14T06:11:04.892558",
     "exception": false,
     "start_time": "2024-04-14T06:11:03.654126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\e0559632\\AppData\\Roaming\\Python\\Python39\\site-packages\\recommenders\\models\\ncf\\ncf_singlenode.py:264: The name tf.losses.log_loss is deprecated. Please use tf.compat.v1.losses.log_loss instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\e0559632\\AppData\\Roaming\\Python\\Python39\\site-packages\\recommenders\\models\\ncf\\ncf_singlenode.py:269: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from NCF_model_trained\\model.ckpt\n"
     ]
    }
   ],
   "source": [
    "model = NCF(\n",
    "    n_users=data.n_users,\n",
    "    n_items=data.n_items,\n",
    "    model_type=\"NeuMF\",\n",
    "    n_factors=4,\n",
    "    layer_sizes=[64,32,16,8],\n",
    "    n_epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    learning_rate=1e-3,\n",
    "    verbose=10,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "dir_path = 'NCF_model_trained'\n",
    "model.load(neumf_dir = dir_path)\n",
    "\n",
    "model.user2id = data.user2id\n",
    "model.item2id = data.item2id\n",
    "model.id2user = data.id2user\n",
    "model.id2item = data.id2item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d98944",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "\n",
    "After fitting the model, we can call `predict` to get some predictions. `predict` returns an internal object Prediction which can be easily converted back to a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ca4290",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T06:11:05.382855Z",
     "iopub.status.busy": "2024-04-14T06:11:05.382159Z",
     "iopub.status.idle": "2024-04-14T06:11:13.571290Z",
     "shell.execute_reply": "2024-04-14T06:11:13.570278Z"
    },
    "papermill": {
     "duration": 8.437246,
     "end_time": "2024-04-14T06:11:13.574019",
     "exception": false,
     "start_time": "2024-04-14T06:11:05.136773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = [[row.userID, row.itemID, model.predict(row.userID, row.itemID)]\n",
    "               for (_, row) in test.iterrows()]\n",
    "\n",
    "predictions = pd.DataFrame(predictions, columns=['userID', 'itemID', 'prediction'])\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "411d203b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T06:11:14.071131Z",
     "iopub.status.busy": "2024-04-14T06:11:14.070237Z",
     "iopub.status.idle": "2024-04-14T06:22:38.893009Z",
     "shell.execute_reply": "2024-04-14T06:22:38.891986Z"
    },
    "papermill": {
     "duration": 685.313804,
     "end_time": "2024-04-14T06:22:39.141969",
     "exception": false,
     "start_time": "2024-04-14T06:11:13.828165",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 35.29185000000007 seconds for prediction.\n"
     ]
    }
   ],
   "source": [
    "with Timer() as test_time:\n",
    "\n",
    "    users, items, preds = [], [], []\n",
    "    item = list(train.itemID.unique())\n",
    "    for user in train.userID.unique():\n",
    "        user = [user] * len(item)\n",
    "        users.extend(user)\n",
    "        items.extend(item)\n",
    "        preds.extend(list(model.predict(user, item, is_list=True)))\n",
    "\n",
    "    all_predictions = pd.DataFrame(data={\"userID\": users, \"itemID\":items, \"prediction\":preds})\n",
    "\n",
    "    merged = pd.merge(train, all_predictions, on=[\"userID\", \"itemID\"], how=\"outer\")\n",
    "    all_predictions = merged[merged.rating.isnull()].drop('rating', axis=1)\n",
    "\n",
    "print(\"Took {} seconds for prediction.\".format(test_time.interval))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f69a6ea",
   "metadata": {},
   "source": [
    "## General Evaluation\n",
    "\n",
    "We remove songs that are already users' top songs in the top k recommendations. To compute ranking metrics, we need predictions on all user, item pairs. We do not want to recommend the same item again to the user.\n",
    "\n",
    "- Ranking Metrics: These are used to evaluate how relevant recommendations are for users\n",
    "\n",
    "MAP - It is the average precision for each user normalized over all users.\n",
    "\n",
    "Normalized Discounted Cumulative Gain (NDCG) - evaluates how well the predicted items for a user are ranked based on relevance\n",
    "\n",
    "Precision - this measures the proportion of recommended items that are relevant\n",
    "\n",
    "Recall - this measures the proportion of relevant items that are recommended\n",
    "\n",
    "\n",
    "- Rating Metrics: These are used to evaluate how accurate a recommender is at predicting ratings that users gave to items\n",
    "\n",
    "Root Mean Square Error (RMSE) - measure of average error in predicted ratings\n",
    "\n",
    "R Squared (R2) - essentially how much of the total variation is explained by the model\n",
    "\n",
    "Mean Absolute Error (MAE) - similar to RMSE but uses absolute value instead of squaring and taking the root of the average\n",
    "\n",
    "Explained Variance - how much of the variance in the data is explained by the model\n",
    "\n",
    "\n",
    "- Non accuracy based metrics: These do not compare predictions against ground truth but instead evaluate the following properties of the recommendations\n",
    "\n",
    "Novelty - measures of how novel recommendation items are by calculating their recommendation frequency among users\n",
    "\n",
    "Diversity - measures of how different items in a set are with respect to each other\n",
    "\n",
    "Serendipity - measures of how surprising recommendations are to to a specific user by comparing them to the items that the user has already interacted with\n",
    "\n",
    "Coverage - measures related to the distribution of items recommended by the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57b0b445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0197592778335005 \n",
      " Recall: 0.08884550476827306\n"
     ]
    }
   ],
   "source": [
    "eval_precision = precision_at_k(test, all_predictions, col_prediction='prediction', k=TOP_K)\n",
    "eval_recall = recall_at_k(test, all_predictions, col_prediction='prediction', k=TOP_K)\n",
    "print(f\"Precision: {eval_precision} \\n Recall: {eval_recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbbeba0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@K: 0.02211773740976093\n"
     ]
    }
   ],
   "source": [
    "eval_map = map_at_k(test, all_predictions, col_prediction='prediction', k=TOP_K)\n",
    "print(f\"MAP@K: {eval_map}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c27656e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG@K: 0.05895727619663889\n"
     ]
    }
   ],
   "source": [
    "eval_ndcg = ndcg_at_k(test, all_predictions, col_prediction='prediction', k=TOP_K)\n",
    "print(f\"NDCG@K: {eval_ndcg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac313d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26609537\n",
      "31350\n"
     ]
    }
   ],
   "source": [
    "# Prepare for diversity based evaluations\n",
    "\n",
    "# Merge all_predictions with train on userID and itemID\n",
    "merged_df = pd.merge(all_predictions, train, left_on=['userID', 'itemID'], right_on=['userID', 'itemID'], how='outer')\n",
    "\n",
    "# Filter out the rows where train.rating is null\n",
    "top_all = merged_df[merged_df['rating'].isnull()]\n",
    "top_all = top_all[['userID', 'itemID', 'prediction']]\n",
    "print(top_all.shape[0])\n",
    "\n",
    "# Sort top_all DataFrame by 'prediction' column within each 'userID' group in descending order\n",
    "top_all_sorted = top_all.sort_values(by=['userID', 'prediction'], ascending=[True, False])\n",
    "\n",
    "# Group by 'userID' and take the top_k items for each group\n",
    "top_k_reco = top_all_sorted.groupby('userID').head(TOP_K)\n",
    "print(top_k_reco.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acc6fee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diversity: 0.9534591327062832\n",
      "Novelty: 12.78564042556168\n",
      "distributional_coverage: 11.260640133456693\n",
      "catalog_coverage: 0.2012704387719092\n",
      "serendipity: 0.9810615281060834\n"
     ]
    }
   ],
   "source": [
    "eval_diversity = diversity(train, top_k_reco, col_user='userID', col_item='itemID')\n",
    "print(f\"Diversity: {eval_diversity}\")\n",
    "\n",
    "eval_novelty = novelty(train, top_k_reco, col_user='userID', col_item='itemID')\n",
    "print(f\"Novelty: {eval_novelty}\")\n",
    "\n",
    "eval_distributional_coverage = distributional_coverage(train, top_k_reco, col_user='userID', col_item='itemID')\n",
    "print(f\"distributional_coverage: {eval_distributional_coverage}\")\n",
    "\n",
    "eval_catalog_coverage = catalog_coverage(train, top_k_reco, col_user='userID', col_item='itemID')\n",
    "print(f\"catalog_coverage: {eval_catalog_coverage}\")\n",
    "\n",
    "eval_serendipity = serendipity(train, top_k_reco, col_user='userID', col_item='itemID')\n",
    "print(f\"serendipity: {eval_serendipity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf360d69",
   "metadata": {},
   "source": [
    "### Summary of Ranking Metrics\n",
    "\n",
    "<center>\n",
    "\n",
    "|Metric|Range|Selection criteria|Limitation|\n",
    "|------|-------------------------------|---------|----------|\n",
    "|Precision|$\\geq 0$ and $\\leq 1$|Higher the better.|Only for hits in recommendations.|\n",
    "|Recall|$\\geq 0$ and $\\leq 1$|Higher the better.|Only for hits in the ground truth.|\n",
    "|NDCG|$\\geq 0$ and $\\leq 1$|Higher the better.|Does not penalize for bad/missing items, and does not perform for several equally good items.|\n",
    "|MAP|$\\geq 0$ and $\\leq 1$|Higher the better.|Depend on variable distributions.|\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2f5349",
   "metadata": {},
   "source": [
    "## \"Leave-one-out\" Evaluation\n",
    "For each item in test data, we randomly samples 100 items that are not interacted by the user, ranking the test item among the 101 items (1 positive item and 100 negative items). The performance of a ranked list is judged by Hit Ratio (HR) and Normalized Discounted Cumulative Gain (NDCG). Finally, we average the values of those ranked lists to obtain the overall HR and NDCG on test data.\n",
    "\n",
    "We truncated the ranked list at 10 for both metrics. As such, the HR intuitively measures whether the test item is present on the top-10 list, and the NDCG accounts for the position of the hit by assigning higher scores to hits at top ranks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f15d1908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR:\t0.751254\n",
      "NDCG:\t0.549389\n"
     ]
    }
   ],
   "source": [
    "k = TOP_K\n",
    "\n",
    "ndcgs = []\n",
    "hit_ratio = []\n",
    "\n",
    "for b in data.test_loader():\n",
    "    user_input, item_input, labels = b\n",
    "    output = model.predict(user_input, item_input, is_list=True)\n",
    "\n",
    "    output = np.squeeze(output)\n",
    "    rank = sum(output >= output[0])\n",
    "    if rank <= k:\n",
    "        ndcgs.append(1 / np.log(rank + 1))\n",
    "        hit_ratio.append(1)\n",
    "    else:\n",
    "        ndcgs.append(0)\n",
    "        hit_ratio.append(0)\n",
    "\n",
    "eval_ndcg = np.mean(ndcgs)\n",
    "eval_hr = np.mean(hit_ratio)\n",
    "\n",
    "print(\"HR:\\t%f\" % eval_hr)\n",
    "print(\"NDCG:\\t%f\" % eval_ndcg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce526e32",
   "metadata": {
    "papermill": {
     "duration": 0.3087,
     "end_time": "2024-04-14T06:22:39.715390",
     "exception": false,
     "start_time": "2024-04-14T06:22:39.406690",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Pre-train with GMF and MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f329cb97",
   "metadata": {},
   "source": [
    "To get better performance of NeuMF, we can adopt pre-training strategy. We train GMF and MLP and then use their model parameters as the initialization for the corresponding parts of NeuMF’s parameters. \n",
    "\n",
    "We then evaluate pre-trained model using the same evaluation metrics. Compared with not pre-trained NMF, all evaluation metrics had slight improvements. The performance of pre-trained NCF is better than the not pre-trained.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe5ff7c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T06:22:40.223083Z",
     "iopub.status.busy": "2024-04-14T06:22:40.222269Z",
     "iopub.status.idle": "2024-04-14T07:02:55.953958Z",
     "shell.execute_reply": "2024-04-14T07:02:55.953016Z"
    },
    "papermill": {
     "duration": 2416.286141,
     "end_time": "2024-04-14T07:02:56.248822",
     "exception": false,
     "start_time": "2024-04-14T06:22:39.962681",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 10 [6.98s]: train_loss = 0.367336 \n",
      "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 20 [6.55s]: train_loss = 0.281015 \n",
      "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 30 [7.27s]: train_loss = 0.242760 \n",
      "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 40 [6.57s]: train_loss = 0.227738 \n",
      "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 50 [6.48s]: train_loss = 0.218232 \n",
      "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 60 [6.98s]: train_loss = 0.211604 \n",
      "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 70 [6.60s]: train_loss = 0.206801 \n",
      "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 80 [6.83s]: train_loss = 0.201693 \n",
      "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 90 [7.12s]: train_loss = 0.197851 \n",
      "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 100 [6.67s]: train_loss = 0.196545 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 677.2953388999999 seconds for training GMF.\n"
     ]
    }
   ],
   "source": [
    "model = NCF(\n",
    "    n_users=data.n_users,\n",
    "    n_items=data.n_items,\n",
    "    model_type=\"GMF\",\n",
    "    n_factors=4,\n",
    "    layer_sizes=[64,32,16,8],\n",
    "    n_epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    learning_rate=1e-3,\n",
    "    verbose=10,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "with Timer() as train_time:\n",
    "    model.fit(data)\n",
    "\n",
    "print(\"Took {} seconds for training GMF.\".format(train_time.interval))\n",
    "\n",
    "model.save(dir_name=\".pretrain/GMF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d38a3ba0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T07:02:56.749548Z",
     "iopub.status.busy": "2024-04-14T07:02:56.748669Z",
     "iopub.status.idle": "2024-04-14T07:44:59.311024Z",
     "shell.execute_reply": "2024-04-14T07:44:59.310078Z"
    },
    "papermill": {
     "duration": 2523.079129,
     "end_time": "2024-04-14T07:44:59.573850",
     "exception": false,
     "start_time": "2024-04-14T07:02:56.494721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 10 [9.18s]: train_loss = 0.140024 \n",
      "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 20 [8.63s]: train_loss = 0.057390 \n",
      "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 30 [8.98s]: train_loss = 0.036796 \n",
      "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 40 [8.67s]: train_loss = 0.026088 \n",
      "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 50 [8.51s]: train_loss = 0.019848 \n",
      "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 60 [8.95s]: train_loss = 0.015442 \n",
      "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 70 [8.68s]: train_loss = 0.013119 \n",
      "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 80 [8.83s]: train_loss = 0.010964 \n",
      "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 90 [8.45s]: train_loss = 0.009063 \n",
      "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 100 [8.35s]: train_loss = 0.008663 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 879.0392510000001 seconds for training MLP.\n"
     ]
    }
   ],
   "source": [
    "model = NCF(\n",
    "    n_users=data.n_users,\n",
    "    n_items=data.n_items,\n",
    "    model_type=\"MLP\",\n",
    "    n_factors=4,\n",
    "    layer_sizes=[64,32,16,8],\n",
    "    n_epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    learning_rate=1e-3,\n",
    "    verbose=10,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "with Timer() as train_time:\n",
    "    model.fit(data)\n",
    "\n",
    "print(\"Took {} seconds for training MLP.\".format(train_time.interval))\n",
    "\n",
    "model.save(dir_name=\".pretrain/MLP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0566567",
   "metadata": {},
   "source": [
    "## Training and evaluating pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "096a9ac7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T07:45:00.062032Z",
     "iopub.status.busy": "2024-04-14T07:45:00.061126Z",
     "iopub.status.idle": "2024-04-14T07:45:00.065895Z",
     "shell.execute_reply": "2024-04-14T07:45:00.064986Z"
    },
    "papermill": {
     "duration": 0.251691,
     "end_time": "2024-04-14T07:45:00.067747",
     "exception": false,
     "start_time": "2024-04-14T07:44:59.816056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from .pretrain/GMF\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from .pretrain/MLP\\model.ckpt\n",
      "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 10 [8.90s]: train_loss = 0.006516 \n",
      "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 20 [8.80s]: train_loss = 0.005565 \n",
      "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 30 [8.95s]: train_loss = 0.005321 \n",
      "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 40 [9.13s]: train_loss = 0.005083 \n",
      "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 50 [8.95s]: train_loss = 0.004585 \n",
      "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 60 [8.87s]: train_loss = 0.004313 \n",
      "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 70 [9.42s]: train_loss = 0.004628 \n",
      "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 80 [8.69s]: train_loss = 0.003939 \n",
      "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 90 [8.72s]: train_loss = 0.003665 \n",
      "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 100 [8.45s]: train_loss = 0.003519 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 886.9909207000001 seconds for training pre-trained NeuMF.\n"
     ]
    }
   ],
   "source": [
    "model = NCF(\n",
    "    n_users=data.n_users,\n",
    "    n_items=data.n_items,\n",
    "    model_type=\"NeuMF\",\n",
    "    n_factors=4,\n",
    "    layer_sizes=[64,32,16,8],\n",
    "    n_epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    learning_rate=1e-3,\n",
    "    verbose=10,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "model.load(gmf_dir=\".pretrain/GMF\", mlp_dir=\".pretrain/MLP\", alpha=0.5)\n",
    "\n",
    "model.user2id = data.user2id\n",
    "model.item2id = data.item2id\n",
    "model.id2user = data.id2user\n",
    "model.id2item = data.id2item\n",
    "\n",
    "with Timer() as train_time:\n",
    "    model.fit(data)\n",
    "\n",
    "print(\"Took {} seconds for training pre-trained NeuMF.\".format(train_time.interval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "842f2f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 35.10330669999985 seconds for prediction.\n"
     ]
    }
   ],
   "source": [
    "with Timer() as test_time:\n",
    "\n",
    "    users, items, preds = [], [], []\n",
    "    item = list(train.itemID.unique())\n",
    "    for user in train.userID.unique():\n",
    "        user = [user] * len(item)\n",
    "        users.extend(user)\n",
    "        items.extend(item)\n",
    "        preds.extend(list(model.predict(user, item, is_list=True)))\n",
    "\n",
    "    all_predictions = pd.DataFrame(data={\"userID\": users, \"itemID\":items, \"prediction\":preds})\n",
    "\n",
    "    merged = pd.merge(train, all_predictions, on=[\"userID\", \"itemID\"], how=\"outer\")\n",
    "    all_predictions = merged[merged.rating.isnull()].drop('rating', axis=1)\n",
    "\n",
    "print(\"Took {} seconds for prediction.\".format(test_time.interval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9794b332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.022801738548980273 \n",
      " Recall: 0.09940217477830315\n"
     ]
    }
   ],
   "source": [
    "eval_precision = precision_at_k(test, all_predictions, col_prediction='prediction', k=TOP_K)\n",
    "eval_recall = recall_at_k(test, all_predictions, col_prediction='prediction', k=TOP_K)\n",
    "print(f\"Precision: {eval_precision} \\n Recall: {eval_recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a34a2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@K: 0.02549432604837352\n"
     ]
    }
   ],
   "source": [
    "eval_map = map_at_k(test, all_predictions, col_prediction='prediction', k=TOP_K)\n",
    "print(f\"MAP@K: {eval_map}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "718655a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG@K: 0.06705734850071839\n"
     ]
    }
   ],
   "source": [
    "eval_ndcg = ndcg_at_k(test, all_predictions, col_prediction='prediction', k=TOP_K)\n",
    "print(f\"NDCG@K: {eval_ndcg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d238ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26609537\n",
      "31350\n"
     ]
    }
   ],
   "source": [
    "# Prepare for diversity based evaluations\n",
    "\n",
    "# Merge all_predictions with train on userID and itemID\n",
    "merged_df = pd.merge(all_predictions, train, left_on=['userID', 'itemID'], right_on=['userID', 'itemID'], how='outer')\n",
    "\n",
    "# Filter out the rows where train.rating is null\n",
    "top_all = merged_df[merged_df['rating'].isnull()]\n",
    "top_all = top_all[['userID', 'itemID', 'prediction']]\n",
    "print(top_all.shape[0])\n",
    "\n",
    "# Sort top_all DataFrame by 'prediction' column within each 'userID' group in descending order\n",
    "top_all_sorted = top_all.sort_values(by=['userID', 'prediction'], ascending=[True, False])\n",
    "\n",
    "# Group by 'userID' and take the top_k items for each group\n",
    "top_k_reco = top_all_sorted.groupby('userID').head(TOP_K)\n",
    "print(top_k_reco.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "da18ff8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diversity: 0.9493022304063957\n",
      "Novelty: 12.691264663902116\n",
      "distributional_coverage: 11.13977560085456\n",
      "catalog_coverage: 0.18774261851546878\n",
      "serendipity: 0.9783733991118525\n"
     ]
    }
   ],
   "source": [
    "eval_diversity = diversity(train, top_k_reco, col_user='userID', col_item='itemID')\n",
    "print(f\"Diversity: {eval_diversity}\")\n",
    "\n",
    "eval_novelty = novelty(train, top_k_reco, col_user='userID', col_item='itemID')\n",
    "print(f\"Novelty: {eval_novelty}\")\n",
    "\n",
    "eval_distributional_coverage = distributional_coverage(train, top_k_reco, col_user='userID', col_item='itemID')\n",
    "print(f\"distributional_coverage: {eval_distributional_coverage}\")\n",
    "\n",
    "eval_catalog_coverage = catalog_coverage(train, top_k_reco, col_user='userID', col_item='itemID')\n",
    "print(f\"catalog_coverage: {eval_catalog_coverage}\")\n",
    "\n",
    "eval_serendipity = serendipity(train, top_k_reco, col_user='userID', col_item='itemID')\n",
    "print(f\"serendipity: {eval_serendipity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80e766f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR:\t0.743230\n",
      "NDCG:\t0.563786\n"
     ]
    }
   ],
   "source": [
    "# \"Leave-one-out\" Evaluation\n",
    "k = TOP_K\n",
    "\n",
    "ndcgs = []\n",
    "hit_ratio = []\n",
    "\n",
    "for b in data.test_loader():\n",
    "    user_input, item_input, labels = b\n",
    "    output = model.predict(user_input, item_input, is_list=True)\n",
    "\n",
    "    output = np.squeeze(output)\n",
    "    rank = sum(output >= output[0])\n",
    "    if rank <= k:\n",
    "        ndcgs.append(1 / np.log(rank + 1))\n",
    "        hit_ratio.append(1)\n",
    "    else:\n",
    "        ndcgs.append(0)\n",
    "        hit_ratio.append(0)\n",
    "\n",
    "eval_ndcg = np.mean(ndcgs)\n",
    "eval_hr = np.mean(hit_ratio)\n",
    "\n",
    "print(\"HR:\\t%f\" % eval_hr)\n",
    "print(\"NDCG:\\t%f\" % eval_ndcg)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4787206,
     "sourceId": 8105469,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4792790,
     "sourceId": 8113037,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30684,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8721.672728,
   "end_time": "2024-04-14T07:45:03.346550",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-14T05:19:41.673822",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
