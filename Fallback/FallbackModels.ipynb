{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading of Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"../../Downloads/songs_feature_eng_pca.csv\")\n",
    "df = df[['track_name', \"artist_name\", \"PC1\", \"PC2\", \"PC3\", \"PC4\", \"PC5\", \"PC6\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine Similarity using Annoy Package\n",
    "\n",
    "We use the 6 different Principal Components to find the top 5 most similar tracks using cosine similarity, denoted by 'angular' using the Annoy package. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m pcs \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPC1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPC2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPC3\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPC4\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPC5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPC6\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[0;32m      7\u001b[0m f \u001b[38;5;241m=\u001b[39m pcs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      9\u001b[0m t \u001b[38;5;241m=\u001b[39m AnnoyIndex(f, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mangular\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# 'angular' is equivalent to cosine similarity\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "from annoy import AnnoyIndex\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pcs = df[['PC1', \"PC2\", \"PC3\", \"PC4\", \"PC5\", \"PC6\"]]\n",
    "\n",
    "f = pcs.shape[1]\n",
    "\n",
    "t = AnnoyIndex(f, 'angular')  # 'angular' is equivalent to cosine similarity\n",
    "\n",
    "for i, vector in enumerate(pcs.to_numpy()):\n",
    "    t.add_item(i, vector)\n",
    "\n",
    "t.build(10) # Adjust more - more precise but take longer\n",
    "\n",
    "top_5_similar = {i: [] for i in range(pcs.shape[0])}\n",
    "\n",
    "for i in range(pcs.shape[0]):\n",
    "    nearest = t.get_nns_by_item(i, 6, include_distances=True)\n",
    "    \n",
    "    indices, distances = nearest[0][1:], nearest[1][1:]\n",
    "    \n",
    "    similarities = [1 - d for d in distances]\n",
    "    \n",
    "    top_5_similar[i] = list(zip(indices, similarities))\n",
    "\n",
    "for i in range(1, 6):\n",
    "    df[f'Track_Name_{i}'] = np.nan\n",
    "    df[f'Artist_Name_{i}'] = np.nan\n",
    "    df[f'Similarity_{i}'] = np.nan\n",
    "\n",
    "for idx, sims in top_5_similar.items():\n",
    "    for i, (sim_idx, sim_score) in enumerate(sims, start=1):\n",
    "        df.at[idx, f'Track_Name_{i}'] = df.at[sim_idx, 'track_name']\n",
    "        df.at[idx, f'Artist_Name_{i}'] = df.at[sim_idx, 'artist_name']\n",
    "        df.at[idx, f'Similarity_{i}'] = sim_score\n",
    "\n",
    "df.to_csv(\"../../Downloads/BT4222ProjectExcel/songs_with_similarities_final.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wyero\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightfm\\_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# from lightfm.data import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "from lightfm import LightFM\n",
    "from lightfm.data import Dataset\n",
    "\n",
    "\n",
    "lastfm_api_key = \"97d5a64d5ba4a8bc580b752ceff3b87f\"\n",
    "lastfm_secret = \"35175090bd61f6f16ac607bd26e5b1de\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 27 friends so far...\n",
      "Error fetching data for user astonbrown: no such page\n",
      "Collected 77 friends so far...\n",
      "Error fetching data for user latenightcryout: no such page\n",
      "Collected 100 friends so far...\n",
      "              User                                             Tracks  \\\n",
      "0       astonbrown  [Bring Me Your Loves, Rebound, Digital Witness...   \n",
      "1         liliwer7  [Fuck The Industry Pt. 2, Calling My Phone, Gl...   \n",
      "2  latenightcryout  [I H3ART Y0U, Jealous, Romantic Homicide, Touc...   \n",
      "3         cabnfver  [Dionysus, IDOL, Maneater, Mad World, PUMPED U...   \n",
      "4  no_eyes_no_ears  [6 Five Heartbeats (feat. Vince Staples), Free...   \n",
      "\n",
      "                                             Artists  \\\n",
      "0  [St. Vincent, Jennifer Lopez, St. Vincent, Ari...   \n",
      "1  [YoungBoy Never Broke Again, Lil Tjay, 6lack, ...   \n",
      "2  [BOY FANTASY, Eyedress, d4vd, Cigarettes After...   \n",
      "3  [BTS, BTS, Nelly Furtado, Tears for Fears, 3TE...   \n",
      "4  [The Alchemist, IceWear Vezzo, Gogetter, Veeze...   \n",
      "\n",
      "                                          Playcounts  \n",
      "0                     [6, 4, 4, 3, 3, 3, 3, 3, 2, 2]  \n",
      "1           [43, 41, 37, 36, 35, 35, 35, 34, 33, 32]  \n",
      "2  [561, 418, 375, 360, 328, 313, 306, 287, 286, ...  \n",
      "3  [194, 179, 175, 167, 143, 131, 128, 120, 120, ...  \n",
      "4           [49, 40, 37, 37, 35, 34, 33, 32, 29, 28]  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from collections import deque\n",
    "def get_lastfm_friends_bfs(start_username, api_key, min_users=5000):\n",
    "    discovered = set([start_username]) \n",
    "    queue = deque([start_username])     \n",
    "    collected_friends = []              \n",
    "\n",
    "    while queue and len(collected_friends) < min_users:\n",
    "        current_user = queue.popleft()\n",
    "        url = f\"http://ws.audioscrobbler.com/2.0/?method=user.getfriends&user={current_user}&api_key={api_key}&format=json\"\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            data = response.json()\n",
    "            \n",
    "            if 'error' in data:\n",
    "                print(f\"Error fetching data for user {current_user}: {data['message']}\")\n",
    "                continue\n",
    "            \n",
    "            users = data.get('friends', {}).get('user', [])\n",
    "            for user in users:\n",
    "                friend_name = user['name']\n",
    "                if friend_name not in discovered:\n",
    "                    discovered.add(friend_name)\n",
    "                    queue.append(friend_name)\n",
    "                    collected_friends.append(friend_name)\n",
    "                    if len(collected_friends) >= min_users:\n",
    "                        break  \n",
    "\n",
    "            print(f\"Collected {len(collected_friends)} friends so far...\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while processing user {current_user}: {e}\")\n",
    "    \n",
    "    return collected_friends[:min_users]\n",
    "\n",
    "def get_top_tracks_for_users(users, api_key):\n",
    "    user_tracks = []\n",
    "    user_artists = []\n",
    "    user_playcounts = []\n",
    "    user_ids = []\n",
    "    \n",
    "    for user in users:\n",
    "        result = get_top_tracks(user, api_key)  \n",
    "        tracks, artists, playcounts = [], [], []\n",
    "        \n",
    "        for item in result['toptracks']['track'][:10]: \n",
    "            tracks.append(item['name'])\n",
    "            artists.append(item['artist']['name'])\n",
    "            playcounts.append(item['playcount'])\n",
    "        \n",
    "        user_tracks.append(tracks)\n",
    "        user_artists.append(artists)\n",
    "        user_playcounts.append(playcounts)\n",
    "        user_ids.append(user)\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'User': user_ids,\n",
    "        'Tracks': user_tracks,\n",
    "        'Artists': user_artists,\n",
    "        'Playcounts': user_playcounts\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_top_tracks(user, api_key):\n",
    "    url = f\"http://ws.audioscrobbler.com/2.0/?method=user.gettoptracks&user={user}&api_key={api_key}&format=json\"\n",
    "    response = requests.get(url)\n",
    "    result = response.json()\n",
    "    return result\n",
    "\n",
    "start_username = \"Bans77\" \n",
    "\n",
    "users = get_lastfm_friends_bfs(start_username, lastfm_api_key, min_users=100)\n",
    "\n",
    "df_top_tracks = get_top_tracks_for_users(users, lastfm_api_key)\n",
    "\n",
    "print(df_top_tracks.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
