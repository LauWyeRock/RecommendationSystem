{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wyero\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\dask\\dataframe\\_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 10.0.1 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "import base64   \n",
    "import pandas as pd\n",
    "import librosa\n",
    "import numpy as np\n",
    "import lyricsgenius\n",
    "import langdetect\n",
    "import re\n",
    "from joblib import Parallel, delayed\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "import tempfile\n",
    "from datetime import datetime, timedelta\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "from dask.diagnostics import ProgressBar\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed, ProcessPoolExecutor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For any api we can try using the \"+\" email trick to get more API keys\n",
    "\n",
    "genius_client_id = \"wZZ2RWc5mqp-5Pbz2W1rQJWE8LQ3pFBrb1Hw5_AOqgybq28mt7kjdjcG4zktCNbO\"\n",
    "genius_client_secret = \"PefqBJHor_muDgTutGlaXXaxmzsI7TQCps9FQ3FwkUTT0WJIT3s0A5YA9mnFbfp_-CBhQF7b0omgE8kaM3dJ3w\"\n",
    "genius_access_token = \"NUHHVpwnmbDYUYw8Padu0gQeHvYN4OsKYtE2MKNUpBUI6yR-xZXKY6S5NvCnFbiP\"\n",
    "\n",
    "lastfm_api_key = \"97d5a64d5ba4a8bc580b752ceff3b87f\"\n",
    "lastfm_secret = \"35175090bd61f6f16ac607bd26e5b1de\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'http://ws.audioscrobbler.com/2.0/'\n",
    "\n",
    "def lastfm_get(payload):\n",
    "    headers = {'user-agent': 'DataCollectorBot'}\n",
    "    payload['api_key'] = lastfm_api_key\n",
    "    payload['format'] = 'json'\n",
    "    response = requests.get(base_url, headers=headers, params=payload)\n",
    "    return response.json()\n",
    "\n",
    "# Function for each endpoint\n",
    "def get_user_info(user):\n",
    "    payload = {'method': 'user.getinfo', 'user': user}\n",
    "    return lastfm_get(payload)\n",
    "\n",
    "def get_top_albums(user):\n",
    "    payload = {'method': 'user.gettopalbums', 'user': user}\n",
    "    return lastfm_get(payload)\n",
    "\n",
    "def get_top_artists(user):\n",
    "    payload = {'method': 'user.gettopartists', 'user': user}\n",
    "    return lastfm_get(payload)\n",
    "\n",
    "def get_top_tracks(user):\n",
    "    payload = {'method': 'user.gettoptracks', 'user': user}\n",
    "    return lastfm_get(payload)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_df(data_list, columns):\n",
    "    if data_list:\n",
    "        df = pd.DataFrame(data_list, columns=columns)\n",
    "        return df\n",
    "    else:\n",
    "        return pd.DataFrame(columns=columns)\n",
    "    \n",
    "def get_top_albums_df(user):\n",
    "    result = get_top_albums(user)\n",
    "    albums = []\n",
    "    for item in result['topalbums']['album']:\n",
    "        albums.append({\n",
    "            'Rank': item['@attr']['rank'],\n",
    "            'Album Name': item['name'],\n",
    "            'Artist': item['artist']['name'],\n",
    "            'Play Count': item['playcount']\n",
    "        })\n",
    "    return list_to_df(albums, ['Rank', 'Album Name', 'Artist', 'Play Count'])\n",
    "\n",
    "def get_top_artists_df(user):\n",
    "    result = get_top_artists(user)\n",
    "    artists = []\n",
    "    for item in result['topartists']['artist']:\n",
    "        artists.append({\n",
    "            'Rank': item['@attr']['rank'],\n",
    "            'Artist': item['name'],\n",
    "            'Play Count': item['playcount']\n",
    "        })\n",
    "    return list_to_df(artists, ['Rank', 'Artist', 'Play Count'])\n",
    "\n",
    "\n",
    "def get_top_tracks_df(user):\n",
    "    result = get_top_tracks(user)\n",
    "    tracks = []\n",
    "    for item in result['toptracks']['track']:\n",
    "        tracks.append({\n",
    "            'Rank': item['@attr']['rank'],\n",
    "            'Track Name': item['name'],\n",
    "            'Artist': item['artist']['name'],\n",
    "            'Play Count': item['playcount']\n",
    "        })\n",
    "    return list_to_df(tracks, ['Rank', 'Track Name', 'Artist', 'Play Count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Albums</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Artists</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Tracks</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Album Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Play Count</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Play Count</th>\n",
       "      <th>Track Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Play Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Discography, Vol. 1</td>\n",
       "      <td>VELVETEARS</td>\n",
       "      <td>2831</td>\n",
       "      <td>VELVETEARS</td>\n",
       "      <td>10912</td>\n",
       "      <td>Думала ты одна</td>\n",
       "      <td>Даша Каплан</td>\n",
       "      <td>1457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3 Ghosts</td>\n",
       "      <td>VELVETEARS</td>\n",
       "      <td>1477</td>\n",
       "      <td>ooes</td>\n",
       "      <td>2730</td>\n",
       "      <td>Sincere Regret</td>\n",
       "      <td>Side of Despondency</td>\n",
       "      <td>357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Думала ты одна</td>\n",
       "      <td>Даша Каплан</td>\n",
       "      <td>1456</td>\n",
       "      <td>Clairo</td>\n",
       "      <td>2251</td>\n",
       "      <td>Minor</td>\n",
       "      <td>Gracie Abrams</td>\n",
       "      <td>345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>мои (твои) тёмные желания</td>\n",
       "      <td>ooes</td>\n",
       "      <td>1217</td>\n",
       "      <td>Alexis Munroe</td>\n",
       "      <td>1972</td>\n",
       "      <td>Central Park</td>\n",
       "      <td>VELVETEARS</td>\n",
       "      <td>291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Discography, Vol. 2</td>\n",
       "      <td>VELVETEARS</td>\n",
       "      <td>1009</td>\n",
       "      <td>Grechka</td>\n",
       "      <td>1522</td>\n",
       "      <td>nothing</td>\n",
       "      <td>VELVETEARS</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Pins &amp; Needles</td>\n",
       "      <td>VELVETEARS</td>\n",
       "      <td>921</td>\n",
       "      <td>Даша Каплан</td>\n",
       "      <td>1457</td>\n",
       "      <td>больше</td>\n",
       "      <td>ooes</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Мне не страшно</td>\n",
       "      <td>ooes</td>\n",
       "      <td>748</td>\n",
       "      <td>Maggie Lindemann</td>\n",
       "      <td>1384</td>\n",
       "      <td>Million Dollar Song</td>\n",
       "      <td>VELVETEARS</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>Erika Lundmoen</td>\n",
       "      <td>699</td>\n",
       "      <td>Zheani</td>\n",
       "      <td>1077</td>\n",
       "      <td>Imma Lie</td>\n",
       "      <td>VELVETEARS</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Immunity</td>\n",
       "      <td>Clairo</td>\n",
       "      <td>688</td>\n",
       "      <td>DSPRITE</td>\n",
       "      <td>1062</td>\n",
       "      <td>Will I Ever Care</td>\n",
       "      <td>VELVETEARS</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Hikikomori</td>\n",
       "      <td>VELVETEARS</td>\n",
       "      <td>683</td>\n",
       "      <td>Side of Despondency</td>\n",
       "      <td>1053</td>\n",
       "      <td>We All Wanna Die Sometimes</td>\n",
       "      <td>VELVETEARS</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rank                     Albums                             \\\n",
       "                       Album Name          Artist Play Count   \n",
       "0    1        Discography, Vol. 1      VELVETEARS       2831   \n",
       "1    2                   3 Ghosts      VELVETEARS       1477   \n",
       "2    3             Думала ты одна     Даша Каплан       1456   \n",
       "3    4  мои (твои) тёмные желания            ooes       1217   \n",
       "4    5        Discography, Vol. 2      VELVETEARS       1009   \n",
       "5    6             Pins & Needles      VELVETEARS        921   \n",
       "6    7             Мне не страшно            ooes        748   \n",
       "7    8                         22  Erika Lundmoen        699   \n",
       "8    9                   Immunity          Clairo        688   \n",
       "9   10                 Hikikomori      VELVETEARS        683   \n",
       "\n",
       "               Artists                                 Tracks  \\\n",
       "                Artist Play Count                  Track Name   \n",
       "0           VELVETEARS      10912              Думала ты одна   \n",
       "1                 ooes       2730              Sincere Regret   \n",
       "2               Clairo       2251                       Minor   \n",
       "3        Alexis Munroe       1972                Central Park   \n",
       "4              Grechka       1522                     nothing   \n",
       "5          Даша Каплан       1457                      больше   \n",
       "6     Maggie Lindemann       1384         Million Dollar Song   \n",
       "7               Zheani       1077                    Imma Lie   \n",
       "8              DSPRITE       1062            Will I Ever Care   \n",
       "9  Side of Despondency       1053  We All Wanna Die Sometimes   \n",
       "\n",
       "                                   \n",
       "                Artist Play Count  \n",
       "0          Даша Каплан       1457  \n",
       "1  Side of Despondency        357  \n",
       "2        Gracie Abrams        345  \n",
       "3           VELVETEARS        291  \n",
       "4           VELVETEARS        265  \n",
       "5                 ooes        258  \n",
       "6           VELVETEARS        255  \n",
       "7           VELVETEARS        253  \n",
       "8           VELVETEARS        251  \n",
       "9           VELVETEARS        243  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_combined_top_data(user, top_n=10):\n",
    "    # Retrieve top albums, artists, and tracks dataframes limited to top_n entries\n",
    "    top_albums_df = get_top_albums_df(user).head(top_n)\n",
    "    top_artists_df = get_top_artists_df(user).head(top_n)\n",
    "    top_tracks_df = get_top_tracks_df(user).head(top_n)\n",
    "    \n",
    "    # Make sure that the 'Rank' column is of the same data type across all DataFrames before concatenating\n",
    "    top_albums_df['Rank'] = top_albums_df['Rank'].astype(int)\n",
    "    top_artists_df['Rank'] = top_artists_df['Rank'].astype(int)\n",
    "    top_tracks_df['Rank'] = top_tracks_df['Rank'].astype(int)\n",
    "\n",
    "    # Align DataFrames by 'Rank' and horizontally concatenate\n",
    "    combined_df = pd.concat([top_albums_df.set_index('Rank'),\n",
    "                             top_artists_df.set_index('Rank'),\n",
    "                             top_tracks_df.set_index('Rank')],\n",
    "                            axis=1,\n",
    "                            keys=['Albums', 'Artists', 'Tracks'])\n",
    "    \n",
    "    combined_df.reset_index(inplace=True)\n",
    "\n",
    "    return combined_df\n",
    "\n",
    "\n",
    "\n",
    "df2 = get_combined_top_data(\"Bans77\")\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "\n",
    "\n",
    "def safe_eval(x):\n",
    "    try:\n",
    "        return literal_eval(x)\n",
    "    except:\n",
    "        return x\n",
    "    \n",
    "def preprocess_column(df, column_name):\n",
    "    df[column_name] = df[column_name].apply(lambda x: [] if pd.isna(x) or x == \"\" else x)\n",
    "    df[column_name] = df[column_name].apply(safe_eval)\n",
    "    return df\n",
    "\n",
    "def extract_unique_songs(df):\n",
    "    # Preprocess 'Top 50 Songs' and 'Liked Songs' columns\n",
    "    df = preprocess_column(df, 'Top 50 Songs')\n",
    "    df = preprocess_column(df, 'Liked Songs')\n",
    "    \n",
    "    all_songs = []\n",
    "    for index, row in df.iterrows():\n",
    "        if isinstance(row['Top 50 Songs'], list) and isinstance(row['Liked Songs'], list):\n",
    "            all_songs.extend(row['Top 50 Songs'])\n",
    "            all_songs.extend(row['Liked Songs'])\n",
    "    \n",
    "    unique_songs = list(set(all_songs))\n",
    "    unique_songs_df = pd.DataFrame(unique_songs, columns=['Unique Songs'])\n",
    "    \n",
    "    # Export the DataFrame to an Excel file\n",
    "    unique_songs_df.to_excel(\"Unique_songs.xlsx\", index=False)\n",
    "    \n",
    "    return unique_songs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_deezer_track(track_name, artist_name):\n",
    "    search_url = \"https://api.deezer.com/search/track\"\n",
    "    # Format the query to include both track name and artist name\n",
    "    query = f\"{track_name} artist:\\\"{artist_name}\\\"\"\n",
    "    params = {\"q\": query}\n",
    "    try:\n",
    "        response = requests.get(search_url, params=params)\n",
    "        response.raise_for_status()\n",
    "        tracks = response.json().get('data', [])\n",
    "        if tracks:\n",
    "            return tracks[0]['id']  # Return only the first track ID\n",
    "        return None\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Request failed: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_deezer_track_info(track_id):\n",
    "    if not track_id:\n",
    "        return {}\n",
    "    base_url = \"https://api.deezer.com/track/\"\n",
    "    try:\n",
    "        response = requests.get(f\"{base_url}{track_id}\")\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        main_artist = data.get(\"artist\", {}).get(\"name\", \"\")\n",
    "        contributors = [contributor['name'] for contributor in data.get(\"contributors\", []) if contributor['name'] != main_artist]\n",
    "        featured_artists = \", \".join(contributors) if contributors else None\n",
    "\n",
    "        return {\n",
    "            \"title\": data.get(\"title\"),\n",
    "            \"artist\": main_artist,\n",
    "            \"featured_artists\": featured_artists,\n",
    "            \"duration\": data.get(\"duration\"),\n",
    "            \"album\": data.get(\"album\", {}).get(\"title\"),\n",
    "            \"preview_url\": data.get(\"preview\"),\n",
    "            \"link\": data.get(\"link\")\n",
    "        }\n",
    "    except requests.RequestException:\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_librosa_features_from_url(url):\n",
    "    # Fetch the audio file from the URL\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Failed to download audio file from {url}\")\n",
    "    \n",
    "    # Create a temporary file and manually manage it\n",
    "    temp_dir = tempfile.gettempdir()\n",
    "    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\", dir=temp_dir)\n",
    "    temp_file_path = temp_file.name\n",
    "    \n",
    "    try:\n",
    "        # Write the fetched content to the temp file and close it to release the lock\n",
    "        temp_file.write(response.content)\n",
    "        temp_file.close()\n",
    "        \n",
    "        y, sr = librosa.load(temp_file_path, sr=None)  # Using sr=None to preserve the original sampling rate\n",
    "        \n",
    "        tempo, beat_frames = librosa.beat.beat_track(y=y, sr=sr)\n",
    "        rms = np.mean(librosa.feature.rms(y=y))\n",
    "        spectral_centroid = np.mean(librosa.feature.spectral_centroid(y=y, sr=sr))\n",
    "        zcr = np.mean(librosa.feature.zero_crossing_rate(y))\n",
    "\n",
    "\n",
    "        features = {\n",
    "            'mfcc': np.mean(librosa.feature.mfcc(y=y, sr=sr).T, axis=0),\n",
    "            'chroma': np.mean(librosa.feature.chroma_stft(y=y, sr=sr).T, axis=0),\n",
    "            'rms': rms,\n",
    "            'spectral_centroid': spectral_centroid,\n",
    "            'zcr': zcr,\n",
    "            'tempo': tempo\n",
    "        }\n",
    "    finally:\n",
    "        os.remove(temp_file_path)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_danceability(features):\n",
    "    beat_intervals = np.diff(features['beat_times'])\n",
    "    beat_interval_std = np.std(beat_intervals)\n",
    "    # Lower standard deviation in beat intervals indicates more consistent rhythm\n",
    "    rhythmic_stability = 1 - (beat_interval_std / (np.mean(beat_intervals) + 1e-6))\n",
    "    tempo_confidence = features.get('tempo_confidence', 0.5)  # Assuming a placeholder value if not provided\n",
    "    return np.mean([rhythmic_stability, tempo_confidence, np.mean(features['chroma'])])\n",
    "\n",
    "def estimate_loudness(features):\n",
    "    # Convert RMS to a dB scale for a more perceptual loudness measurement\n",
    "    rms_db = 20 * np.log10(features['rms'] + 1e-6)\n",
    "    # Map the dB scale to a 0-1 range considering human hearing sensitivity\n",
    "    return np.interp(rms_db, [-60, 0], [0, 1])\n",
    "\n",
    "\n",
    "\n",
    "def calculate_song_features(features):\n",
    "    scores = {}\n",
    "\n",
    "    # Danceability\n",
    "    scores['danceability'] = estimate_danceability(features)\n",
    "\n",
    "    # Loudness\n",
    "    scores['loudness'] = estimate_loudness(features)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_song(track_name, artist_name):\n",
    "    # Use both track_name and artist_name for searching\n",
    "    track_id = search_deezer_track(track_name, artist_name)  # Update this function as needed to use both parameters\n",
    "    track_info = get_deezer_track_info(track_id)\n",
    "    if not track_info or 'preview_url' not in track_info or not track_info['preview_url']:\n",
    "        return {'Song': track_name}  # Return minimal data if track info is not available or no preview URL\n",
    "\n",
    "    try:\n",
    "        features = extract_librosa_features_from_url(track_info['preview_url'])\n",
    "        # scores = calculate_song_features(features)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {track_name}: {e}\")\n",
    "        features = {}\n",
    "        scores = {}\n",
    "\n",
    "    # Merge dictionaries: track_info, features, and scores.\n",
    "    return {**{'Song': track_name}, **track_info, **features} # Add **scores if we using the calculate_song_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Songs:   9%|▉         | 1691/18253 [11:18<1:22:24,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing autumn waves: Failed to download audio file from https://cdns-preview-0.dzcdn.net/stream/c-0344605836c27f5acc1d8c69c8c166a4-2.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Songs:  46%|████▌     | 8345/18253 [55:31<29:10,  5.66it/s]  c:\\Users\\wyero\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\librosa\\core\\pitch.py:101: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n",
      "Processing Songs:  59%|█████▊    | 10701/18253 [1:11:00<32:21,  3.89it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing The Forest: Failed to download audio file from https://cdns-preview-f.dzcdn.net/stream/c-f8b74a33c6c64c29a2c4e9abfdda5bbd-0.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Songs:  60%|█████▉    | 10883/18253 [1:12:11<44:02,  2.79it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing A Souljah's Dream: Failed to download audio file from https://cdns-preview-d.dzcdn.net/stream/c-db04e801605f2a81c76013db83335b5b-2.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Songs: 100%|██████████| 18253/18253 [2:01:13<00:00,  2.51it/s]  \n"
     ]
    }
   ],
   "source": [
    "def main(df_songs):\n",
    "    # Convert DataFrame rows to a list of tuples for iteration\n",
    "    tracks_and_artists = [(row['track_name'], row['artist_name']) for index, row in df_songs.iterrows()]\n",
    "    \n",
    "    # Initialize the ThreadPoolExecutor\n",
    "    with ThreadPoolExecutor(max_workers=20) as executor:\n",
    "        # Submit all tasks to the executor\n",
    "        future_to_song = {executor.submit(process_song, track, artist): (track, artist) for track, artist in tracks_and_artists}\n",
    "        \n",
    "        # Initialize a list to accumulate results\n",
    "        results = []\n",
    "        \n",
    "        # Use tqdm to display progress\n",
    "        for future in tqdm(as_completed(future_to_song), total=len(tracks_and_artists), desc=\"Processing Songs\"):\n",
    "            track, artist = future_to_song[future]\n",
    "            try:\n",
    "                song_data = future.result()\n",
    "                results.append(song_data)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {track} by {artist}: {e}\")\n",
    "    \n",
    "    # Convert the accumulated results into a DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_excel(\"../../Downloads/unique_songs_cleaned_with_librosa_wyerock9thRun.xlsx\", index=False)\n",
    "\n",
    "\n",
    "try_df = pd.read_excel(\"../../Downloads/Unique_Song_Eng_Lyrics.xlsx\")\n",
    "try_df = try_df[['track_name', 'artist_name']]\n",
    "main(try_df[270000:])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
