{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df_users = pd.read_csv('../Data/multiple_user_seq_df.csv')\n",
    "df_users = df_users.sort_values(by=['Username', 'Timestamp'])\n",
    "\n",
    "def sequential_pattern_mining(df_user):\n",
    "    label_encoder = LabelEncoder()\n",
    "    combined_encoded = label_encoder.fit_transform(df_user['Artist'] + ' - ' + df_user['Track Name'])\n",
    "\n",
    "    sequence_length = 3\n",
    "    sequences = [combined_encoded[i: i + sequence_length + 1] for i in range(len(combined_encoded) - sequence_length)]\n",
    "\n",
    "    sequences = np.array(sequences)\n",
    "\n",
    "    X, y = sequences[:, :-1], sequences[:, -1]\n",
    "    y = to_categorical(y, num_classes=len(label_encoder.classes_))\n",
    "\n",
    "    vocab_size = len(label_encoder.classes_)  # Number of unique artist-track combinations\n",
    "\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=vocab_size, output_dim=50),\n",
    "        LSTM(100, return_sequences=False),\n",
    "        Dropout(0.2),\n",
    "        Dense(vocab_size, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    model.fit(X, y, epochs=20, batch_size=32, verbose=1)\n",
    "\n",
    "\n",
    "for user, df_user in df_users.groupby('Username'):\n",
    "    print(f\"Sequential pattern mining for user: {user}\")\n",
    "    sequential_pattern_mining(df_user)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "test = pd.read_csv(\"../Data/lastfm_user_clean.csv\")\n",
    "\n",
    "lastfm_api_key = \"9285c225124a467ccf14911a4389058f\"\n",
    "lastfm_secret = \"35175090bd61f6f16ac607bd26e5b1de\"\n",
    "\n",
    "base_url = 'http://ws.audioscrobbler.com/2.0/'\n",
    "\n",
    "\n",
    "usernames_list = df['Username'].tolist()\n",
    "\n",
    "def lastfm_get(payload):\n",
    "    headers = {'user-agent': 'DataCollectorBot'}\n",
    "    payload['api_key'] = lastfm_api_key\n",
    "    payload['format'] = 'json'\n",
    "    response = requests.get(base_url, headers=headers, params=payload)\n",
    "    return response.json()\n",
    "\n",
    "def get_one_month_ago_timestamp():\n",
    "    one_month_ago = datetime.now() - timedelta(days=30)\n",
    "    return int(one_month_ago.timestamp())\n",
    "\n",
    "def recent_tracks_last_month_to_df(user):\n",
    "    from_timestamp = get_one_month_ago_timestamp()\n",
    "\n",
    "    payload = {\n",
    "        'method': 'user.getrecenttracks',\n",
    "        'user': user,\n",
    "        'from': from_timestamp,\n",
    "        'limit': 100  # Adjust based on Last.fm API limits\n",
    "    }\n",
    "\n",
    "    recent_tracks = lastfm_get(payload)\n",
    "\n",
    "    tracks_list = []\n",
    "\n",
    "    if 'recenttracks' in recent_tracks and 'track' in recent_tracks['recenttracks']:\n",
    "        for track in recent_tracks['recenttracks']['track']:\n",
    "            if 'date' in track:  # Ensure the track has a timestamp\n",
    "                track_info = {\n",
    "                    'Artist': track['artist']['#text'],\n",
    "                    'Track Name': track['name'],\n",
    "                    'Timestamp': track['date']['uts']\n",
    "                }\n",
    "                tracks_list.append(track_info)\n",
    "\n",
    "    # Only proceed if more than 50 tracks were found, else return an empty DataFrame\n",
    "    if len(tracks_list) == 100:\n",
    "        df = pd.DataFrame(tracks_list)\n",
    "        return df\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "def get_recent_tracks_for_multiple_users(users):\n",
    "    dfs = []\n",
    "    for user in users:\n",
    "        df = recent_tracks_last_month_to_df(user)\n",
    "        if not df.empty:\n",
    "            df['Username'] = user\n",
    "            dfs.append(df)\n",
    "    if dfs:\n",
    "        return pd.concat(dfs, ignore_index=True)\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "multiple_user_seq_df_2 = get_recent_tracks_for_multiple_users(usernames_list)\n",
    "\n",
    "multiple_user_seq_df_2.to_csv('multiple_user_seq_df_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 9.1947, Accuracy: 0.0001\n",
      "Epoch 2/50, Loss: 9.1849, Accuracy: 0.0001\n",
      "Epoch 3/50, Loss: 9.1779, Accuracy: 0.0001\n",
      "Epoch 4/50, Loss: 9.1713, Accuracy: 0.0001\n",
      "Epoch 5/50, Loss: 9.1645, Accuracy: 0.0003\n",
      "Epoch 6/50, Loss: 9.1584, Accuracy: 0.0003\n",
      "Epoch 7/50, Loss: 9.1514, Accuracy: 0.0002\n",
      "Epoch 8/50, Loss: 9.1446, Accuracy: 0.0004\n",
      "Epoch 9/50, Loss: 9.1388, Accuracy: 0.0004\n",
      "Epoch 10/50, Loss: 9.1319, Accuracy: 0.0004\n",
      "Epoch 11/50, Loss: 9.1252, Accuracy: 0.0005\n",
      "Epoch 12/50, Loss: 9.1190, Accuracy: 0.0004\n",
      "Epoch 13/50, Loss: 9.1114, Accuracy: 0.0005\n",
      "Epoch 14/50, Loss: 9.1057, Accuracy: 0.0006\n",
      "Epoch 15/50, Loss: 9.0989, Accuracy: 0.0008\n",
      "Epoch 16/50, Loss: 9.0910, Accuracy: 0.0009\n",
      "Epoch 17/50, Loss: 9.0844, Accuracy: 0.0009\n",
      "Epoch 18/50, Loss: 9.0776, Accuracy: 0.0008\n",
      "Epoch 19/50, Loss: 9.0694, Accuracy: 0.0008\n",
      "Epoch 20/50, Loss: 9.0622, Accuracy: 0.0007\n",
      "Epoch 21/50, Loss: 9.0547, Accuracy: 0.0006\n",
      "Epoch 22/50, Loss: 9.0466, Accuracy: 0.0008\n",
      "Epoch 23/50, Loss: 9.0383, Accuracy: 0.0008\n",
      "Epoch 24/50, Loss: 9.0292, Accuracy: 0.0022\n",
      "Epoch 25/50, Loss: 9.0216, Accuracy: 0.0027\n",
      "Epoch 26/50, Loss: 9.0115, Accuracy: 0.0029\n",
      "Epoch 27/50, Loss: 9.0012, Accuracy: 0.0028\n",
      "Epoch 28/50, Loss: 8.9922, Accuracy: 0.0013\n",
      "Epoch 29/50, Loss: 8.9814, Accuracy: 0.0009\n",
      "Epoch 30/50, Loss: 8.9709, Accuracy: 0.0013\n",
      "Epoch 31/50, Loss: 8.9609, Accuracy: 0.0009\n",
      "Epoch 32/50, Loss: 8.9479, Accuracy: 0.0009\n",
      "Epoch 33/50, Loss: 8.9371, Accuracy: 0.0007\n",
      "Epoch 34/50, Loss: 8.9271, Accuracy: 0.0004\n",
      "Epoch 35/50, Loss: 8.9119, Accuracy: 0.0005\n",
      "Epoch 36/50, Loss: 8.9014, Accuracy: 0.0006\n",
      "Epoch 37/50, Loss: 8.8903, Accuracy: 0.0008\n",
      "Epoch 38/50, Loss: 8.8769, Accuracy: 0.0006\n",
      "Epoch 39/50, Loss: 8.8625, Accuracy: 0.0008\n",
      "Epoch 40/50, Loss: 8.8501, Accuracy: 0.0008\n",
      "Epoch 41/50, Loss: 8.8359, Accuracy: 0.0006\n",
      "Epoch 42/50, Loss: 8.8210, Accuracy: 0.0006\n",
      "Epoch 43/50, Loss: 8.8079, Accuracy: 0.0008\n",
      "Epoch 44/50, Loss: 8.7912, Accuracy: 0.0009\n",
      "Epoch 45/50, Loss: 8.7768, Accuracy: 0.0008\n",
      "Epoch 46/50, Loss: 8.7634, Accuracy: 0.0009\n",
      "Epoch 47/50, Loss: 8.7507, Accuracy: 0.0009\n",
      "Epoch 48/50, Loss: 8.7340, Accuracy: 0.0012\n",
      "Epoch 49/50, Loss: 8.7235, Accuracy: 0.0011\n",
      "Epoch 50/50, Loss: 8.7055, Accuracy: 0.0011\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "\n",
    "updated_df = pd.read_csv(\"../Data/multiple_user_seq_df_2.csv\")\n",
    "updated_df = updated_df.sort_values(by=['Username', 'Timestamp'])\n",
    "updated_df = updated_df.head(12800)\n",
    "updated_df = updated_df.reset_index(drop=True)\n",
    "\n",
    "class SongDataset(Dataset):\n",
    "    def __init__(self, df, sequence_length=10):\n",
    "        self.sequence_length = sequence_length\n",
    "        \n",
    "        # Encode 'Song' into numerical values\n",
    "        self.song_encoder = LabelEncoder()\n",
    "        updated_df['Song'] = self.song_encoder.fit_transform(updated_df['Track Name'])\n",
    "        \n",
    "        # Create sequences of songs\n",
    "        self.sequences = []\n",
    "        for username in updated_df['Username'].unique():\n",
    "            user_df = updated_df[updated_df['Username'] == username]\n",
    "            songs = user_df['Song'].values\n",
    "            for i in range(len(songs) - sequence_length):\n",
    "                input_sequence = songs[i:i+sequence_length]\n",
    "                target_song = songs[i+sequence_length]\n",
    "                self.sequences.append((input_sequence, target_song))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        input_sequence, target_song = self.sequences[idx]\n",
    "        # Add an extra dimension for input_size\n",
    "        input_sequence = torch.tensor(input_sequence, dtype=torch.float32).unsqueeze(-1)\n",
    "        target_song = torch.tensor(target_song, dtype=torch.long)\n",
    "        return input_sequence, target_song\n",
    "\n",
    "\n",
    "dataset = SongDataset(updated_df)\n",
    "batch_size = 6400\n",
    "num_unique_songs = len(dataset.song_encoder.classes_)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        hidden = (torch.zeros(1, batch_size, self.hidden_size),\n",
    "                  torch.zeros(1, batch_size, self.hidden_size))\n",
    "        out, hidden = self.lstm(x, hidden)\n",
    "        out = self.linear(out[:, -1, :])  \n",
    "        return out\n",
    "\n",
    "def calculate_accuracy(outputs, targets):\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    correct = (predicted == targets).sum().item()\n",
    "    total = targets.size(0)\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "model = SimpleLSTM(input_size=1, hidden_size=50, output_size=num_unique_songs)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_accuracy = 0.0\n",
    "    for inputs, targets in dataloader:\n",
    "        # print(inputs)\n",
    "        # print(targets)\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_accuracy += calculate_accuracy(outputs, targets)\n",
    "    \n",
    "    # Calculate average loss and accuracy over the epoch\n",
    "    train_loss /= len(dataloader)\n",
    "    train_accuracy /= len(dataloader)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{50}, Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.4f}')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
