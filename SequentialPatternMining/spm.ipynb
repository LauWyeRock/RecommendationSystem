{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "import base64   \n",
    "import pandas as pd\n",
    "import librosa\n",
    "import numpy as np\n",
    "import lyricsgenius\n",
    "import langdetect\n",
    "import re\n",
    "import string\n",
    "import tempfile\n",
    "from tqdm import tqdm  # Import tqdm for progress bar\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For any api we can try using the \"+\" email trick to get more API keys\n",
    "\n",
    "genius_client_id = \"wZZ2RWc5mqp-5Pbz2W1rQJWE8LQ3pFBrb1Hw5_AOqgybq28mt7kjdjcG4zktCNbO\"\n",
    "genius_client_secret = \"PefqBJHor_muDgTutGlaXXaxmzsI7TQCps9FQ3FwkUTT0WJIT3s0A5YA9mnFbfp_-CBhQF7b0omgE8kaM3dJ3w\"\n",
    "genius_access_token = \"NUHHVpwnmbDYUYw8Padu0gQeHvYN4OsKYtE2MKNUpBUI6yR-xZXKY6S5NvCnFbiP\"\n",
    "\n",
    "lastfm_api_key = \"97d5a64d5ba4a8bc580b752ceff3b87f\"\n",
    "lastfm_secret = \"35175090bd61f6f16ac607bd26e5b1de\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next 2 codeblocks are for extracting data from lastfm. These pertain to User data, where we want to get their recent tracks from up to one month ago. We limit it to 100 tracks per user. This is run on unique users from the user-song dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'http://ws.audioscrobbler.com/2.0/'\n",
    "\n",
    "def lastfm_get(payload):\n",
    "    headers = {'user-agent': 'DataCollectorBot'}\n",
    "    payload['api_key'] = lastfm_api_key\n",
    "    payload['format'] = 'json'\n",
    "    response = requests.get(base_url, headers=headers, params=payload)\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def get_recent_tracks(user):\n",
    "    payload = {'method': 'user.getrecenttracks', 'user': user}\n",
    "    return lastfm_get(payload)\n",
    "\n",
    "def get_weekly_artist_chart(user):\n",
    "    payload = {'method': 'user.getweeklyartistchart', 'user': user}\n",
    "    return lastfm_get(payload)\n",
    "\n",
    "def get_weekly_track_chart(user):\n",
    "    payload = {'method': 'user.getweeklytrackchart', 'user': user}\n",
    "    return lastfm_get(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Users: 100%|██████████| 9483/9483 [2:08:50<00:00,  1.23user/s]  \n"
     ]
    }
   ],
   "source": [
    "def get_one_month_ago_timestamp():\n",
    "    one_month_ago = datetime.now() - timedelta(days=30)\n",
    "    return int(one_month_ago.timestamp())\n",
    "\n",
    "def recent_tracks_for_user_to_df(user, min_tracks=50, max_tracks=100):\n",
    "    from_timestamp = get_one_month_ago_timestamp()\n",
    "    \n",
    "    payload = {\n",
    "        'method': 'user.getrecenttracks',\n",
    "        'user': user,\n",
    "        'from': from_timestamp,\n",
    "        'limit': max_tracks \n",
    "    }\n",
    "    \n",
    "    recent_tracks = lastfm_get(payload)\n",
    "    tracks_list = []\n",
    "    \n",
    "    if 'track' in recent_tracks.get('recenttracks', {}):\n",
    "        for track in recent_tracks['recenttracks']['track']:\n",
    "            if 'date' in track: \n",
    "                track_info = {\n",
    "                    'User': user, \n",
    "                    'Artist': track['artist']['#text'],\n",
    "                    'Track Name': track['name'],\n",
    "                    'Timestamp': track['date']['uts']\n",
    "                }\n",
    "                tracks_list.append(track_info)\n",
    "\n",
    "    df = pd.DataFrame(tracks_list)\n",
    "    return df\n",
    "\n",
    "def recent_tracks_all_users_to_df(users):\n",
    "    all_tracks_dfs = [] \n",
    "    total_users = len(users)\n",
    "    \n",
    "    with tqdm(total=total_users, desc=\"Processing Users\", unit=\"user\") as pbar:\n",
    "        for user in users:\n",
    "            df = recent_tracks_for_user_to_df(user)\n",
    "            all_tracks_dfs.append(df)\n",
    "            pbar.update(1) \n",
    "    \n",
    "    combined_df = pd.concat(all_tracks_dfs, ignore_index=True)\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "\n",
    "df = pd.read_csv('../../Downloads/user_songs_filtered.csv')\n",
    "users = df[\"Username\"].unique()\n",
    "combined_tracks_df = recent_tracks_all_users_to_df(users)\n",
    "combined_tracks_df.to_excel(\"../../Downloads/Users_Songs_Timestamps.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_df(data_list, columns):\n",
    "    if data_list:\n",
    "        df = pd.DataFrame(data_list, columns=columns)\n",
    "        return df\n",
    "    else:\n",
    "        return pd.DataFrame(columns=columns)\n",
    "\n",
    "def get_weekly_artist_chart_df(user):\n",
    "    result = get_weekly_artist_chart(user)\n",
    "    artists = []\n",
    "    if 'weeklyartistchart' in result and 'artist' in result['weeklyartistchart']:\n",
    "        for item in result['weeklyartistchart']['artist']:\n",
    "            artists.append({\n",
    "                'Artist': item['name'],\n",
    "                'Play Count': item['playcount']\n",
    "            })\n",
    "    return list_to_df(artists, ['Artist', 'Play Count'])\n",
    "\n",
    "def get_weekly_track_chart_df(user):\n",
    "    result = get_weekly_track_chart(user)\n",
    "    tracks = []\n",
    "    if 'weeklytrackchart' in result and 'track' in result['weeklytrackchart']:\n",
    "        for item in result['weeklytrackchart']['track']:\n",
    "            tracks.append({\n",
    "                'Track Name': item['name'],\n",
    "                'Artist': item['artist']['#text'],\n",
    "                'Play Count': item['playcount']\n",
    "            })\n",
    "    return list_to_df(tracks, ['Track Name', 'Artist', 'Play Count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we are concatenating the data, then splitting it into sequences of length 3 after grouping them by user and then sorting by timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = combined_tracks_df[:100000]\n",
    "df = pd.read_excel(\"../../Downloads/Users_Songs_Timestamps.xlsx\")\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'], unit='s')\n",
    "df['Time_of_Day'] = df['Timestamp'].dt.hour\n",
    "df['Artist_Track'] = df['Artist'].astype(str) + ' - ' + df['Track Name'].astype(str)\n",
    "\n",
    "time_of_day_encoded = pd.get_dummies(df['Time_of_Day'], prefix='hour')\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "df['Artist_Track_Encoded'] = label_encoder.fit_transform(df['Artist_Track'])\n",
    "\n",
    "df = pd.concat([df, time_of_day_encoded], axis=1)\n",
    "\n",
    "sequence_length = 3\n",
    "vocab_size = len(label_encoder.classes_)\n",
    "\n",
    "\n",
    "X_seq_list, y_seq_list = [], []\n",
    "\n",
    "for _, group in df.groupby('User'):\n",
    "    group = group.sort_values('Timestamp')\n",
    "    \n",
    "    for i in range(len(group) - sequence_length + 1):\n",
    "        artist_track_sequence = group['Artist_Track_Encoded'].iloc[i:i + sequence_length - 1].values\n",
    "        \n",
    "        time_features_sequence = group[time_of_day_encoded.columns].iloc[i:i + sequence_length - 1].values.reshape((sequence_length - 1) * len(time_of_day_encoded.columns))\n",
    "        \n",
    "        sequence = np.hstack([artist_track_sequence, time_features_sequence])\n",
    "        \n",
    "        label = group['Artist_Track_Encoded'].iloc[i + sequence_length - 1]\n",
    "        \n",
    "        X_seq_list.append(sequence)\n",
    "        y_seq_list.append(label)\n",
    "\n",
    "X_seq = np.array(X_seq_list)\n",
    "# y_seq = to_categorical(y_seq_list, num_classes=vocab_size)\n",
    "y_seq = np.array(y_seq_list) # Integer instead of one hot encoding\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, shuffle=False)\n",
    "\n",
    "num_artist_track_features = sequence_length - 1  \n",
    "num_time_features = 24 * (sequence_length - 1)  \n",
    "\n",
    "X_train_artist_track = X_train[:, :num_artist_track_features]  \n",
    "X_train_time_features = X_train[:, num_artist_track_features:] \n",
    "\n",
    "X_test_artist_track = X_test[:, :num_artist_track_features] \n",
    "X_test_time_features = X_test[:, num_artist_track_features:]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated number of time features: 48\n"
     ]
    }
   ],
   "source": [
    "num_time_features_actual = X_train_time_features.shape[1]\n",
    "\n",
    "num_time_features = num_time_features_actual\n",
    "print(\"Updated number of time features:\", num_time_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Mixed precision compatibility check (mixed_float16): WARNING\n",
      "The dtype policy mixed_float16 may run slowly because this machine does not have a GPU. Only Nvidia GPUs with compute capability of at least 7.0 run quickly with mixed_float16.\n",
      "If you will use compatible GPU(s) not attached to this host, e.g. by running a multi-worker model, you can ignore this warning. This message will only be logged once\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " artist_track_input (InputLayer  [(None, 2)]         0           []                               \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 2, 50)        15286150    ['artist_track_input[0][0]']     \n",
      "                                                                                                  \n",
      " time_features_input (InputLaye  [(None, 48)]        0           []                               \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, 40)           14560       ['embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 40)           1960        ['time_features_input[0][0]']    \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 80)           0           ['lstm_1[0][0]',                 \n",
      "                                                                  'dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 80)           0           ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 80)          320         ['dropout[0][0]']                \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 100)          8100        ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 100)          0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 305722)       30877922    ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 46,189,012\n",
      "Trainable params: 46,188,852\n",
      "Non-trainable params: 160\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dropout, Dense, Bidirectional, BatchNormalization, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.mixed_precision import set_global_policy\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "set_global_policy('mixed_float16')\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  \n",
    "    patience=10,  \n",
    "    restore_best_weights=True \n",
    ")\n",
    "\n",
    "artist_track_input = Input(shape=(sequence_length-1,), dtype='int32', name='artist_track_input')\n",
    "time_features_input = Input(shape=(num_time_features,), name='time_features_input')  \n",
    "\n",
    "embedding_layer = Embedding(input_dim=vocab_size + 1, output_dim=50, input_length=sequence_length-1)(artist_track_input)\n",
    "lstm_layer = LSTM(40, dropout=0.2, recurrent_dropout=0.2)(embedding_layer)\n",
    "\n",
    "time_dense_layer = Dense(40, activation='relu')(time_features_input)\n",
    "\n",
    "combined = concatenate([lstm_layer, time_dense_layer])\n",
    "\n",
    "x = Dropout(0.5)(combined)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(100, activation='relu', kernel_regularizer=l1_l2(l1=0.01, l2=0.01))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(vocab_size, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=[artist_track_input, time_features_input], outputs=output)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(X_artist_track, X_time_features, y, batch_size):\n",
    "\n",
    "    num_samples = X_artist_track.shape[0]\n",
    "    while True: \n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_X_artist_track = X_artist_track[offset:offset+batch_size]\n",
    "            batch_X_time_features = X_time_features[offset:offset+batch_size]\n",
    "            batch_y = y[offset:offset+batch_size]\n",
    "            \n",
    "            \n",
    "            yield [batch_X_artist_track, batch_X_time_features], batch_y\n",
    "            \n",
    "import tensorflow as tf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m train_generator \u001b[38;5;241m=\u001b[39m data_generator(X_train_artist_track, X_train_time_features, y_train, batch_size)\n\u001b[0;32m      5\u001b[0m validation_generator \u001b[38;5;241m=\u001b[39m data_generator(X_test_artist_track, X_test_time_features, y_test, batch_size)\n\u001b[1;32m----> 7\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# train_generator,\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# validation_data=validation_generator,\u001b[39;49;00m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvalidation_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mceil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_artist_track\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\wyero\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\wyero\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1642\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1643\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1644\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1648\u001b[0m ):\n\u001b[0;32m   1649\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1650\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1651\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1652\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\wyero\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\wyero\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    877\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    879\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 880\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    882\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    883\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\wyero\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:945\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    941\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[0;32m    942\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    943\u001b[0m     \u001b[38;5;66;03m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[0;32m    944\u001b[0m     \u001b[38;5;66;03m# no_variable_creation function.\u001b[39;00m\n\u001b[1;32m--> 945\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    946\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    947\u001b[0m   _, _, filtered_flat_args \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    948\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn\u001b[38;5;241m.\u001b[39m_function_spec  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    949\u001b[0m       \u001b[38;5;241m.\u001b[39mcanonicalize_function_inputs(\n\u001b[0;32m    950\u001b[0m           args, kwds))\n",
      "File \u001b[1;32mc:\\Users\\wyero\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    132\u001b[0m   (concrete_function,\n\u001b[0;32m    133\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\wyero\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1741\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1744\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1745\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1746\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1747\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m     args,\n\u001b[0;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1750\u001b[0m     executing_eagerly)\n\u001b[0;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\wyero\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    377\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 378\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    384\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    386\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    387\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    390\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    391\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\wyero\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "steps_per_epoch = np.ceil(X_train_artist_track.shape[0] / batch_size)\n",
    "\n",
    "train_generator = data_generator(X_train_artist_track, X_train_time_features, y_train, batch_size)\n",
    "validation_generator = data_generator(X_test_artist_track, X_test_time_features, y_test, batch_size)\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=np.ceil(X_test_artist_track.shape[0] / batch_size), \n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: lstm_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: lstm_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('lstm_model')\n",
    "\n",
    "# model = load_model('lstm_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "613/613 [==============================] - 348s 567ms/step\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.43 GiB for an array with shape (19594, 19594) and data type int32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m y_pred_top_k \u001b[38;5;241m=\u001b[39m label_encoder\u001b[38;5;241m.\u001b[39minverse_transform(top_k_indices\u001b[38;5;241m.\u001b[39mflatten())\u001b[38;5;241m.\u001b[39mreshape(top_k_indices\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      7\u001b[0m y_true_names \u001b[38;5;241m=\u001b[39m label_encoder\u001b[38;5;241m.\u001b[39minverse_transform(y_true)\n\u001b[1;32m----> 9\u001b[0m binary_relevance \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpred\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43my_true_names\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpred\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43my_pred_top_k\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m predicted_scores \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand(k)  \n\u001b[0;32m     12\u001b[0m all_positives \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(y_true)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.43 GiB for an array with shape (19594, 19594) and data type int32"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred_prob = model.predict([X_test_artist_track, X_test_time_features])\n",
    "y_true = y_test\n",
    "k = 30\n",
    "top_k_indices = np.argsort(y_pred_prob, axis=1)[:, -k:][:, ::-1]  \n",
    "\n",
    "y_pred_top_k = label_encoder.inverse_transform(top_k_indices.flatten()).reshape(top_k_indices.shape)\n",
    "y_true_names = label_encoder.inverse_transform(y_true)\n",
    "\n",
    "# binary_relevance = np.array([[1 if label in pred[:k] else 0 for label in y_true_names] for pred in y_pred_top_k])\n",
    "# predicted_scores = np.random.rand(k)  \n",
    "\n",
    "all_positives = len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit Rate at 30: 0.0469\n",
      "Precision@30: 0.0469\n",
      "Recall@30: 0.0469\n",
      "MAP: 0.0070\n"
     ]
    }
   ],
   "source": [
    "def calculate_top_30_accuracy_and_print_recommendations(y_pred_prob, y_true, label_encoder):\n",
    "    \n",
    "    k = 30\n",
    "    top_k_indices = np.argsort(y_pred_prob, axis=1)[:, -k:][:, ::-1] \n",
    "    top_k_accuracy_list = []\n",
    "\n",
    "    for i, (top_k, true) in enumerate(zip(top_k_indices, y_true)):\n",
    "        hit = true in top_k\n",
    "        top_k_accuracy_list.append(int(hit))\n",
    "\n",
    "        recommended_names = label_encoder.inverse_transform(top_k)\n",
    "        true_name = label_encoder.inverse_transform([true])[0]\n",
    "\n",
    "\n",
    "    top_30_accuracy = np.mean(top_k_accuracy_list)\n",
    "    print(f\"Top-30 Accuracy: {top_30_accuracy*100:.2f}%\")\n",
    "    \n",
    "    return top_30_accuracy\n",
    "\n",
    "def compute_hit_rate_at_k(y_true, y_pred_top_k, k):\n",
    "\n",
    "    hits = 0\n",
    "    for true, pred in zip(y_true, y_pred_top_k):\n",
    "        if true in pred[:k]:\n",
    "            hits += 1\n",
    "    return hits / len(y_true)\n",
    "\n",
    "def precision_at_30(y_true, y_pred_top_k):\n",
    "    correct_predictions = sum(1 for true, pred in zip(y_true, y_pred_top_k) if true in pred[:30])\n",
    "    return correct_predictions / len(y_pred_top_k)\n",
    "\n",
    "def recall_at_30(y_true, y_pred_top_k):\n",
    "    hits = sum(1 for true, pred in zip(y_true, y_pred_top_k) if true in pred[:30])\n",
    "    total_relevant = len(y_true)  \n",
    "    return hits / total_relevant\n",
    "\n",
    "\n",
    "def average_precision_at_k(y_true, y_score, k=30):\n",
    "    y_true = np.asarray(y_true)[:k]\n",
    "    y_score = np.asarray(y_score)[:k]\n",
    "\n",
    "    if not y_true.any():\n",
    "        return 0\n",
    "\n",
    "    score = 0\n",
    "    num_hits = 0\n",
    "    for i, (p, rel) in enumerate(zip(y_score, y_true), 1):\n",
    "        if rel:\n",
    "            num_hits += 1\n",
    "            score += num_hits / i\n",
    "    return score / np.sum(y_true)\n",
    "\n",
    "def apk(actual, predicted, k=30):\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k=30):\n",
    "    return np.mean([apk(a, p, k) for a, p in zip(actual, predicted)])\n",
    "\n",
    "\n",
    "\n",
    "hit_rate = compute_hit_rate_at_k(y_true_names, y_pred_top_k, k)\n",
    "print(f\"Hit Rate at {k}: {hit_rate:.4f}\")\n",
    "precision_30 = precision_at_30(y_true_names, y_pred_top_k)\n",
    "print(f\"Precision@30: {precision_30:.4f}\")\n",
    "recall_30 = recall_at_30(y_true_names, y_pred_top_k)\n",
    "print(f\"Recall@30: {recall_30:.4f}\")\n",
    "\n",
    "\n",
    "map_score = mapk([[y] for y in y_true_names], y_pred_top_k, k=30)\n",
    "print(f\"MAP: {map_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean NDCG@30: 0.0128\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def precompute_logarithms(k):\n",
    "    return np.log2(np.arange(2, k + 2))\n",
    "\n",
    "def calculate_batch_ndcg(y_true_batch, y_pred_prob_batch, k, precomputed_logs):\n",
    "    top_k_indices = np.argpartition(y_pred_prob_batch, -k)[:, -k:]\n",
    "    ndcg_scores = []\n",
    "\n",
    "    for true_label, indices in zip(y_true_batch, top_k_indices):\n",
    "        sorted_indices = np.argsort(-y_pred_prob_batch[np.arange(len(indices)), indices])\n",
    "        is_relevant = (true_label == indices[sorted_indices]).astype(int)\n",
    "        \n",
    "        dcg = np.sum((2**is_relevant - 1) / precomputed_logs[sorted_indices])\n",
    "        idcg = np.sum((2**1 - 1) / precomputed_logs[:np.sum(is_relevant)])\n",
    "        ndcg_score = dcg / idcg if idcg > 0 else 0\n",
    "        ndcg_scores.append(ndcg_score)\n",
    "\n",
    "    return np.mean(ndcg_scores)\n",
    "\n",
    "def calculate_ndcg_in_batches(y_true, y_pred_prob, k=30, batch_size=1000):\n",
    "    num_samples = y_true.shape[0]\n",
    "    precomputed_logs = precompute_logarithms(k)\n",
    "    ndcg_scores = []\n",
    "\n",
    "    for start_idx in range(0, num_samples, batch_size):\n",
    "        end_idx = start_idx + batch_size\n",
    "        batch_ndcg_score = calculate_batch_ndcg(\n",
    "            y_true[start_idx:end_idx],\n",
    "            y_pred_prob[start_idx:end_idx],\n",
    "            k,\n",
    "            precomputed_logs\n",
    "        )\n",
    "        ndcg_scores.append(batch_ndcg_score)\n",
    "\n",
    "    mean_ndcg = np.mean(ndcg_scores)\n",
    "    return mean_ndcg\n",
    "\n",
    "mean_ndcg_score = calculate_ndcg_in_batches(y_true, y_pred_prob, k=30, batch_size=1000)\n",
    "print(f\"Mean NDCG@30: {mean_ndcg_score:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
