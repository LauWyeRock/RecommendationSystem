{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "time signature (Audio)\n",
    "\n",
    "Valence (Audio)\n",
    "\n",
    "Danceability: tempo, chroma_stft\n",
    "\n",
    "Energy: rms, spectral_centroid\n",
    "\n",
    "Instrumentalness: mfcc (Higher variance in MFCCs might indicate instrumental tracks)\n",
    "\n",
    "Loudness: rms\n",
    "\n",
    "Speechiness: zcr, mfcc (Patterns in MFCCs that indicate speech)\n",
    "\n",
    "Valence, Mood, Emotion: These are subjective and would require complex modeling with labeled data to infer accurately from the extracted features. Machine learning models trained on datasets where songs \n",
    "are labeled with these attributes can use these features as input to predict mood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "import base64   \n",
    "import pandas as pd\n",
    "import librosa\n",
    "import numpy as np\n",
    "import lyricsgenius\n",
    "import langdetect\n",
    "import re\n",
    "import string\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lastfm_api_key = \"97d5a64d5ba4a8bc580b752ceff3b87f\"\n",
    "lastfm_secret = \"35175090bd61f6f16ac607bd26e5b1de\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_deezer_track(track_name):\n",
    "    search_url = \"https://api.deezer.com/search/track\"\n",
    "    params = {\"q\": track_name}\n",
    "    response = requests.get(search_url, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        tracks = response.json().get('data', [])\n",
    "        for track in tracks:\n",
    "            print(f\"Track ID: {track['id']}, Title: {track['title']}, Artist: {track['artist']['name']}\")\n",
    "    else:\n",
    "        print(f\"Failed to search tracks. Status code: {response.status_code}\")\n",
    "\n",
    "\n",
    "def get_deezer_track_info(track_id):\n",
    "    \"\"\"\n",
    "    Fetch track information and MP3 preview file URL from Deezer API.\n",
    "\n",
    "    Parameters:\n",
    "    - track_id: The unique identifier for the track on Deezer.\n",
    "\n",
    "    Returns:\n",
    "    A dictionary with track information and the preview URL.\n",
    "    \"\"\"\n",
    "    base_url = \"https://api.deezer.com/track/\"\n",
    "    response = requests.get(f\"{base_url}{track_id}\")\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        main_artist = data.get(\"artist\", {}).get(\"name\", \"\")\n",
    "        contributors = [contributor['name'] for contributor in data.get(\"contributors\", []) if contributor['name'] != main_artist]\n",
    "        featured_artists = \", \".join(contributors) if contributors else None\n",
    "\n",
    "        track_info = {\n",
    "            \"title\": data.get(\"title\"),\n",
    "            \"artist\": main_artist,\n",
    "            \"featured_artists\": featured_artists,\n",
    "            \"duration\": data.get(\"duration\"),\n",
    "            \"album\": data.get(\"album\", {}).get(\"title\"),\n",
    "            \"preview_url\": data.get(\"preview\"),\n",
    "            \"link\": data.get(\"link\")\n",
    "        }\n",
    "        return track_info\n",
    "    else:\n",
    "        print(f\"Failed to fetch data for track ID {track_id}. Status code: {response.status_code}\")\n",
    "        return {}\n",
    "\n",
    "\n",
    "def get_song_details_from_url(audio_url, api_token):\n",
    "    \"\"\"\n",
    "    Fetch song details using AudD API from an audio URL.\n",
    "\n",
    "    Parameters:\n",
    "    - audio_url: URL to the audio file for song recognition.\n",
    "    - api_token: Your AudD API token.\n",
    "\n",
    "    Returns:\n",
    "    A dictionary with song details.\n",
    "    \"\"\"\n",
    "    api_endpoint = \"https://api.audd.io/\"\n",
    "    params = {\n",
    "        \"url\": audio_url,\n",
    "        \"return\": \"apple_music,spotify\",  # You can specify what additional data you want (e.g., metadata from Apple Music or Spotify)\n",
    "        \"api_token\": api_token,\n",
    "    }\n",
    "\n",
    "    response = requests.post(api_endpoint, data=params)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Failed to fetch song details. Status code: {response.status_code}\")\n",
    "        return {}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'FÃ¼r Elise',\n",
       " 'artist': 'Ludwig van Beethoven',\n",
       " 'featured_artists': None,\n",
       " 'duration': 173,\n",
       " 'album': 'Classical Best Of',\n",
       " 'preview_url': 'https://cdns-preview-a.dzcdn.net/stream/c-a9dee2af0ec7ab7000e8f63cca353ce7-13.mp3',\n",
       " 'link': 'https://www.deezer.com/track/4538913'}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search_deezer_track(\"Fur Elise\")\n",
    "get_deezer_track_info(\"4538913\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_librosa_features_from_url(url):\n",
    "    # Fetch the audio file from the URL\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Failed to download audio file from {url}\")\n",
    "    \n",
    "    # Create a temporary file and manually manage it\n",
    "    temp_dir = tempfile.gettempdir()\n",
    "    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\", dir=temp_dir)\n",
    "    temp_file_path = temp_file.name\n",
    "    \n",
    "    try:\n",
    "        # Write the fetched content to the temp file and close it to release the lock\n",
    "        temp_file.write(response.content)\n",
    "        temp_file.close()\n",
    "        \n",
    "        # Now, load the audio file from the path\n",
    "        y, sr = librosa.load(temp_file_path, sr=None)  # Using sr=None to preserve the original sampling rate\n",
    "        \n",
    "        # Analyze the audio file\n",
    "        duration = librosa.get_duration(y=y, sr=sr)\n",
    "        tempo, beat_frames = librosa.beat.beat_track(y=y, sr=sr)\n",
    "        harmonic, percussive = librosa.effects.hpss(y)\n",
    "        rms = np.mean(librosa.feature.rms(y=y))\n",
    "        spectral_centroid = np.mean(librosa.feature.spectral_centroid(y=y, sr=sr))\n",
    "        zcr = np.mean(librosa.feature.zero_crossing_rate(y))\n",
    "        beat_times = librosa.frames_to_time(beat_frames, sr=sr)\n",
    "        \n",
    "        tonnetz = np.mean(librosa.feature.tonnetz(y=y, sr=sr).T, axis=0)\n",
    "        spectral_bandwidth = np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr))\n",
    "        spectral_contrast = np.mean(librosa.feature.spectral_contrast(y=y, sr=sr).T, axis=0)\n",
    "        \n",
    "        harmonic_centroid = librosa.feature.spectral_centroid(y=harmonic, sr=sr)\n",
    "        percussive_centroid = librosa.feature.spectral_centroid(y=percussive, sr=sr)\n",
    "\n",
    "\n",
    "        mfcc_var = np.std(librosa.feature.mfcc(y=y, sr=sr).T, axis=0)\n",
    "        chroma_var = np.std(librosa.feature.chroma_stft(y=y, sr=sr).T, axis=0)\n",
    "\n",
    "        features = {\n",
    "            'mfcc': np.mean(librosa.feature.mfcc(y=y, sr=sr).T, axis=0),\n",
    "            'mfcc_var': mfcc_var, \n",
    "            'chroma': np.mean(librosa.feature.chroma_stft(y=y, sr=sr).T, axis=0),\n",
    "            'chroma_var': chroma_var, \n",
    "            'duration': duration,\n",
    "            'rms': rms,\n",
    "            'spectral_bandwidth': spectral_bandwidth,\n",
    "            'spectral_contrast': spectral_contrast,\n",
    "            'spectral_centroid': spectral_centroid,\n",
    "            'harmonic_centroid': harmonic_centroid,\n",
    "            'percussive_centroid': percussive_centroid,\n",
    "            'zcr': zcr,\n",
    "            'tonnetz': tonnetz,\n",
    "            'tempo': tempo,\n",
    "            'beat_times': beat_times\n",
    "        }\n",
    "    finally:\n",
    "        # Ensure the temporary file is removed after processing\n",
    "        os.remove(temp_file_path)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def estimate_instrumentalness(features):\n",
    "    harmonic_centroid = features['harmonic_centroid']\n",
    "    percussive_centroid = features['percussive_centroid']\n",
    "\n",
    "    harmonic_mean_centroid = np.mean(harmonic_centroid)\n",
    "    percussive_mean_centroid = np.mean(percussive_centroid)\n",
    "\n",
    "    instrumentalness = 1.0 - (percussive_mean_centroid / harmonic_mean_centroid)\n",
    "\n",
    "    return instrumentalness\n",
    "\n",
    "\n",
    "def estimate_speechiness(features):\n",
    "    # Extract relevant features\n",
    "    zcr_mean = np.mean(features['zcr'])\n",
    "    spectral_centroid_mean = np.mean(features['spectral_centroid'])\n",
    "    spectral_bandwidth_mean = np.mean(features['spectral_bandwidth'])\n",
    "\n",
    "    # Calculate statistical properties of features\n",
    "    mean_zcr = np.mean(zcr_mean)\n",
    "    mean_centroid = np.mean(spectral_centroid_mean)\n",
    "    mean_bandwidth = np.mean(spectral_bandwidth_mean)\n",
    "\n",
    "    # Calculate speechiness score based on dynamic heuristic approach\n",
    "    # This approach estimates speechiness based on deviations from the mean of features\n",
    "    # The assumption is that speech will exhibit certain characteristics in terms of zero crossing rate, spectral centroid, and spectral bandwidth\n",
    "\n",
    "    # Calculate deviations from mean\n",
    "    zcr_deviation = (mean_zcr - zcr_mean) / (np.std(zcr_mean) + 1e-8)\n",
    "    centroid_deviation = (mean_centroid - spectral_centroid_mean) / (np.std(spectral_centroid_mean) + 1e-8)\n",
    "    bandwidth_deviation = (mean_bandwidth - spectral_bandwidth_mean) / (np.std(spectral_bandwidth_mean) + 1e-8)\n",
    "\n",
    "    # Aggregate deviations and compute speechiness score\n",
    "    deviation_score = np.mean([zcr_deviation, centroid_deviation, bandwidth_deviation])\n",
    "    speechiness_score = 1.0 - np.clip(deviation_score, 0.0, 1.0)  # Clip to [0, 1]\n",
    "\n",
    "    return speechiness_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def soft_normalize(value, scale=1.0, offset=0.0):\n",
    "    \"\"\"Applies a soft normalization with optional scaling and offset.\"\"\"\n",
    "    # Ensure value is non-negative and apply a logarithmic scaling for normalization\n",
    "    return np.log1p(max(0, value)) / (np.log1p(scale) + offset)\n",
    "\n",
    "def calculate_song_features(features):\n",
    "    scores = {}\n",
    "\n",
    "    # Danceability\n",
    "    beat_intervals = np.diff(features['beat_times'])\n",
    "    beat_interval_variability = 1 / (1 + np.var(beat_intervals))  # Inverted variability for regularity\n",
    "    scores['danceability'] = np.mean([\n",
    "        1 - (features['tempo'] / 240),  # Invert as higher tempo doesn't always mean more danceable\n",
    "        beat_interval_variability,\n",
    "        np.mean(features['chroma'])  # Chroma contributes to danceability\n",
    "    ])\n",
    "\n",
    "    # Energy\n",
    "    dynamic_range = np.max(features['rms']) - np.min(features['rms'])\n",
    "    perceived_loudness = features['rms']\n",
    "    timbre = features['spectral_centroid'] / np.max(features['spectral_centroid'])\n",
    "    onset_rate = len(features['beat_times']) / features['duration']\n",
    "    scores['energy'] = np.mean([\n",
    "        dynamic_range,\n",
    "        perceived_loudness,\n",
    "        timbre,\n",
    "        onset_rate\n",
    "    ])\n",
    "\n",
    "    # Instrumentalness\n",
    "\n",
    "    instrumentalness_score = estimate_instrumentalness(features)\n",
    "    scores['instrumentalness'] = instrumentalness_score\n",
    "\n",
    "\n",
    "\n",
    "    # Loudness (Using RMS as a proxy, normalized to a -60 to 0 dB range for demonstration)\n",
    "    # This is an approximation and may not accurately reflect Spotify's loudness in dB.\n",
    "    rms_db = 20 * np.log10(features['rms'] + 1e-6)  # Avoid log(0) by adding a small constant\n",
    "    scores['loudness'] = np.interp(rms_db, [-60, 0], [0, 1])  # Interpolate RMS dB value to 0-1 range\n",
    "\n",
    "    # Speechiness\n",
    "    # Extract features\n",
    "    speechiness_score = estimate_speechiness(features)\n",
    "    scores['speechiness'] = speechiness_score\n",
    "\n",
    "\n",
    "    return scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_artist_tracks(artist_name, song_name):\n",
    "    # def search_deezer_track(track_name):\n",
    "    #     search_url = \"https://api.deezer.com/search/track\"\n",
    "    #     params = {\"q\": track_name}\n",
    "    #     response = requests.get(search_url, params=params)\n",
    "    #     tracks = []\n",
    "    #     if response.status_code == 200:\n",
    "    #         tracks_data = response.json().get('data', [])\n",
    "    #         for track in tracks_data:\n",
    "    #             if artist_name.lower() in track['artist']['name'].lower():\n",
    "    #                 tracks.append({\n",
    "    #                     'id': track['id'],\n",
    "    #                     'title': track['title'],\n",
    "    #                     'artist': track['artist']['name'],\n",
    "    #                     'preview_url': track['preview']\n",
    "    #                 })\n",
    "    #     return tracks\n",
    "\n",
    "    def search_deezer_track(track_name):\n",
    "        search_url = \"https://api.deezer.com/search/track\"\n",
    "        query = f'artist:\"{artist_name}\" track:\"{song_name}\"'\n",
    "        params = {\"q\": query}\n",
    "        response = requests.get(search_url, params=params)\n",
    "        if response.status_code == 200:\n",
    "            tracks_data = response.json().get('data', [])\n",
    "            for track in tracks_data:\n",
    "                if artist_name.lower() in track['artist']['name'].lower():\n",
    "                    # Return the first match immediately\n",
    "                    return {\n",
    "                        'id': track['id'],\n",
    "                        'title': track['title'],\n",
    "                        'artist': track['artist']['name'],\n",
    "                        'preview_url': track['preview']\n",
    "                    }\n",
    "        return None  # Return None if no match is found\n",
    "\n",
    "    # Search for the track\n",
    "    track_name = f\"{artist_name} {song_name}\"\n",
    "    track = search_deezer_track(track_name)\n",
    "\n",
    "    # Initialize DataFrame\n",
    "    df = pd.DataFrame(columns=['Song Name', 'Artist Name', 'Danceability', 'Energy', 'Instrumentalness', 'Loudness', 'Speechiness'])\n",
    "\n",
    "    # Process each track found\n",
    "    if track:\n",
    "        # Extract features\n",
    "        features = extract_librosa_features_from_url(track['preview_url'])\n",
    "\n",
    "        # Calculate scores\n",
    "        score = calculate_song_features(features)\n",
    "\n",
    "        # Append to DataFrame directly without for-loop\n",
    "        df = df.append({\n",
    "            'Song Name': track['title'],\n",
    "            'Artist Name': track['artist'],\n",
    "            'Danceability': score.get('danceability', np.nan),\n",
    "            'Energy': score.get('energy', np.nan),\n",
    "            'Instrumentalness': score.get('instrumentalness', np.nan),\n",
    "            'Loudness': score.get('loudness', np.nan),\n",
    "            'Speechiness': score.get('speechiness', np.nan)\n",
    "        }, ignore_index=True)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wyero\\AppData\\Local\\Temp\\ipykernel_8504\\2371916571.py:53: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Artist Name</th>\n",
       "      <th>Danceability</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>Loudness</th>\n",
       "      <th>Speechiness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gangnam style</td>\n",
       "      <td>Psy</td>\n",
       "      <td>0.64482</td>\n",
       "      <td>0.880602</td>\n",
       "      <td>-0.326651</td>\n",
       "      <td>0.829844</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Song Name Artist Name  Danceability    Energy  Instrumentalness  \\\n",
       "0  Gangnam style         Psy       0.64482  0.880602         -0.326651   \n",
       "\n",
       "   Loudness  Speechiness  \n",
       "0  0.829844          1.0  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# analyze_artist_tracks(\"Ludwig van Beethoven\", \"Fur Elise\")\n",
    "# analyze_artist_tracks(\"IU\", \"Blueming\")\n",
    "analyze_artist_tracks(\"Psy\", \"Gangnam Style\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
